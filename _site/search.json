[
  {
    "objectID": "01_introduction.html",
    "href": "01_introduction.html",
    "title": "Chapter one: Setup and getting data",
    "section": "",
    "text": "Starting with packages\nQuarto is a recently developed framework that interactively connects to multiple programming languages and allows for advanced statistical work to be linked to word processing with ease. It will be the basis for our course and for data analysis.\n\n\n\nFigure @ref(fig:2) Opening a new quarto file\n\n\nThe R programming language was first released on 29 February 2000. Ross Ihaka and Robert Gentleman wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. R is now an internationally recognized language used all over the world. It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on CRAN. Today we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")\n\n\n\nIncluding your own data\nTo add data to your directory, first create a folder that\n\n\n\nFigure @ref(fig:3) Adding a folder.\n\n\nand name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R.\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”"
  },
  {
    "objectID": "slides/01-introduction.html",
    "href": "slides/01-introduction.html",
    "title": "Chapter one: Setup and getting data",
    "section": "",
    "text": "Starting with packages\nQuarto is a recently developed framework that interactively connects to multiple programming languages and allows for advanced statistical work to be linked to word processing with ease. It will be the basis for our course and for data analysis.\n\n\n\nFigure @ref(fig:2) Opening a new quarto file\n\n\nThe R programming language was first released on 29 February 2000. Ross Ihaka and Robert Gentleman wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. R is now an internationally recognized language used all over the world. It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on CRAN. Today we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")\n\n\n\nIncluding your own data\nTo add data to your directory, first create a folder that\n\n\n\nFigure @ref(fig:3) Adding a folder.\n\n\nand name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R.\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\nNotice that your environment tab will change and will show that you have data imported into R.\n\n\n\nUpdates in environment tab after importing data.\n\n\nCongratulations! You have just imported your first dataset into R which is the first step in the data science workflow!\n\n\n\nData science workflow"
  },
  {
    "objectID": "slides/01-introduction.html#downloading-software-and-creating-a-project",
    "href": "slides/01-introduction.html#downloading-software-and-creating-a-project",
    "title": "STAT 1010 - Fall 2022",
    "section": "Downloading software and creating a project",
    "text": "Downloading software and creating a project\nPrior to starting any statistics, software organization is crucial. Your high schools may have used google sheets or excel, but for our course we will be using R and RStudio. Please see our website to download them, then download quarto to get started.\nOnce this is completed, please open RStudio and do the following:\n\n\n\nFigure @ref(fig:1) Start a new project in RStudio\n\n\n\n\n\nFigure @ref(fig:2) Select “New Directory”\n\n\n\n\n\nFigure @ref(fig:3) Then select “New Project”\n\n\nHit the “Browse” button, then the “New Folder” button and call this new folder “Stats1010.” All work related to chapter 1 will be in this folder, and we will create a new project for each chapter and a new project for each homework.\n\n\n\n\n\nthen hit “Create project.”"
  },
  {
    "objectID": "computing-pipelines.html",
    "href": "computing-pipelines.html",
    "title": "Pipelines",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "computing-pipelines.html#simple-linear-regression",
    "href": "computing-pipelines.html#simple-linear-regression",
    "title": "Pipelines",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nModel fitting\nFit model:\n\npenguins_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\nTidy model output:\n\ntidy(penguins_fit)\n\nFormat model output as table:\n\ntidy(penguins_fit) %>%\n  kable(digits = 3)\n\nAugment data with model:\n\naugment(penguins_fit$fit)\n\n\n\nStatistical inference"
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Open your Stat1010 project then go to file and open a quarto document. You can add code chunks by clicking on the green button in the IDE and answer some questions directly in the document, and add further code chunks. Hit render and if there are no errors in your code, the pdf should pop up. You can then upload to either Canvas or Gradescope"
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.1.2: https://cran.r-project.org/\nDownload and install a daily build of RStudio: https://dailies.rstudio.com/\nInstall Quarto CLI: https://quarto.org/docs/getting-started/installation.html\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here."
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#discussion-forum",
    "href": "course-support.html#discussion-forum",
    "title": "Course support",
    "section": "Discussion forum",
    "text": "Discussion forum\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The online discussion forum is the best venue for these! We will use Ed discussion as the online discussion forum. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go Ed discussion), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email dr. gwynn sturdevant at gwynnc@wharton.upenn.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STAT 1010” and only “STAT 1010” in the subject line. You can also contact me privately on Canvas. Barring extenuating circumstances, I will respond to STAT 1010 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Weingarten learning center. The Weingarten Center offers a variety of resources to support all Penn students in reaching their academic goals. They offer multiple workshops throughout the semester and students can request workshops. All services are free and confidential. To contact the Weingarten Center, call 215-573-9235. The office is located in Stouffer Commons at 3702 Spruce Street, Suite 300.\nLearning Consultations offers individual consultations and group workshops that support students in developing more efficient and effective study skills and learning strategies. Learning specialists work with students to address time and project management, academic reading and writing, note-taking, problem-solving, exam preparation, test-taking, self-regulation, and flexibility.\n\nTutoring offers free access to on-campus tutors for many Penn courses in both drop-in and weekly contract format. Tutoring may be individual or in small groups. Tutors will assist with applying course information, understanding key concepts, and developing course-specific strategies. Tutoring support is available throughout the term but is best accessed early in the semester. First-time users must meet with a staff member; returning users may submit their requests online.\n\nAdditionally, Marks Family Writing Center provides expert help in writing for undergraduate and graduate students. Communication Within the Curriculum helps students express themselves orally with clarity and confidence. Language Direct provides tutoring for foreign languages. Van\nPelt Library supports students in research and instructional technologies through a range of workshops and consultations."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nCounseling and Psychological Services (CAPS) provides professional psychological and psychiatric services to students who need support in fulfilling their academic, social, and personal objectives. CAPS directly supports student mental health through counseling, crisis management, consultation, education and outreach, and training. CAPS has a satellite office in Huntsman Hall, and students with urgent concerns can talk with a CAPS clinician 24/7 at 215.898.7021 (press 1) or visit CAPS' main office at 3624 Market Street during business hours.\n\nStudent Health Service provides students with accessible, cost-effective, culturally-sensitive, and student-focused healthcare, including care for acute and chronic health problems, preventive health services, and health and wellness education.\n\nAlcohol and Other Drug Program Initiatives (AOD) works to reduce harm related to alcohol and other drug use at Penn.\n\nPenn Violence Prevention (PVP) engages the Penn community in the prevention of sexual violence, relationship violence, stalking, and sexual harassment on campus. PVP provides education and outreach and the staff serves as confidential resources for students.\n\nPublic Safety: From riding your bike on campus, to preventing unattended theft, the Division of Public Safety wants to make sure you have the information you need to protect your safety and your belongings.\n\nPenn Recreation: Penn offers many opportunities for students to participate in competitive team sports and stay physically fit at state-of-the-art, world-class training centers.\n\nWharton Wellness is a division-sponsored student organization that works to implement initiatives targeted at specific wellness issues in the Wharton community by creating experiences, fostering a positive culture of well-being, and connecting clubs/students to wellness resources.\n\nIt is important to me that you have the resources you need to be able to focus on learning in this course – this includes both the necessary academic materials as well as taking care of your day-to-day needs. Students experiencing difficulty affording the course materials should reach out to the Penn First Plus office (pennfirstplus@upenn.edu). Students who are struggling to afford sufficient food to eat every day and/or lack a safe and suitable space to live should contact Student Intervention Services (vpul-sisteam@pobox.upenn.edu). Students may also wish to contact their Financial Aid Counselor or Academic Advisor about these concerns. You are welcome to notify me if any of these challenges are affecting your success in this course, as long as you are comfortable doing so – I may have resources to support you."
  },
  {
    "objectID": "course-support.html#technology-accommodations",
    "href": "course-support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For technology assistance requests, please go here. Please note that supplies are limited. Additional support is also available through Student Intervention Services."
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-sakai",
    "href": "course-support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission and discussion will take place on GitHub instead.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "exams/exam-1.html",
    "href": "exams/exam-1.html",
    "title": "Exam 1",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team’s project"
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you’re interested in potentially using for the final project. If you’re unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you’re interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you’re interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you’re investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nRegression model technique (multiple linear regression and logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Gradescope.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting."
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project description",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model."
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’s projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nPairings\n\nSection 1 - M 1:45PM - 3:00PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\nchaa_chaa_chaa\nyay_stats\nstat_over_flow\n\n\ndekk\nchaa_chaa_chaa\nyay_stats\n\n\neight\ndekk\nchaa_chaa_chaa\n\n\nhousecats\neight\ndekk\n\n\nkrafthouse\nhousecats\neight\n\n\nrrawr\nkrafthouse\nhousecats\n\n\nstat_over_flow\nrrawr\nkrafthouse\n\n\nyay_stats\nstat_over_flow\nrrawr\n\n\n\n\n\nSection 2 - M 3:30PM - 4:45PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\na_plus_plus_plus\nwe_r\ntina\n\n\npredictors\na_plus_plus_plus\nwe_r\n\n\nsixers\npredictors\na_plus_plus_plus\n\n\nsoy_nuggets\nsixers\npredictors\n\n\ntina\nsoy_nuggets\nsixers\n\n\nwe_r\ntina\nsoy_nuggets\n\n\n\n\n\nSection 3 - M 5:15PM - 6:30PM\n\n\n\n\n\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\ndown_to_earth_goats\nthe_three_musketeers\nteam_five\n\n\nginger_and_stats\ndown_to_earth_goats\nthe_three_musketeers\n\n\npineapple_wedge_and_diced_papaya\nginger_and_stats\ndown_to_earth_goats\n\n\nstatchelorettes\npineapple_wedge_and_diced_papaya\nginger_and_stats\n\n\nstatisix\nstatchelorettes\npineapple_wedge_and_diced_papaya\n\n\nstats_squad\nstatisix\nstatchelorettes\n\n\nteam_five\nstats_squad\nstatisix\n\n\nthe_three_musketeers\nteam_five\nstats_squad\n\n\n\n\n\n\nProcess and questions\nSpend ~30 mins to review each team’s project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team’s repo.\nOpen the repo of the team you’re reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description.html#written-report",
    "href": "project-description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo = FALSE.\nYou will submit the PDF of your final report on Gradescope.\nThe PDF you submit must match the files in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#video-presentation-slides",
    "href": "project-description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nFor submission, convert these slides to a .pdf document, and submit the PDF of the slides on Gradescope.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick “Start a new conversation”.\nMake the title “Your Team Name: Project Title”. For example, “Teaching Team: Our Awesome Presentation”.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click “Insert 1 item.” This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou’re done!"
  },
  {
    "objectID": "project-description.html#presentation-comments",
    "href": "project-description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group’s video, then click “Reply” to post a question for the group. You may not post a question that’s already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e. it shouldn’t be “Why did you use a bar plot instead of a pie chart”?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group’s specific presentation, i.e demonstrating that you’ve watched the presentation.\nThis portion of the project will be assessed individually.\n\nPairings\nFind your team name in the first column, watch videos from teams in the second column and leave comments.\n\n\n\n\n\n\n\n\nReviewer\nFirst video to review\nSecond video to review\n\n\n\n\nGinger and Stats\nEight\nWe R\n\n\nKrafthouse\nGinger and Stats\nEight\n\n\nSoy Nuggets\nKrafthouse\nGinger and Stats\n\n\nDown To Earth Goats\nSoy Nuggets\nKrafthouse\n\n\nA+++\nDown To Earth Goats\nSoy Nuggets\n\n\nTeam Five\nA+++\nDown To Earth Goats\n\n\nRrawr\nTeam Five\nA+++\n\n\nHousecats\nRrawr\nTeam Five\n\n\nDekk\nHousecats\nRrawr\n\n\nStat OverFlow\nDekk\nHousecats\n\n\nThe Three Musketeers\nStat OverFlow\nDekk\n\n\nPredictors\nThe Three Musketeers\nStat OverFlow\n\n\nStats Squad\nPredictors\nThe Three Musketeers\n\n\nStatisix\nStats Squad\nPredictors\n\n\nSixers\nStatisix\nStats Squad\n\n\nYay Stats\nSixers\nStatisix\n\n\nTINA\nYay Stats\nSixers\n\n\nStatchelorettes\nTINA\nYay Stats\n\n\nPineapple Wedge and Diced Papaya\nStatchelorettes\nTINA\n\n\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\nStatchelorettes\n\n\nWe R\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\n\n\nEight\nWe R\nChaa Chaa Chaa"
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#peer-teamwork-evaluation",
    "href": "project-description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-syllabus.html#course-info",
    "href": "course-syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nSection 1\nMon & Wed\n8:30 am - 10:00 am\nSHDH 1206\n\n\nSection 2\nMon & Wed\n10:15 am - 11:45 am\nSHDH 1206\n\n\nSection 3\nMon & Wed\n1:45 pm - 3:15 pm\nSHDH 1206"
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the semester, you will be able to…\n\nunderstand data manipulation, and find basic summaries\nreason under uncertainity\nmake predictions\nunderstand probability\ncommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "course-syllabus.html#community",
    "href": "course-syllabus.html#community",
    "title": "Syllabus",
    "section": "Community",
    "text": "Community\n\nWharton’s Code of Conduct\nAs a student in this course, you have agreed to uphold the Wharton’s Student Code of Conduct as well as the practices specific to this course.\n\n\nInclusive community\nMy goal as your lecturer is to help you accomplish or discover your passion and find your spark. You all belong here. It is also my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Diversity, Inclusion and Belonging at the Wharton School. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups. Please feel free to leave anonymous comments in my mailbox on the 4th floor of the Academic Research Building.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Weingarten Center is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the the Weingarten Center to request or update accommodations under these circumstances; it can take up to 4 weeks to review documents and get approval.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website at stats1010-f22.github.io/website.\nI will regularly send course announcements via email and canvas, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the Ed discussion forum. There is a chance another student has already asked a similar question, so please check the other posts in Conversations before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\nEmails should be reserved for questions not appropriate for the public forum. If you email me, please include “STAT 1010” in the subject line and ONLY STAT 1010. Barring extenuating circumstances, I will respond to STAT 1010 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\n\nCheck out the Support page for more resources."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin\nStatistics for Business by Robert Stine and Dean Foster"
  },
  {
    "objectID": "course-syllabus.html#lectures-and-labs",
    "href": "course-syllabus.html#lectures-and-labs",
    "title": "Syllabus",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nThe goal of both the lectures is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded. In addition to application exercises will be periodic activities help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. More information on loaner laptops can be found here."
  },
  {
    "objectID": "course-syllabus.html#teams",
    "href": "course-syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture. All team members are expected to contribute equally to the completion of the labs and project and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team’s overall mark."
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nAssessment for the course is comprised of five components: application exercises, homework assignments, exams, projects, and teamwork.\n\nApplication exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises give you an opportunity to apply the statistical concepts and code introduced in the readings and lectures. Due dates for AEs will be announced as they are assigned.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and submitted as a PDF in Canvas.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be four exams consisting of multiple choice questions. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on the conceptual understanding of the content. The content of the exam will be related to the content in the prepare, practice, and perform assignments. More detail about the exams will be given during the semester.\nThe lowest exam grade will be dropped at the end of the semester.\n\n\nProject\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting, data-driven research question. The project will be completed with your teams, and each team will present their work. More information about the project will be provided during the semester."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n7%\n\n\nHomework\n35% (7 x 5%)\n\n\nProject\n15%\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n13%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "course-syllabus.html#five-tips-for-success",
    "href": "course-syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TA and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TA, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. If something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, and eventually you won’t know where to begin asking questions. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours, and let me help you identify a good (re)starting point."
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic integrity\nTL;DR: Don’t cheat!\nAll students must adhere to Wharton’s Code of Academic Integrity: Wharton is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nRegardless of course delivery format, it is your responsibility to understand and follow Wharton policies regarding academic integrity, including doing one’s own work, following proper citation of sources, and adhering to guidance around group work projects. Ignoring these requirements is a violation of the Wharton Community Standard. If you have any questions about how to follow these requirements, please contact Julie Nettleton, Director of the Center for Community Standards and Accountability (CSA).\n\n\nCollaboration policy\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\n\n\n\nPolicy on sharing and reusing code\nI am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. On individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email dr. sturdevant before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let dr. sturdevant know if you need help contacting your academic dean.\n\n\nRegrade request policy\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Wharton attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you’re going to miss a class and you’re feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others’ time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have symptoms related to COVID-19, have had a known exposure to COVID-19, or have tested positive for COVID-19. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health at 215-898-0300. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class. For the safety of all students, I require that students wear masks in class and prefer N95 or KN95 masks.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously or watching a recording of the class.\n\n\nPolicy on video recording course content\nLectures will be recorded and available on Canvas, so students should not need to create their own recordings of lectures. If you feel that you need record the lectures yourself, you must get written permission from me ahead of time and these recordings should be used for personal study only, not for distribution. The full policy on recording of lectures falls under the University of Pennsylvania’s V.L. Policy on Unauthorized Copying of Copyrighted Media, available at https://catalog.upenn.edu/faculty-handbook/v/v-l/. Unauthorized distribution may result in a civil suite, criminal charges, and/or penalties and fines."
  },
  {
    "objectID": "course-syllabus.html#learning-during-a-pandemic",
    "href": "course-syllabus.html#learning-during-a-pandemic",
    "title": "Syllabus",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis.\n\nNote: If you’ve read this far in the syllabus, send me an email with a picture of your pet if you have one or your favorite memes with STAT1010 in the subject line!"
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAugust 30: First day of classes\nSeptember 5: Labor Day holiday, no classes are held\nSeptember 13: Course Selection Period ends\nOctober 6 - 9: Fall term break, no classes are held\nOctober 10: Drop period ends\nOctober 10: Indigenous People’s Day (classes in session)\nOctober 28: Grade Type Change Deadline\nNovember 7: Last day to withdraw from a course\nNovember 22-23: Thur-Fri class schedule on Tue-Wed\nNovember 24-27: Thanksgiving Break\nDecember 12: Last day of classes\nDecember 13-14: Reading Days\nDecember 15 - 22: Final exams\nDecember 22: Fall term ends\n\nClick here for the full University of Pennsylvania academic calendar."
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They’ll be able to help diagnose the issue."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 1010: Introduction to Business Statistics",
    "section": "",
    "text": "Week\nDate\nTopic\nPrepare\nSlides\nAE\nHW\nExam\nProject\n\n\n\n\n\n1\nMon, 29 Aug\nNo class - opening exercises\n\n\n\n\n\n\n\n\n\n\nWed, 31 Aug\nStarting with R\n\n🖥️\n📋\n\n\n\n\n\n\n2\nMon, 5 Sept\nNo class - Labor Day\n\n\n\n\n\n\n\n\n\n\nWed, 7 Sept\nContinuation of Intro to R\n📖\n🖥️\n\n\n\n\n\n\n\n3\nMon, 12 Sept\nCategorical variables\n📖\n🖥️\n📋\n\n\n\n\n\n\n\nWed, 14 Sept\nNumerical variables\n\n🖥️\n📋\n✍️\n\n\n\n\n\n4\nMon, 19 Sept\nIntro to probability\n📖\n🖥️\n📋\n✍️\n\n\n\n\n\n\nWed, 21 Sept\nMore probability rules\n\n🖥️\n📋\n\n\n\n\n\n\n5\nMon, 26 Sept\nRevision of AE 1-4\n📖\n\n\n\n\n\n\n\n\n\nWed, 28 Sept"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Discussion forum\n🔗 on Ed discussion\n\n\n\n\nLecture streaming and recordings (email for permission)\n🔗 on Canvas\n\n\nSubmit AE\n🔗 on Canvas\n\n\nSubmit HWK\n🔗 on Gradescope\n\n\nGradebook\n🔗 on Canvas"
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Teaching Assistant\n\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\n\nPatrick Chao\nMon & Wed\n4pm - 5pm\nZoom"
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\n\nMartha Aboagye\nThursday 7 - 9 pm\nZoom\n\n\n\nRichard Fremgen\nLead TA for Section 3 (5:15 pm)\nTues 7 - 9 pm\nZoom\n\n\n\nEmily Gentles\nLead TA for Section 1 (1:45pm)\nWednesday 1 - 3 pm\nOld Chem 203B (On Zoom until January 18)\n\n\n\nSara Mehta\nMon 2 - 4 pm\nZoom\n\n\n\nRick Presman\nHead TA\nLead TA for Section 2 (3:30pm)\nThursday 3:30 - 4:30 pm\nFri 9 - 10 am\nZoom"
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "Prepare",
    "text": "Prepare\n📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-1.html#participate",
    "href": "weeks/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 1 - Download R and plotting your first graph"
  },
  {
    "objectID": "weeks/week-1.html#practice",
    "href": "weeks/week-1.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\n📋 diamonds"
  },
  {
    "objectID": "weeks/week-1.html#perform",
    "href": "weeks/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "supplemental/slr-derivations.html",
    "href": "supplemental/slr-derivations.html",
    "title": "Deriving the Least-Squares Estimates for Simple Linear Regression",
    "section": "",
    "text": "This document contains the mathematical details for deriving the least-squares estimates for slope (\\(\\beta_1\\)) and intercept (\\(\\beta_0\\)). We obtain the estimates, \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) by finding the values that minimize the sum of squared residuals, as shown in Equation 1.\n\\[\nSSR = \\sum\\limits_{i=1}^{n}[y_i - \\hat{y}_i]^2 = [y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)]^2 = [y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i]^2\n\\tag{1}\\]\nRecall that we can find the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize /eq-ssr by taking the partial derivatives of Equation 1 and setting them to 0. Thus, the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize the respective partial derivative also minimize the sum of squared residuals. The partial derivatives are shown in Equation 2.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} &= -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)  \\\\\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)\n\\end{aligned}\n\\tag{2}\\]\nThe derivation of deriving \\(\\hat{\\beta}_0\\) is shown in Equation 3.\n\\[\n\\begin{aligned}\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}(y_i + \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow - \\sum\\limits_{i=1}^{n}y_i + n\\hat{\\beta}_0 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i = 0 \\\\&\\Rightarrow n\\hat{\\beta}_0  = \\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i \\\\&\\Rightarrow \\hat{\\beta}_0  = \\frac{1}{n}\\Big(\\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i\\Big)\\\\&\\Rightarrow \\hat{\\beta}_0  = \\bar{y} - \\hat{\\beta}_1 \\bar{x} \\\\\\end{aligned}\n\\tag{3}\\]\nThe derivation of \\(\\hat{\\beta}_1\\) using the \\(\\hat{\\beta}_0\\) we just derived is shown in Equation 4.\n\\[\n\\begin{aligned}&\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} = -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0  \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + \\hat{\\beta}_0\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\\\text{(Fill in }\\hat{\\beta}_0\\text{)}&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\&\\Rightarrow  (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\bar{y}\\sum\\limits_{i=1}^{n}x_i - \\hat{\\beta}_1\\bar{x}\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow n\\bar{y}\\bar{x} - \\hat{\\beta}_1n\\bar{x}^2 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 - \\hat{\\beta}_1n\\bar{x}^2  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\&\\Rightarrow \\hat{\\beta}_1\\Big(\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2\\Big)  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\ &\\hat{\\beta}_1 = \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2}\\end{aligned}\n\\tag{4}\\]\nTo write \\(\\hat{\\beta}_1\\) in a form that’s more recognizable, we will use the following:\n\\[\n\\sum x_iy_i - n\\bar{y}\\bar{x} = \\sum(x - \\bar{x})(y - \\bar{y}) = (n-1)\\text{Cov}(x,y)\n\\tag{5}\\]\n\\[\n\\sum x_i^2 - n\\bar{x}^2 - \\sum(x - \\bar{x})^2 = (n-1)s_x^2\n\\tag{6}\\]\nwhere \\(\\text{Cov}(x,y)\\) is the covariance of \\(x\\) and \\(y\\), and \\(s_x^2\\) is the sample variance of \\(x\\) (\\(s_x\\) is the sample standard deviation).\nThus, applying Equation 5 and Equation 6, we have\n\\[\n\\begin{aligned}\\hat{\\beta}_1 &= \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2} \\\\&= \\frac{\\sum\\limits_{i=1}^{n}(x-\\bar{x})(y-\\bar{y})}{\\sum\\limits_{i=1}^{n}(x-\\bar{x})^2}\\\\&= \\frac{(n-1)\\text{Cov}(x,y)}{(n-1)s_x^2}\\\\&= \\frac{\\text{Cov}(x,y)}{s_x^2}\\end{aligned}\n\\tag{7}\\]\nThe correlation between \\(x\\) and \\(y\\) is \\(r = \\frac{\\text{Cov}(x,y)}{s_x s_y}\\). Thus, \\(\\text{Cov}(x,y) = r s_xs_y\\). Plugging this into Equation 7, we have\n\\[\n\\hat{\\beta}_1 = \\frac{\\text{Cov}(x,y)}{s_x^2} = r\\frac{s_ys_x}{s_x^2} = r\\frac{s_y}{s_x}\n\\tag{8}\\]"
  },
  {
    "objectID": "slides/01_introduction.html",
    "href": "slides/01_introduction.html",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "",
    "text": "For our course we will be using R and RStudio."
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "STA 1010: Introduction to Business Statistics",
    "section": "",
    "text": "The course goals are as follows:\n\nRecognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the scope of inference.\nUse statistical software to summarize data numerically and visually, and to perform data analysis.\nHave a conceptual understanding of the unified nature of statistical inference.\nApply estimation and testing methods to analyze single variables or the relationship between two variables in order to understand natural phenomena and make data-based\ndecisions.\nModel numerical response variables using a single or multiple explanatory variables.\nInterpret results correctly, effectively, and in context without relying on statistical jargon.\nCritique data-based claims and evaluate data-based decisions.\nComplete a research project demonstrating mastery of statistical data analysis from exploratory analysis to inference to modeling."
  },
  {
    "objectID": "slides/01_introduction.html#downloading-software-and-creating-a-project",
    "href": "slides/01_introduction.html#downloading-software-and-creating-a-project",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Downloading software and creating a project",
    "text": "Downloading software and creating a project\nFor our course we will be using R and RStudio."
  },
  {
    "objectID": "slides/01_introduction.html#start-a-project",
    "href": "slides/01_introduction.html#start-a-project",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Start a project",
    "text": "Start a project\nOpen RStudio and do the following:\n\nFigure @ref(fig:1) Start a new project in RStudio"
  },
  {
    "objectID": "slides/01_introduction.html#new-directory",
    "href": "slides/01_introduction.html#new-directory",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "New directory",
    "text": "New directory\n\nSelect “New Directory”"
  },
  {
    "objectID": "slides/01_introduction.html#directory-type",
    "href": "slides/01_introduction.html#directory-type",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Directory type",
    "text": "Directory type\n\nThen select “New Project”"
  },
  {
    "objectID": "slides/01_introduction.html#new-folder",
    "href": "slides/01_introduction.html#new-folder",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "New folder",
    "text": "New folder\nHit the “Browse” button, then the “New Folder” button and name it “Stats1010.” All work related to this class will be in this folder, and we will create a new document for each chapter and homework.\n\nthen hit “Create project.”"
  },
  {
    "objectID": "slides/01_introduction.html#why",
    "href": "slides/01_introduction.html#why",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Why?",
    "text": "Why?\nThe R programming language was first released on 29 February 2000. Ross Ihaka and Robert Gentleman wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. R is now an internationally recognized language used all over the world. It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on CRAN. Today we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")"
  },
  {
    "objectID": "slides/01_introduction.html#including-your-own-data",
    "href": "slides/01_introduction.html#including-your-own-data",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Including your own data",
    "text": "Including your own data\nTo add data to your directory, first create a folder that\n\nFigure @ref(fig:3) Adding a folder.and name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R."
  },
  {
    "objectID": "slides/01_introduction.html#importing-data",
    "href": "slides/01_introduction.html#importing-data",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Importing data",
    "text": "Importing data\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lec_1_images/first_line_of_code.html",
    "href": "slides/lec_1_images/first_line_of_code.html",
    "title": "Introduction to the diamonds dataset",
    "section": "",
    "text": "You own a jewelry business and are working to price your diamonds. To facilitate, you explore the diamond dataset in R and pay special attention to the cost of the diamond. Let’s explore together."
  },
  {
    "objectID": "slides/lec_1_images/first_line_of_code.html#what-should-the-price-of-your-diamonds-be",
    "href": "slides/lec_1_images/first_line_of_code.html#what-should-the-price-of-your-diamonds-be",
    "title": "Introduction to the diamonds dataset",
    "section": "What should the price of your diamonds be?",
    "text": "What should the price of your diamonds be?\nBased upon the above plot, and since the diamonds are nice, they should all cost above $150,000, right?"
  },
  {
    "objectID": "slides/01_introduction.html#name-the-document",
    "href": "slides/01_introduction.html#name-the-document",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Name the document",
    "text": "Name the document\nName the document “lec_01” and hit create\n\nNaming the document"
  },
  {
    "objectID": "slides/01_introduction.html#insert-an-r-code-chuck",
    "href": "slides/01_introduction.html#insert-an-r-code-chuck",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Insert an R code chuck",
    "text": "Insert an R code chuck\nInsert a code chunk\n\nInsert code chunk"
  },
  {
    "objectID": "slides/01_introduction.html#write-your-first-line-of-coding",
    "href": "slides/01_introduction.html#write-your-first-line-of-coding",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Write your first line of coding",
    "text": "Write your first line of coding\nClick here or the qr code below to write your first line of code\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/01_introduction.html#what-if-it-breaks",
    "href": "slides/01_introduction.html#what-if-it-breaks",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "What if it breaks?",
    "text": "What if it breaks?\nUse the QR code below or click here.\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_02.html#why",
    "href": "slides/lect_02.html#why",
    "title": "Lec 2 - The here package and adding your own data",
    "section": "Why?",
    "text": "Why?\nToday we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")"
  },
  {
    "objectID": "slides/lect_02.html#including-your-own-data",
    "href": "slides/lect_02.html#including-your-own-data",
    "title": "Lec 2 - The here package and adding your own data",
    "section": "Including your own data",
    "text": "Including your own data\nTo add data to your directory, first create a folder that\n\nFigure @ref(fig:3) Adding a folder.and name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R."
  },
  {
    "objectID": "slides/lect_02.html#importing-data",
    "href": "slides/lect_02.html#importing-data",
    "title": "Lec 2 - The here package and adding your own data",
    "section": "Importing data",
    "text": "Importing data\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "documents/about_R.html",
    "href": "documents/about_R.html",
    "title": "About R",
    "section": "",
    "text": "The R programming language was first released on [29 February 2000](https://www.hermetic.ch/y2k/feb29.htm). [Ross Ihaka](https://en.wikipedia.org/wiki/Ross_Ihaka) and [Robert Gentleman](https://en.wikipedia.org/wiki/Robert_Gentleman_(statistician)) wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. [R is now an internationally recognized language used all over the world](https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html). It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on [CRAN](https://cran.r-project.org/)."
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Department of Data Science and Statistics at Wharton go to the UPDATE website, UPDATE."
  },
  {
    "objectID": "ae/ae-0-movies.html",
    "href": "ae/ae-0-movies.html",
    "title": "Movie budgets and revenues",
    "section": "",
    "text": "Important\n\n\n\nThis application exercise is a demo only. You do not have a corresponding repository for it and you’re not expected to turn in anything for it.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB)."
  },
  {
    "objectID": "ae/ae-0-movies.html#data",
    "href": "ae/ae-0-movies.html#data",
    "title": "Movie budgets and revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies <- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies\n\n# A tibble: 7,668 × 15\n   name   rating genre  year released score  votes director writer star  country\n   <chr>  <chr>  <chr> <dbl> <chr>    <dbl>  <dbl> <chr>    <chr>  <chr> <chr>  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.2 e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.3 e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# … with 7,658 more rows, and 4 more variables: budget <dbl>, gross <dbl>,\n#   company <chr>, runtime <dbl>\n\n\nThe ___ dataset has ___ observations and ___ variables."
  },
  {
    "objectID": "ae/ae-0-movies.html#analysis",
    "href": "ae/ae-0-movies.html#analysis",
    "title": "Movie budgets and revenues",
    "section": "Analysis",
    "text": "Analysis\n\nGross over time\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list <- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\nThen, we will filter for these genres and visualize the average gross revenue over time.\n\nmovies %>%\n  filter(genre %in% genre_list) %>% \n  group_by(genre,year) %>%\n  summarise(avg_gross = mean(gross)) %>%\n  ggplot(mapping = aes(x = year, y = avg_gross, color= genre)) +\n    geom_point() + \n    geom_line() +\n    scale_color_viridis_d() +\n    scale_y_continuous(labels = label_dollar()) +\n    labs(\n      x = \"Year\",\n      y = \"Average Gross Revenue (US Dollars)\",\n      color = \"Genre\",\n      title = \"Gross Revenue Over Time\"\n    )\n\n`summarise()` has grouped output by 'genre'. You can override using the\n`.groups` argument.\n\n\nWarning: Removed 47 rows containing missing values (geom_point).\n\n\nWarning: Removed 23 row(s) containing missing values (geom_path).\n\n\n\n\n\nThe plot suggests …\n\n\nBudget and gross\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies %>%\n  filter(genre %in% genre_list, budget > 0) %>% \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d() +\n  labs(\n    x = \"Log-transformed Budget\",\n    y = \"Log-transformed Gross Revenue\"\n  )\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 35 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 35 rows containing missing values (geom_point)."
  },
  {
    "objectID": "ae/ae-0-movies.html#exercises",
    "href": "ae/ae-0-movies.html#exercises",
    "title": "Movie budgets and revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nIn the remaining time, discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)?"
  },
  {
    "objectID": "ae/ae-0-movies.html#appendix",
    "href": "ae/ae-0-movies.html#appendix",
    "title": "Movie budgets and revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies %>% \n  distinct(genre) %>%\n  arrange(genre) %>% \n  datatable()"
  },
  {
    "objectID": "ae/ae-0-first_line_of_code.html",
    "href": "ae/ae-0-first_line_of_code.html",
    "title": "Introduction to the diamonds dataset",
    "section": "",
    "text": "Scenario\nYou own a jewelry business and are working to price your diamonds. To facilitate, you explore the diamond dataset in R and pay special attention to the cost of the diamond. Let’s explore together.\nTo accomplish this, please paste each line of code into your RStudio instance, and answer the accompanying questions.\n\n\nCoding basics\nGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread.\n\nWhen writing code, load all libraries first.\n“##” is used to write comments in R and should be used to justify next steps and anything unusual or unexpected steps\nComments are really important and are notes to your future self to remind you about steps that you took and decisions that you made.\n\n\n## loading library\nlibrary(tidyverse) # for data analysis and visualisation\n\n\n\nData\nThe diamonds dataset includes basic information about 53940 diamonds including price and other characteristics.\n\n## View the dataset in a separate tab\nglimpse(diamonds)\n\nThe ___ dataset has ___ observations and ___ variables.\n\n## What are the variables in this dataset?\n?diamonds\n\n\nWhat do the “4 c’s” of every diamond mean? What kind of variables are they? (hint: This video may help, copy this into your notes under the title data types)\n\nggplot is an R package that is used to create data visualizations. We will be using it throughout this course. The basic format for every ggplot command is:\n\n## DO NOT COPY INTO YOUR QUARTO DOCUMENT\n## THIS IS TO SHOW YOU THE BASIC FORMAT OF ALL ggplots\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\n\n\n## What is the distribution of price?\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price), binwidth = 1) \n\n\nWhat kind of variable is price? What happens if you draw a histogram with another kind of variable?\n\n\n## What happens if you draw a histogram with a different type of variable?\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = OTHER_VAR), binwidth = 1) \n\n\nWhat does the binwidth in the geom_histogram() function do? (hint: draw multiple plots changing this value) What binwidth value is most appropriate for this data?\n\n\n## Find an appropriate binwidth\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price), binwidth = OTHER_VALUE) \n\nThe distribution of diamond prices is right skewed (long right tail).\n\nIn your notes, copy these histograms and the words used to describe them.\n\nOne interesting feature of this graph is the dip in diamonds priced at about $1000. Let’s explore this a little further and look at some basic dplyr commands.\nThe pipe operator “%>%” tells R to take the output from one function and sends it to the input in the next function.\n\n## Filtering on price\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% \n  View()\n\n\nWhat does the filter function do?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  View()\n\n\nWhat does this “%/%” operator do? (hint: run 10 %/% 3, 10 %/% 5, 7 %/% 3, 7 %/% 5 in the console)\nWhat does the mutate function do? (hint: pay special attention to the dimensions of the data)\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  View()\n\n\nWhat does the select function do?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  count(price_hundred) %>% ## Count\n  View()\n\n\nCan you identify the values where the dip is using the information above? Why or why not?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  mutate(price_remainder = price %% 100) %>% ## Finding price_remainder\n  count(price_hundred, price_remainder) %>% ## Count\n  View()\n\n10. What does the “%%” operator do?\n\nCan you identify the values where the dip is using the information above? Why or why not?\n\nCut may impact upon price\n\n## Cut and price\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price, color = cut, fill = cut),\n                 binwidth = 100) \n\n\nWhich cut do you suspect is the most common in the dataset? How many diamonds with that cut are in the dataset?\n\n\n## Most common cute\ndiamonds %>% \n  INSERT_FUNCTION_HERE(cut)\n\n\nThe variables color or clarity might impact upon the price. Draw a histogram and color it using one of them.\n\n\n## Impact of color and clarity\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price, color = VAR_NAME, \n                               fill = VAR_NAME), \n                 binwidth = YOUR_BIN_WIDTH) \n\n\nWhat do the fill and color inputs do in the above coding?\nWhat kind of variables should we use for the fill and color inputs? What happens if another type of variable is used?\n\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_histogram(mapping = aes(x = price, color = VAR_NAME, \n                                   fill = VAR_NAME), \n                     binwidth = YOUR_BIN_WIDTH) \n\nSo far we have been looking at only 1 continuous variable. To look at two continous variables, we draw scatterplots.\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_point(mapping = aes(x = price, y = depth)) \n\n\nWhat kinds of variables do you think you could use to color this plot? Please use an appropriate variable from diamonds dataset and do so.\n\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_point(mapping = aes(x = price, y = depth))"
  },
  {
    "objectID": "ae/ae-0-first_line_of_code.html#exercises",
    "href": "ae/ae-0-first_line_of_code.html#exercises",
    "title": "Introduction to the diamonds dataset",
    "section": "Exercises",
    "text": "Exercises\n\nWhat do the “4 c’s” of every diamond mean? What kind of variables are they? (hint: This video may help)\nWhat do the inputs (stackratio, alpha, and stadir) in the geom_dotplot() function do? (hint: draw multiple plots changing the values)\nBased upon the above plot, how much should your charge for your diamonds? Why?"
  },
  {
    "objectID": "course-syllabus.html#lectures",
    "href": "course-syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nThe goal of the lectures is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded. In addition to application exercises will be periodic activities to help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. If you are in need of a loaner laptop please seek support here."
  },
  {
    "objectID": "course-syllabus.html#name-tags",
    "href": "course-syllabus.html#name-tags",
    "title": "Syllabus",
    "section": "Name tags",
    "text": "Name tags\nEvery one of you are important to me. To facilitate interactions, I would like to learn your names. To help with this, please wear name tags in class that include pronouns so that I can call you by your name and begin to connect with each of you."
  },
  {
    "objectID": "slides/01_introduction.html#text",
    "href": "slides/01_introduction.html#text",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Text",
    "text": "Text"
  },
  {
    "objectID": "slides/01_introduction.html#workspace-image",
    "href": "slides/01_introduction.html#workspace-image",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Workspace image",
    "text": "Workspace image\n\nSaving workspace"
  },
  {
    "objectID": "slides/01_introduction.html#rainbow-parenthesis",
    "href": "slides/01_introduction.html#rainbow-parenthesis",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Rainbow parenthesis",
    "text": "Rainbow parenthesis\n\nParenthesis are important"
  },
  {
    "objectID": "slides/01_introduction.html#code-font",
    "href": "slides/01_introduction.html#code-font",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Code font",
    "text": "Code font\n\nUpdate background and font color of code"
  },
  {
    "objectID": "slides/01_introduction.html#panel-layout",
    "href": "slides/01_introduction.html#panel-layout",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Panel layout",
    "text": "Panel layout\n\nUpdate options"
  },
  {
    "objectID": "slides/01_introduction.html#another-attempt",
    "href": "slides/01_introduction.html#another-attempt",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Another attempt",
    "text": "Another attempt\n{background-image=“https://www.purina.com.au/-/media/project/purina/main/breeds/dog/dog_boston-terrier_desktop.jpg?h=475&la=en&w=825&hash=DC3F38D08CCE086118327D827C002A62” background-size=“cover”}"
  },
  {
    "objectID": "slides/01_introduction.html#text-background-image-httpsgithub.comstats1010-f22websiteblobmainslideslec_1_imageswitten_cs.png-background-sizecover",
    "href": "slides/01_introduction.html#text-background-image-httpsgithub.comstats1010-f22websiteblobmainslideslec_1_imageswitten_cs.png-background-sizecover",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Text {background-image= “https://github.com/stats1010-f22/website/blob/main/slides/lec_1_images/witten_CS.png” background-size=“cover”}",
    "text": "Text {background-image= “https://github.com/stats1010-f22/website/blob/main/slides/lec_1_images/witten_CS.png” background-size=“cover”}"
  },
  {
    "objectID": "slides/01_introduction.html#pane-layout",
    "href": "slides/01_introduction.html#pane-layout",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Pane layout",
    "text": "Pane layout\n\nUpdate panes and their layout"
  },
  {
    "objectID": "course-support.html#lectures",
    "href": "course-support.html#lectures",
    "title": "Course support",
    "section": "Lectures",
    "text": "Lectures\nIf you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-canvas",
    "href": "course-support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas, Gradescope, or Zoom, contact Wharton Student Computing. You can also access the self-service help documentation for Zoom here, Canvas here, and for Gradescope here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-2.html#participate",
    "href": "weeks/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 2"
  },
  {
    "objectID": "weeks/week-2.html#practice",
    "href": "weeks/week-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\n📋 diamonds"
  },
  {
    "objectID": "weeks/week-2.html#perform",
    "href": "weeks/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html",
    "href": "ae/ae-1-dcbikeshare.html",
    "title": "AE 02: Bike rentals in DC",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-1-dcbikeshare-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#bike-rentals-in-dc",
    "href": "ae/ae-1-dcbikeshare.html#bike-rentals-in-dc",
    "title": "AE 02: Bike rentals in DC",
    "section": "Bike rentals in DC",
    "text": "Bike rentals in DC\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#data",
    "href": "ae/ae-1-dcbikeshare.html#data",
    "title": "AE 02: Bike rentals in DC",
    "section": "Data",
    "text": "Data\nOur dataset contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare <- read_csv(\"data/dcbikeshare.csv\")"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#daily-counts-and-temperature",
    "href": "ae/ae-1-dcbikeshare.html#daily-counts-and-temperature",
    "title": "AE 02: Bike rentals in DC",
    "section": "Daily counts and temperature",
    "text": "Daily counts and temperature\n\nExercise 1\nVisualize the distribution of daily bike rentals and temperature as well as the relationship between these two variables.\n\nggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250)\n\n\n\nggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point()\n\n\n\n\n\n\nExercise 2\nDescribe the distribution of daily bike rentals and the distribution of temperature based on the visualizations created in Exercise 1. Include the shape, center, spread, and presence of any potential outliers.\n[Add your answer here]\n\n\nExercise 3\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day.\n[Add your answer here]\n\n\nExercise 4\nDescribe the relationship between daily bike rentals and temperature based on the visualization created in Exercise 1. Comment on how we expect the number of bike rentals to change as the temperature increases.\n[Add your answer here]\n\n\nExercise 5\nSuppose you want to fit a model so you can use the temperature to predict the number of bike rentals. Would a model of the form\n\\[\\text{count} = \\beta_0 + \\beta_1 ~ \\text{temp\\_orig} + \\epsilon\\]\nbe the best fit for the data? Why or why not?\nNo."
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#daily-counts-temperature-and-season",
    "href": "ae/ae-1-dcbikeshare.html#daily-counts-temperature-and-season",
    "title": "AE 02: Bike rentals in DC",
    "section": "Daily counts, temperature, and season",
    "text": "Daily counts, temperature, and season\n\nExercise 6\nIn the raw data, seasons are coded as 1, 2, 3, 4 as numerical values, corresponding to winter, spring, summer, and fall respectively. Recode the season variable to make it a categorical variable (a factor) with levels corresponding to season names, making sure that the levels appear in a reasonable order in the variable (i.e., not alphabetical).\n\n# add code developed during livecoding here\n\n\n\nExercise 7\nNext, let’s look at how the daily bike rentals differ by season. Let’s visualize the distribution of bike rentals by season using density plots. You can think of a density plot as a “smoothed out histogram”. Compare and contrast the distributions. Is this what you expected? Why or why not?\n\n# add code developed during livecoding here\n\n[Add your answer here]\n\n\nExercise 8\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, first create a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here\n\n\n\nExercise 9\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#modeling",
    "href": "ae/ae-1-dcbikeshare.html#modeling",
    "title": "AE 02: Bike rentals in DC",
    "section": "Modeling",
    "text": "Modeling\n\nExercise 10\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here\n\n\n\nExercise 11\nUsing the data you filtered in Exercise 10, fit a linear model for predicting daily bike rentals from temperature for this season.\n\n# add code developed during livecoding here\n\n\n\nExercise 12\nUse the output to write out the estimated regression equation.\n[Add your answer here]\n\n\nExercise 13\nInterpret the slope in the context of the data.\n[Add your answer here]\n\n\nExercise 14\nInterpret the intercept in the context of the data.\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#synthesis",
    "href": "ae/ae-1-dcbikeshare.html#synthesis",
    "title": "AE 02: Bike rentals in DC",
    "section": "Synthesis",
    "text": "Synthesis\n\nExercise 15\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2022. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?\n[Add your answer here]\n\nThe following exercises will be completed only if time permits.\n\n\nExercise 16\nPick another season. Based on the visualization in Exercise 8, would you expect the slope of the relationship between temperature and daily bike rentals to be smaller or larger than the slope of the model you’ve been working with so far? Explain your reasoning.\n[Add your answer here]\n\n\nExercise 17\nFor this season you picked in Exercise 16, fit a linear model for predicting daily bike rentals from temperature. Note, you will need to filter your data for this season first. Use the output to write out the estimated regression equation and interpret the slope and the intercept of this model.\n\n# add your code here\n\n[Add your answer here]"
  },
  {
    "objectID": "slides/here_lecture.html#why",
    "href": "slides/here_lecture.html#why",
    "title": "Here lecture",
    "section": "Why?",
    "text": "Why?\nToday we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")"
  },
  {
    "objectID": "slides/here_lecture.html#including-your-own-data",
    "href": "slides/here_lecture.html#including-your-own-data",
    "title": "Here lecture",
    "section": "Including your own data",
    "text": "Including your own data\nTo add data to your directory, first create a folder that\n\nFigure @ref(fig:3) Adding a folder.and name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R."
  },
  {
    "objectID": "slides/here_lecture.html#importing-data",
    "href": "slides/here_lecture.html#importing-data",
    "title": "Here lecture",
    "section": "Importing data",
    "text": "Importing data\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_04.html#definition-of-numerical-variable",
    "href": "slides/lect_04.html#definition-of-numerical-variable",
    "title": "Lec 4 - Exploring numerical data",
    "section": "Definition of numerical variable",
    "text": "Definition of numerical variable\nA numerical or quantitative variable is a variable that can be measured."
  },
  {
    "objectID": "slides/lect_04.html#the-purpose-of-exploratory-data-analysis-eda",
    "href": "slides/lect_04.html#the-purpose-of-exploratory-data-analysis-eda",
    "title": "Lec 4 - Exploring numeric data",
    "section": "The purpose of Exploratory Data Analysis (EDA)",
    "text": "The purpose of Exploratory Data Analysis (EDA)\n\nEDA is about learning the structure of a dataset through a series of numerical and graphical techniques.\nWhen you do EDA, you’ll look for both\n\ngeneral trends and\ninteresting outliers in your data.\n\n\ngenerate questions that will help inform subsequent analysis."
  },
  {
    "objectID": "ae/ae-5.html",
    "href": "ae/ae-5.html",
    "title": "The birthday simulation (AE-5)",
    "section": "",
    "text": "Computers let you assemble, manipulate, and visualize data sets, all at speeds that would have wowed yesterday’s scientists. In short, computers give you superpowers! But if you wish to use them, you’ll need to pick up some programming skills. Steve Job said that “computers are bicycles for our minds” because the efficiency rating of humans on bicycles is so incredible, and computers give us similar powers.\nOne reason computers are so incredible is that they allow us to simulate a multitude of events. Today we will simulate the probability that two of you in this section of Stat1010 have the same birthdays.\n\nlibrary(tidyverse) # for data manipulation\nlibrary(vctrs) # to find the length of a tibble\n\nSuppose you are in a classroom with 100 people. If we assume this is a randomly selected group of 100 people, what is the chance that at least two people have the same birthday? Although it is somewhat advanced, we can deduce this mathematically. We will do this later. Here we use a Monte Carlo simulation. For simplicity, we assume nobody was born on February 29. This actually doesn’t change the answer much.\nFirst, note that birthdays can be represented as numbers between 1 and 365, so a sample of 100 birthdays can be obtained like this:\n\nall_bdays <- as_tibble(1:365) # data from where we can sample\n\nbdays_class <- \n  all_bdays %>% # data from where to sample\n  sample_n(size = 100, replace = TRUE) # sample of size 100 with replacement\n\nTo check if in this particular set of 100 people we have at least two with the same birthday, we can use the functions group_by and filter, which returns a tibble with a vector of duplicated dates. Here is an example:\n\nbdays_class %>% \n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) # those have more than 1\n\nTo estimate the probability of a shared birthday in the group, we repeat this experiment by sampling sets of 100 birthdays over and over. Prior to replicating, we need to write this as a function.\n\nbdays_dups <- \n  all_bdays %>% # data from where to sample\n  sample_n(size = 100, replace = TRUE) %>% # take a sample of size 100\n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) %>% # those have more than 1\n  vec_size(.) # the number that are duplicated\n\nA function has an input (in this case \\(n\\))\n\nWhat does \\(n\\) represent in this coding?\n\n\nnum_of_same_birthdays <- function(n){\n  all_bdays %>% # data from where to sample\n  sample_n(size = n, replace = TRUE) %>% # take a sample\n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) %>% # those have more than 1\n  vec_size(.) # the number that are duplicated\n}\n\nTo run this function, we do this:\n\nnum_of_same_birthdays(10) # run the function\n\n\nHow many students are there in class today?\nRun the coding above but include the number of students in class today.\n\nThe law of large numbers says that if we do this many times we should have an estimate of the number of people that have the same birthdays in class today. The function replicate can be used to run functions multiple times.\n\nB <- 10000 # the number of times to run\nresults <- replicate(B, # replicate this number of times\n          num_of_same_birthdays(INSERT)) # our function\n\nmean(results) # take the mean\n\nWere you expecting the probability to be this high?\nPeople tend to underestimate these probabilities. To get an intuition as to why it is so high, think about what happens when the group size is close to 365. At this stage, we run out of days and the probability is one.\nSay we want to use this knowledge to bet with friends about two people having the same birthday in a group of people. When are the chances larger than 50%? Larger than 75%?\nLet’s create a look-up table. We can create a function to compute this for any group size. This function runs our function \\(10000\\) times for every value of \\(n\\).\n\ncompute_prob <- # name the function\n  function(n, B = 10000){ # function inputs\n  results <- # store results\n    replicate(B, # run num_of_same_birthdays B times \n              num_of_same_birthdays(n)) # for the value of n\n  \n  mean(results) # find the mean\n}\n\nUsing the function map_dbl, we can perform element-wise operations on any function. Note that this may take awhile to run.\n\nn <- seq(1, 60) # which values of n are important\nprob <- # save the results as prob\n  map_dbl(n,  # for each value of n \n          compute_prob) # run the function\n\nWe can now make a plot of the estimated probabilities of two people having the same birthday in a group of size n:\n\nas_tibble(n, prob) %>% # the format for ggplot\n  ggplot() + # draw a graph\n  geom_point(aes(x = n, y = prob)) # of points\n\nNow let’s compute the exact probabilities rather than use Monte Carlo approximations. Not only do we get the exact answer using math, but the computations are much faster since we don’t have to generate experiments.\nTo make the math simpler, instead of computing the probability of it happening, we will compute the probability of it not happening, or the compliment. For this, we use the multiplication rule.\nLet’s start with the first person. The probability that person 1 has a unique birthday is 1. The probability that person 2 has a unique birthday, given that person 1 already took one, is 364/365. Then, given that the first two people have unique birthdays, person 3 is left with 363 days to choose from. We continue this way and find the chances of all \\(n\\) people having a unique birthday is:\n\\[1×\\frac{364}{365}×\\frac{363}{365}…\\frac{365−n+1}{365}\\]\nWe can write a function that does this for any number:\n\nexact_prob <- function(n){\n  1 - \n    prod(365:(365-25+1))/ # the product from the numerator above\n    365^(25) # the denominator from above\n}\n\n\nRun this coding for the number of people that are in class today.\n\nNow, we run this on multiple values of \\(n\\)\n\neprob <- map_dbl(n, exact_prob) # run on multiple values of n\n\nNext we plot the results.\n\nas_tibble(n, eprob) %>% # the format for ggplot\n  ggplot() + # draw a graph\n  geom_point(aes(x = n, y = eprob)) # of points\n\nOn mercury, the year is only 88 days. Update the coding above to simulate the expected number of people with the same birthdays on Mercury.\nAssuming we have the same number of people, would you expect the number of people with the same birthdays to be higher or lower than those on earth?"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "📖 Read chapter 14 of Introduction to Data Science\n📖 Read chapter 2 of Probability, Statistics, and Data: A fresh approach using R"
  },
  {
    "objectID": "weeks/week-4.html#participate",
    "href": "weeks/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 5\n🖥️ Lecture 6"
  },
  {
    "objectID": "weeks/week-4.html#practice",
    "href": "weeks/week-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\n📋 Exploring probabilities\n📋 The birthday simulation"
  },
  {
    "objectID": "weeks/week-4.html#perform",
    "href": "weeks/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test - week 3\n✍️ HW 1 - Titanic\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "📖 Read chapter 4 of Introduction to Modern Statistics\n📖 Read chapter 5 of Introduction to Modern Statistics"
  },
  {
    "objectID": "weeks/week-3.html#participate",
    "href": "weeks/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 3\n🖥️ Lecture 4"
  },
  {
    "objectID": "weeks/week-3.html#practice",
    "href": "weeks/week-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\n📋 Exploring qualitative variables\n📋 Exploring numeric variables"
  },
  {
    "objectID": "weeks/week-3.html#perform",
    "href": "weeks/week-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test - week 3\n✍️ HW 6 - Statistics Experience\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "hw/hw-6.html",
    "href": "hw/hw-6.html",
    "title": "HW 6 - Statistics Experience",
    "section": "",
    "text": "The world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience\n2️⃣ Make a slide summarizing on your experience\nYou must complete both parts to receive credit."
  },
  {
    "objectID": "hw/hw-6.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/hw-6.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "HW 6 - Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professional in industry, a speaker from the RLadies directory, or other local data science groups.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\nrstudio::conf 2022\nrstudio::global 2021 talks\nrstudio::conf 2020 talks\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask your professor if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team. Kaggle and Drivendata both lead online competitions. More information to follow here or here.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask your professor to make sure it counts toward the experience. Many of these books are available through the Van Pelt Library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some don’t by Nate Silver\nHow Charts Lie by Alberto Cairo\nList of books about data science ethics\n\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a project for your TidyTuesday submission - The Quarto file with all the code needed to reproduce your visualization. - A pdf that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n✅ The visualization should include features or customization that are beyond what we’ve done in class ."
  },
  {
    "objectID": "hw/hw-6.html#part-2-summarize-your-experience",
    "href": "hw/hw-6.html#part-2-summarize-your-experience",
    "title": "HW 6 - Statistics Experience",
    "section": "Part 2: Summarize your experience",
    "text": "Part 2: Summarize your experience\nMake one slide summarizing your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nName and brief description of the event/podcast/competition/etc.\nSomething you found new, interesting, or unexpected\nHow the event/podcast/competition/etc. connects to something we’ve done in class.\nCitation or link to web page for event/competition/etc.\n\nClick here to see a template to help you get started on your slide. Your slide does not have to follow this exact format; it just needs to include the information mentioned above and be easily readable (i.e. use a reasonable font size!). Creativity is encouraged!"
  },
  {
    "objectID": "hw/hw-6.html#submission",
    "href": "hw/hw-6.html#submission",
    "title": "HW 6 - Statistics Experience",
    "section": "Submission",
    "text": "Submission\nSubmit the reflection as a PDF under the HW 6 - Statistics Experience assignment on Gradescope by Tuesday, Nov 22 at 5 pm ET. It must be submitted by the deadline on Gradescope to be considered for grading."
  },
  {
    "objectID": "hw/hw-1.html",
    "href": "hw/hw-1.html",
    "title": "HW 1 - Titanic dataset",
    "section": "",
    "text": "For this homework assignment we will be exploring the Titanic dataset.\n\n\nIn this assignment, you will…\n\nDownload and import data into R\nExplore categorical variables\nCompute the expected counts of a \\(\\chi^2\\) distribution and\nPerform a \\(\\chi^2\\) test on some variables"
  },
  {
    "objectID": "hw/hw-1.html#getting-started",
    "href": "hw/hw-1.html#getting-started",
    "title": "HW 1 - Titanic dataset",
    "section": "Getting started",
    "text": "Getting started\n\nLog in to RStudio\nClick on your Stat1010.Rproj.\nGo to File ➛ New File ➛ Quarto Document and name the document hw-1 click create"
  },
  {
    "objectID": "hw/hw-1.html#packages",
    "href": "hw/hw-1.html#packages",
    "title": "HW 1 - Titanic dataset",
    "section": "Packages",
    "text": "Packages\nThe following packages will be used in this assignment:\n\nlibrary(tidyverse) # for data manipulation and data visualization\nlibrary(here) # to organize files"
  },
  {
    "objectID": "hw/hw-1.html#data-titanic",
    "href": "hw/hw-1.html#data-titanic",
    "title": "HW 1 - Titanic dataset",
    "section": "Data: Titanic",
    "text": "Data: Titanic\nOn April 15, 1912, the largest passenger liner ever made collided with an iceberg during her maiden voyage. When the Titanic sank it killed 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck resulted in such loss of life wasthat there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others.\nThe titanic.csv file contains data for 887 of the real Titanic passengers. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their passenger-class, their sex, and the fare they paid\n\nPclass: The class of passengers on the titanic, with \\(1st\\) being the highest class, and \\(3rd\\) the lowest.\nSurvived: A variable that records whether or not a passenger survived the sinking of the titanic.\n\nPart 1: Download and import the data\n\nDownload the file into your Stat1010 R project in the data folder.\nImport your data into R.\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document to ensure that the data loads without errors.\n\n\nPart 2: Exploring categorical variables\n\nHow many observations and how many variables in this dataset?\nClassify all the variables into two categories: qualitative or quantitative\nHow many levels of passenger class are there in the variable?\nHow many passengers survived the sinking of the titanic?\nMake a contingency table of class and survival. Which combination of class and survival is the most common?\n\nWhat proportion of \\(3rd\\) class passengers survived?\nWhat proportion of \\(1st\\) class passengers survived?\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document.\n\n\n\nDraw a plot that conditions on class and displays the proportions of each that survived and update labels. What does the plot suggest regarding the chance of survival and your class? Does it suggest that they are associated?\nAssuming Survived and Pclass are independent, write R coding to find the expected counts for all cells of the contingency table. (Hint: you will need to use the rowSums(.[2:3]) and colSums(.[2:4]) functions, depending on the order that you compute the two.)\nPerform a \\(\\chi^2\\) test on the two variables Survived and Pclass. Include both \\(H_0\\) and \\(H_A\\) and interpret the \\(p-value\\). What conclusions can you draw about the independence of Survived and Pclass?\n\n\n\n\n\n\n\nWarning\n\n\n\nBefore submitting, make sure you render your document,"
  },
  {
    "objectID": "hw/hw-1.html#submission",
    "href": "hw/hw-1.html#submission",
    "title": "HW 1 - Titanic dataset",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nThen submit the pdf following the link on the course website."
  },
  {
    "objectID": "hw/hw-1.html#grading",
    "href": "hw/hw-1.html#grading",
    "title": "HW 1 - Titanic dataset",
    "section": "Grading",
    "text": "Grading\nTotal points available: 25 points.\n\n\n\nComponent\nPoints\n\n\n\n\nPart 1 Qu 1\n2\n\n\nPart 1 Qu 2\n3\n\n\nPart 2 Qu 1\n2\n\n\nPart 2 Qu 2\n2\n\n\nPart 2 Qu 3\n1\n\n\nPart 2 Qu 4\n2\n\n\nPart 2 Qu 5 Pt 1\n1\n\n\nPart 2 Qu 5 Pt 2\n1\n\n\nPart 2 Qu 6\n3\n\n\nPart 2 Qu 7\n4\n\n\nPart 2 Qu 8\n4"
  },
  {
    "objectID": "ae/ae-2-exploring-categorical-vars.html",
    "href": "ae/ae-2-exploring-categorical-vars.html",
    "title": "Exploring categorical data AE-2",
    "section": "",
    "text": "Load packages, data\n\n## loading libraries\nlibrary(tidyverse) # for data analysis and visualisation\nlibrary(here) # to organize files\nlibrary(praise) # for ocassional good vibes!\n\nLet’s look at the data on the web prior to importing it and also to ensure that we know what it should look like when it is imported into R.\nNow press “raw”\n\nThen copy the url:\n\nDownload the file by inserting the URL below:\n\nfs::dir_create(here(\"data\")) # create a data folder \ndownload.file(\n  url = URL_HERE, # url of file to download\n  destfile = here(\"data/comics.csv\") # directory/name_of_file\n)\n\nThen click on the data folder in the “Files” panel.\n\nDouble click on “comics.csv” and click on “Import Dataset…”\n\nCheck the data in the “Data Preview” pane and ensure that it looks as it should.\n\nNext, click on the clipboard icon to copy the code from the “Code Preview” pane, then click “Import”.\n\n#PASTE THE CODE FROM \"Code Preview\" HERE\n\n\n\nData\nThe comics dataset includes basic information scraped from the superheroDb for a kaggle competition.\n\n## An overview of the dataset and type of variables\nglimpse(comics)\n\nThe first superhero is named “A-Bomb” he is male, with yellow eyes, human, with no hair. Marvel Comics created him and his skin color is not listed, but his height and weight are.\n\nAre there any differences between the data on the website above and the one in R? What are they? (Hint: which function can you use to see the whole dataset?)\n\npraise()\n\nThe ___ dataset has ___ observations and ___ variables.\nClassify all variables in the dataset as either: quantitative discrete, quantitative continuous, qualitative nominal, qualitative ordinal. Which of these variables is also categorical?\n\n\n\nCounts\n\nHow many publishers are there in this dataset?\n\ncomics %>% \n  distinct(Publisher) # finds the levels of publisher\n\nHow many levels of the variable Alignment are there in this dataset?\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\n\nA common way to represent the number of cases that fall into each combination of levels of two categorical variables, such as these, is with what’s called a “contingency table.” Note that each superhero appears in exactly one cell, statisticians call this mutually exclusive.\n\npraise()\n\n\nWhich is the most common category in this contingency table? How many superheros are in that category? (note: please look at both of the next two blocks of code.)\n\ncomics %>% \n  count(Publisher, Alignment) %>% # counts all combinations\n  View()\n\n\nThe long format above is difficult to see clearly. The format we normally use for contingency tables is the wide format.\nThe third line of coding below takes a long table and makes it wide by moving the Alignment variable to the columns, and filling the values of the table with the count variable (n). The names_from argument tells R where the names of the new columns are coming from (i.e. what variable), and the values_from argument tells R where the values in the table are coming from. Here, the values we want in our table are stored as a variable labeled n in our table.\n\ncomics %>% \n  count(Publisher, Alignment) %>%  # counts all combinations\n  pivot_wider(names_from = Alignment, \n              values_from = n) # pivots from long to wide \n\n\nThere are about ___ good superheros for each bad superhero.\n\nggplot(data = comics) + # the dataset\n  geom_bar(mapping = aes(x = Alignment)) # a bar chart of Alignment\n\nLook at the next two plots and find the difference between them. What would make you use one plot over the other? Which plot shows that females are much more likely to be good superheros than bad? Which one shows that good superheros are more likely to be missing gender? And which that females are more likely to be good superheros than males? All of these mean that the variables gender and alignment are associated, the value of one impacts upon the value of the other.\n\nggplot(data = comics) + # add the data\n  geom_bar(mapping = aes(x = Gender, # bar chart of gender\n                         fill = Alignment)) +  # colored by alignment\n  labs(title = \"Gender colored with alignment\") # add title\n\n\nggplot(data = comics) + # add the data\n  geom_bar(mapping = aes(x = Alignment, # bar chart of alignment\n                         fill = Gender)) + # colored by gender\n  labs(title = \"Alignment colored with gender\")  # add title\n\n\nWe note that the commonly held belief that gender is binary is no longer the scientific consensus and that gender is a complex spectrum.\n\nStatisticians want to discuss the strength of association of variables. They want to ensure that this association is not the result of random noise, but instead is a function of the underlying population of interest (all superheros).\n\npraise()\n\n\n\nChi-Squared test\nTo test for independence in 2 categorical variables, statisticians use a Chi-squared test. This is a hypothesis test so it has both a null hypothesis (\\(H_0\\)) and an alternative hypothesis (\\(H_A\\)).\n\\(H_0\\) = the variables are independent, there is no relationship between the two categorical variables.\n\\(H_A\\) = Knowing the value of one variable helps to predict the value of the other variable\nJust like a fair court case, where a defendant is assumed to be innocent until proven guilty, here we assume \\(H_0\\) until proven otherwise. The proof that we present at the case is a formula relating the actual values in our sample to what we would expect to get under the independence assumption.\nTo perform a Chi-squared test of independence on gender and alignment we must find the marginal distributions of both gender and alignment.\n\n\nMarginal distribution\n\nThe marginal distribution is the count of each variable.\n\ncomics %>% \n  count(Alignment, Gender) %>% \n  pivot_wider(names_from = Alignment, \n              values_from = n)\n\n\nWe take the original two-way table (with two categorical variables) and added up the cells across each level of align (ie \\(1+7+19+2 = 29\\)) to get the marginal distribution for each variable.\n\ncomics %>% # the dataset\n  count(Gender) # and marginal distribution of gender\n\n\npraise()\n\n\ncomics %>% # the dataset\n  count(Alignment) # and marginal distribution of the Alignment\n\nIf these are independent, we would expect \\(\\frac{200}{29+200+505}\\) of the \\(207\\) (about \\(56.4\\)) bad superheros to be female, and the same proportion of \\(496\\) (about \\(135.1\\)) good superheros to be female, and so on.\n\nAssuming independence of Alignment and Gender, how many good superheros would we expect to be male? (hint: use the “$$” to make\\(\\frac{1}{2}\\))\n\nMore information, including mathematical notation can be found here.\nFortunately, `R` does all of this for us.\n\n# the \"$\" sign pulls out the Gender values and Alignment value from the comics dataset\nchisq.test(comics$Gender, comics$Alignment)\n\nWe get a warning because the missing values (“-”) expected counts are probably quite small. You can safely use the chi-square test with critical values from the chi-square distribution when no more than 20% of the expected counts are less than \\(5\\) and all individual expected counts are 1 or greater. In particular, all four expected counts in a \\(2 \\times 2\\) table should be 5 or greater.\n\npraise()\n\nThe \\(p-value\\) for this test \\(0.0003298\\) is very small which means that we have very strong evidence against \\(H_0\\) — that there is independence between Alignment and Gender — and we can reject the null hypothesis. This suggests that the association between Gender and Alignment is not likely due to chance.\n\nThere are a few characters with missing data “-” in the Alignment and Gender variables? How many are in each?\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\nSince there are only a few missing values (<10%) in each category, there is no reason to keep them especially since our analysis is largely about these two variables.\nWhat does the “!=” operator do?\n\ncomics_filtered <- # assign a name to a new dataset\n  comics %>% # tell R which dataset to start with\n  INSERT_FUNCTION(Alignment != \"-\", # remove \"-\" values in Alignment\n                  Gender != \"-\") # remove \"-\" values in Gender\n\nRemake the “Alignment colored with gender” plot and the “Gender colored with alignment” plots with this new dataset.\nRedo the Chi-Squared test for independence between Alignement and Gender. Include all hypotheses, and computations for at least \\(2\\) expected values. Does this change our conclusion?\n\npraise()\n\nSide-by-side barcharts allow us to represent the counts from a contingency table graphically. Telling R to make a side-by-side barchart involves adding the words position = \"dodge” to the coding from above. Now created the other bar chart side-by-side, the “Gender colored with alignment.” use the comics_filter dataset.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of alignment\n                         fill = INSERT), # colored by gender\n           position = INSERT) + # side_by_side\n  labs(title = \"Alignment colored with gender\")  # add title\n\n\n\n\nProportions\nWe have been focusing mostly on counts. Proportional data is also interesting to explore and it is easy to get R to produce those for us.\n\nWhat combination of Gender and Alignment has the highest proportion? What is the value? What is the sum of all of the proportions in the table below? (Note: Use the View() function to go through each line of code and ensure you know what each step does.)\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>% # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\n\n\n\nConditional proportions\n\nIf we’re curious about systematic associations between variables, we should look to conditional proportions. An example of a conditional proportion is the proportion of female superheroes that are good. To build a table of these conditional proportions, we need to specify a grouping variable before we calculate the proportions. What proportion of female characters are good? What do the rows sum to? (Note: Use the View() function to go through each line of code and ensure you know what each step does.)\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  group_by(Gender) %>% # conditions on gender\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>%  # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\nWhat proportion of good characters are male? What do the columns sum to?\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  group_by(Alignment) %>% # conditions on gender\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>%  # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\n\npraise()\n\nPlotting proportions is similar to the side-by-side bar chart completed earlier. Instead of position = \"dodge\" we use position = \"fill\" . Draw one such plot below using Gender for the x axis and color it using Alignment.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of ?\n                         fill = INSERT), # colored by ?\n           position = INSERT) # fill\n\nNow, change the label of the y axis from count by including the coding\nlabs(y = \"Proportion of superheroes\")\n\npraise()\n\nDoes the above plot condition on gender or alignment? How do you know? (hint: what sums to 1?)\nCondition on the other variable.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of ?\n                         fill = INSERT), # colored by ?\n           position = INSERT)  + # fill\n  lab(y = \"INSERT Y AXIS TITLE HERE\")\n\nAnother way to view the differences in variables is to facet. What is the advantage of a facet plot over a stacked barchart?\n\nggplot(comics) + # which dataset\n  geom_bar(mapping = aes(x = Gender)) + # bar chart of Gender\n  facet_wrap(~Alignment) # broken down by Alignment"
  },
  {
    "objectID": "ae/ae-3.html",
    "href": "ae/ae-3.html",
    "title": "Exploring numerical data (AE-3)",
    "section": "",
    "text": "Important\n\n\n\nThis application exercise is due on 20 Sept at 2:00pm."
  },
  {
    "objectID": "ae/ae-3.html#dotplot",
    "href": "ae/ae-3.html#dotplot",
    "title": "Exploring numerical data (AE-3)",
    "section": "Dotplot",
    "text": "Dotplot\n\nLook at the coding below and one at a time remove each of the dotsize, alpha, and stackdir from the code. What does each of these inputs do? How does each input impact upon the plot?\n\n\nggplot(data = diamonds) + # the data\n  geom_dotplot(mapping = aes(x = price), # plot of price\n               dotsize = 0.005, # make the dots tiny\n               alpha = 0.3, # less opaque\n               stackdir = \"center\") #"
  },
  {
    "objectID": "ae/ae-3.html#dotplot-vs-boxplot",
    "href": "ae/ae-3.html#dotplot-vs-boxplot",
    "title": "Exploring numerical data (AE-3)",
    "section": "Dotplot vs boxplot",
    "text": "Dotplot vs boxplot\nA boxplot provides summary information for the distribution of a variable. Here are some explanations (using different data) showing the purpose of the box portion of the boxplot.\nThe left line of the box is the quartile 1 (\\(Q_1\\)) or Q1 \n\npraise()\n\nThe middle line of the box is the median (\\(Q_2\\)) \nThe right line of the box is the quartile 3 (\\(Q_3\\)) \n\nLooking at the above plots, count the percentage of yellow dots in each of the dotplots. Is there anything interesting about these values?\nCompare and contrast a dotplot and a boxplot? What are the advantages and disadvantages of each? Think carefully about bimodal data and which plot you would use to show that aspect of a variable. Also think about outliers."
  },
  {
    "objectID": "ae/ae-3.html#boxplots",
    "href": "ae/ae-3.html#boxplots",
    "title": "Exploring numerical data (AE-3)",
    "section": "Boxplots",
    "text": "Boxplots\n\nDraw a boxplot of the price data from the diamonds dataset.\n\n\nggplot(data = INSERT) + # the data\n  INSERT(aes(x = INSERT)) # the variable\n\n\nBoxplot descriptions\n\n\nUse the information above to describe the boxplot of price.\n\n\n\nInterquartile range (IQR)\nThe IQR of a variable is the length of the box in a boxplot. \\[ IQR = Q_3 - Q_1\\]\n\npraise()"
  },
  {
    "objectID": "ae/ae-3.html#density-plot",
    "href": "ae/ae-3.html#density-plot",
    "title": "Exploring numerical data (AE-3)",
    "section": "Density plot",
    "text": "Density plot\n\n ggplot(data = diamonds) + # the data\n       geom_density(aes(x = price), # plot of price\n                    bw = 1) # plot of price\n\n\nWhat does the “bw” input in the geom_density function do? What is an appropriate value of “bw” for this data?\n\n\nggplot(data = diamonds) + # the data\n  geom_density(aes(x = price), # plot of price\n               bw = INSERT) + # binwidth\n  facet_wrap(~clarity) # faceting\n\n\nWhat does the above plot suggest about the prices of diamonds for all levels of the variable clarity?\n\n\npraise()\n\n\nDraw a density plot for each value of cut. Describe the distribution of diamond price for each value of cut.\n\n\nggplot(data = diamonds) + # the data\n  geom_density(aes(x = price), # plot of price\n               bw = INSERT) + # binwidth\n  facet_wrap(~INSERT) # faceting"
  },
  {
    "objectID": "ae/ae-3.html#measures-of-center",
    "href": "ae/ae-3.html#measures-of-center",
    "title": "Exploring numerical data (AE-3)",
    "section": "Measures of center",
    "text": "Measures of center\nWe use the summarise() function when we expect the result to be one number.\n\nMean\n\ndiamonds %>% # the dataset\n  summarise(mean = mean(price)) # function that is used to compute mean of price\n\n9, Now compute the means of the variables \\(x\\), \\(y\\), \\(z\\), and \\(carat\\). (hint: You will need to insert a code chunk for each of these variables.)\n\npraise()\n\nLast class we learned about the group_by() and used it to compute conditional probabilities. Today we will use it to compare the means of different subgroups.\n\ndiamonds %>% # the data\n  group_by(cut) %>% # for each value of cut\n  summarise(mean = mean(price), # find the mean\n            median = median(price)) # and the median\n\n\nCompare the average values of price for each level of the cut variable. Considering the distributions of price for each level of cut in question 8, is the grouped mean a good measure of center for each level of cut? Why or why not?\n\n\n\nMedian\n\nHow would you find the overall median of price?"
  },
  {
    "objectID": "ae/ae-3.html#measures-of-spread",
    "href": "ae/ae-3.html#measures-of-spread",
    "title": "Exploring numerical data (AE-3)",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nVariance\nR also computes measures of spread.\n\ndiamonds %>% # the data\n  summarise(var = var(price)) # find the variance\n\nBesides the direct method above, we can also do this computationally, by using the definition and finding the mean, subtracting, and squaring, then dividing.\n\ndiamonds %>% # the data\n  mutate(\n    mean_price = mean(price), # mean of price\n    deviation = price - mean_price, # subtraction from notes\n    deviation_sq = deviation^2) %>% # then square it\n  summarise(\n    mean_sq_deviation = sum(deviation_sq)/ # sum them\n      (nrow(diamonds) - 1)) # divide by n - 1\n\n\nRun each line of code above and ensure that you understand how this computation was developed. This shows us how to find \\(s_{price}^2\\) directly.\nFind \\(s_{x}^2\\), \\(s_{y}^2\\), and \\(s_{z}^2\\) both directly, and computationally: having R do the computation. (hint: you will need to insert 6 code chunks)\n\n\npraise()\n\n\n\nStandard deviation\n\nR also computes the standard deviation \\(s\\) directly:\n\n\n    diamonds %>% # the data\n      summarise(sd = sd(price)) # find the sd\n\nCan you use the computational approach (finding the mean_sq_deviation) from above to find the standard deviation of price \\(s_{price}\\)? (hint: you will need to use the sqrt() operator)\n\n\nIQR\n\nThe \\(IQR\\) can also be computed directly or indirectly:\n\n\ndiamonds %>% # the data\n  summarise(\n    q1 = quantile(price, 0.25), # find Q1\n    q3 = quantile(price, 0.75), # find Q3\n    iqr = q3 - q1 # now the IQR\n  )\n\n\n\nRange\n\ndiamonds %>% # the data\n  summarise(\n    min = min(price), # find min\n    max = max(price), # find max\n    range = max - min # and range\n  )\n\n\nOf all of the measures of spread, which do you think are sensitive to skewed data and outliers? Why?"
  },
  {
    "objectID": "ae/ae-4.html",
    "href": "ae/ae-4.html",
    "title": "Introduction to probability (AE-4)",
    "section": "",
    "text": "One ball will be drawn at random from a box containing: 3 cyan balls, 5 magenta balls, and 7 yellow balls. What is the probability that the ball will be cyan?\nWhat is the probability that the ball will not be cyan?\nInstead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling without replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nNow repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling with replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nTwo events A and B are independent if Pr(A and B)=Pr(A)P(B). Under which situation are the draws independent?\n\nYou don’t replace the draw.\nYou replace the draw.\nNeither\nBoth\n\nSay you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?\nIf you roll a 6-sided die six times, what is the probability of not seeing a 6?"
  },
  {
    "objectID": "slides/lect_04.html#definition-of-numeric-variable",
    "href": "slides/lect_04.html#definition-of-numeric-variable",
    "title": "Lec 4 - Exploring numeric data",
    "section": "Definition of numeric variable",
    "text": "Definition of numeric variable\nA numeric or quantitative variable is a variable that can be measured."
  },
  {
    "objectID": "slides/lec-1.html#meet-the-professor",
    "href": "slides/lec-1.html#meet-the-professor",
    "title": "Welcome to STA 210!",
    "section": "Meet the professor",
    "text": "Meet the professor\n\n\n\n\n\nDr. Mine Çetinkaya-Rundel (she/her)\n\n\n\n\nProfessor of the Practice & Director of Undergraduate Studies, Department of Statistical Science\nAffiliated Faculty, Computational Media, Arts & Cultures\nFind out more at mine-cr.com"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-tas",
    "href": "slides/lec-1.html#meet-the-tas",
    "title": "Welcome to STA 210!",
    "section": "Meet the TAs",
    "text": "Meet the TAs\n\nMartha Aboagye (she/her, UG)\nRich Fremgen (he/him, MS)\nEmily Gentles (she/her, MS)\nSara Mehta (she/her, UG)\nRick Presman (he/him, PhD)\nShari Tian (she/her, UG)\nAaditya Warrier (he/him, UG)"
  },
  {
    "objectID": "slides/lec-1.html#check-out-conversations",
    "href": "slides/lec-1.html#check-out-conversations",
    "title": "Welcome to STA 210!",
    "section": "Check out Conversations",
    "text": "Check out Conversations\n\nGo to Conversations 💬\nAnswer the discussion question: How are you doing?"
  },
  {
    "objectID": "slides/lec-1.html#what-is-regression-analysis",
    "href": "slides/lec-1.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis",
    "text": "What is regression analysis\n\n\n“In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or predictors). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or ‘criterion variable’) changes when any one of the independent variables is varied, while the other independent variables are held fixed.”\n\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/lec-1.html#course-faq",
    "href": "slides/lec-1.html#course-faq",
    "title": "Welcome to STA 210!",
    "section": "Course FAQ",
    "text": "Course FAQ\n\n\nWhat background is assumed for the course? Introductory statistics or probability course.\nWill we be doing computing? Yes. We will use R.\nWill we learn the mathematical theory of regression? Yes and No. The course is primarily focused on application; however, we will discuss some of the mathematics of simple linear regression. The 1-credit course STA 211: Mathematics of Regression you can take simultaneously / after dives into more of the mathematics."
  },
  {
    "objectID": "slides/lec-1.html#course-learning-objectives",
    "href": "slides/lec-1.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nAnalyze real-world data to answer questions about multivariable relationships.\nFit and evaluate linear and logistic regression models.\nAssess whether a proposed model is appropriate and describe its limitations.\nUse Quarto to write reproducible reports and GitHub for version control and collaboration.\nCommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "slides/lec-1.html#examples-of-regression-in-practice",
    "href": "slides/lec-1.html#examples-of-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Examples of regression in practice",
    "text": "Examples of regression in practice\n\n\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\nHow FiveThirtyEight’s 2020 Presidential Forecast Works — And What’s Different Because Of COVID-19\nEffect of Forensic Evidence on Criminal Justice Case Processing\nWhy it’s so freaking hard to make a good COVID-19 model"
  },
  {
    "objectID": "slides/lec-1.html#homepage",
    "href": "slides/lec-1.html#homepage",
    "title": "Welcome to STA 210!",
    "section": "Homepage",
    "text": "Homepage\nsta210-s22.github.io/website\n\nAll course materials\nLinks to Sakai, GitHub, RStudio containers, etc.\nLet’s take a tour!"
  },
  {
    "objectID": "slides/lec-1.html#course-toolkit",
    "href": "slides/lec-1.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta210-s22\nRStudio containers: cmgr.oit.duke.edu/containers\nDiscussion forum: Conversations\nAssignment submission and feedback: Gradescope\n\n\n\n\n\n\n\nImportant\n\n\nReserve an RStudio Container (titled STA 210) before lab on Monday!"
  },
  {
    "objectID": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "href": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to STA 210!",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Introduce new content and prepare for lectures by completing the readings (and sometimes watching the videos)\nParticipate: Attend and actively participate in lectures and labs, office hours, team meetings\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what you’ve learned to analyze real-world data\n\nLab assignments x 7 (first individual, later team-based)\nHomework assignments x 5 (individual)\nThree take-home exams\nTerm project presented during the final exam period"
  },
  {
    "objectID": "slides/lec-1.html#cadence",
    "href": "slides/lec-1.html#cadence",
    "title": "Welcome to STA 210!",
    "section": "Cadence",
    "text": "Cadence\n\n\nLabs: Start and make large progress on Monday in lab section, finish up by Friday 5pm of that week\nHWs: Posted Friday morning, due following Friday 5pm\nExams: Exam review Thursday in class, exam posted Friday morning, no lab on Monday of following week, due Monday 11:59pm\nProject: Deadlines throughout the semester, with some lab and lecture time dedicated to working on them, and most work done in teams outside of class"
  },
  {
    "objectID": "slides/lec-1.html#teams",
    "href": "slides/lec-1.html#teams",
    "title": "Welcome to STA 210!",
    "section": "Teams",
    "text": "Teams\n\nTeam assignments\n\nAssigned by me\nApplication exercises, labs, and project\nPeer evaluation during teamwork and after completion\n\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/lec-1.html#grading",
    "href": "slides/lec-1.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n3%\n\n\nHomework\n35% (7% x 5)\n\n\nProject\n15%\n\n\nLab\n14% (2% x 7)\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n3%\n\n\n\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/lec-1.html#support",
    "href": "slides/lec-1.html#support",
    "title": "Welcome to STA 210!",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions on the discussion forum\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/lec-1.html#announcements",
    "href": "slides/lec-1.html#announcements",
    "title": "Welcome to STA 210!",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Sakai (Announcements tool) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/lec-1.html#diversity-inclusion",
    "href": "slides/lec-1.html#diversity-inclusion",
    "title": "Welcome to STA 210!",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know!\nPlease let me know your preferred pronouns. You’ll also be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/lec-1.html#accessibility",
    "href": "slides/lec-1.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/lec-1.html#covid-policies",
    "href": "slides/lec-1.html#covid-policies",
    "title": "Welcome to STA 210!",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask at all times!\nRead and follow university guidance"
  },
  {
    "objectID": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "href": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "title": "Welcome to STA 210!",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/lec-1.html#collaboration-policy",
    "href": "slides/lec-1.html#collaboration-policy",
    "title": "Welcome to STA 210!",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/lec-1.html#sharing-reusing-code-policy",
    "href": "slides/lec-1.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 210!",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/lec-1.html#academic-integrity",
    "href": "slides/lec-1.html#academic-integrity",
    "title": "Welcome to STA 210!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/lec-1.html#most-importantly",
    "href": "slides/lec-1.html#most-importantly",
    "title": "Welcome to STA 210!",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "slides/lec-1.html#five-tips-for-success",
    "href": "slides/lec-1.html#five-tips-for-success",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings.\nDo the homework and lab.\nDon’t procrastinate and don’t let a week pass by with lingering questions."
  },
  {
    "objectID": "slides/lec-1.html#learning-during-a-pandemic",
    "href": "slides/lec-1.html#learning-during-a-pandemic",
    "title": "Welcome to STA 210!",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis."
  },
  {
    "objectID": "slides/lec-1.html#this-weeks-tasks",
    "href": "slides/lec-1.html#this-weeks-tasks",
    "title": "Welcome to STA 210!",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nGet a GitHub account if you don’t have one (some advice for choosing a username here)\nComplete the Getting to know you survey if you haven’t yet done so!\nRead the syllabus\nWatch out for next week’s announcement email, in your inbox sometime tomorrow"
  },
  {
    "objectID": "slides/lec-1.html#midori-says",
    "href": "slides/lec-1.html#midori-says",
    "title": "Welcome to STA 210!",
    "section": "Midori says…",
    "text": "Midori says…"
  },
  {
    "objectID": "slides/lect_03.html#definition-of-categorical-variable",
    "href": "slides/lect_03.html#definition-of-categorical-variable",
    "title": "Lec 3 - Exploring categorical data",
    "section": "Definition of categorical variable",
    "text": "Definition of categorical variable\nA categorical or qualitative variable is a variable that can not be measured. They are descriptors or grouping factors."
  },
  {
    "objectID": "slides/lect_03.html#the-purpose-of-exploring-categorical-variables",
    "href": "slides/lect_03.html#the-purpose-of-exploring-categorical-variables",
    "title": "Lec 3 - Exploring categorical data",
    "section": "The purpose of exploring categorical variables",
    "text": "The purpose of exploring categorical variables\n\nExploratory Data Analysis is about learning the structure of a dataset through a series of numerical and graphical techniques.\nWhen you do EDA, you’ll look for both\n\ngeneral trends and\ninteresting outliers in your data.\n\n\ngenerate questions that will help inform subsequent analysis."
  },
  {
    "objectID": "supplemental/chi-squared.html",
    "href": "supplemental/chi-squared.html",
    "title": "Chi-squared test expected values",
    "section": "",
    "text": "Information about the Chi-Squared test can be found here. We have two hypotheses:\n\\(H_0\\) = the variables are independent, there is no relationship between the two categorical variables.\n\\(H_A\\) = Knowing the value of one variable helps to predict the value of the other variable.\nUnder the null hypothesis, the distribution of one variable is independent to the distribution of the other. This means that the expected count for one cell, can be found using the column total times the row total divided by the total number of observations."
  },
  {
    "objectID": "course-faq.html#how-do-i-find-the-expected-values-for-a-chi-squared-distribution",
    "href": "course-faq.html#how-do-i-find-the-expected-values-for-a-chi-squared-distribution",
    "title": "FAQ",
    "section": "How do I find the expected values for a Chi-Squared distribution?",
    "text": "How do I find the expected values for a Chi-Squared distribution?\nInformation about the Chi-Squared test can be found here. We have two hypotheses:\n\\(H_0\\) = the variables are independent, there is no relationship between the two categorical variables.\n\\(H_A\\) = Knowing the value of one variable helps to predict the value of the other variable.\nUnder the null hypothesis, the distribution of one variable is independent to the distribution of the other. This means that the expected count for one cell, can be found using the column total times the row total divided by the total number of observations."
  },
  {
    "objectID": "ae/ae-6.html",
    "href": "ae/ae-6.html",
    "title": "Revision for exam 1",
    "section": "",
    "text": "What tidyverse function would you use to extract rows?\n\n\nfilter()\ncount()\nselect()\ndistinct()\n\n\nWhat tidyverse function would you use to extract colums?\n\n\nfilter()\ncount()\nselect()\ndistinct()\n\n\nTo find the maximum number of times that a categorical variable appears which function should I use?\n\n\nfilter()\ncount()\nselect()\ndistinct()\n\n\nWhat does the “%>%” operator do?\n\n\nused in tidyverse between layers of dplyr coding\nused in ggplot to add more layers of coding\n\n\nWill this code run without an error? mutate(price_hundred = price %/% 100)\n\n\nIt will produce an error\nIt will not produce an error\n\n\nWhat does the binwidth input do?\n\n\nIt controls the\n\n\nWhat punctuation must be placed before a function or dataset to access more information?\n\n\n“.”\n“+”\n“?”\n“!”\n\n\nWhere should the variable names go in the following line of code ggplot(data = ) + (mapping = aes())”\n\n\nA\nB\nC\n\n\nWhat does the here package do?\n\n\nfor data manipulation and display\nto organize files\nnone of the above\n\n\nWhich of the following variables are discrete?\nWhich of the following variables are categorical?\nWhich of the following variables are ordinal?\nWhich of the following variables are continous?\nWhat is the difference between distinct() and count()?\n\n\nthey are the same\ndistinct() gives the levels in a variable, count() gives the marginal distribution\ndistinct() gives the marginal distribution, count() gives the levels in a variable\n\n\nWhat operator is used in ggplot?\n\n\n“.”\n“+”\n“?”\n“!”\n\nCategorical variables\n\nFind the expected count for a \\(\\chi^2\\) distribution assuming independence.\n\n\ndiamonds %>% \n  count(color, clarity) %>% \n  pivot_wider(names_from = color,\n              values_from = n) %>% \n  mutate(marginal_clarity = rowSums(.[2:7])) %>% \n  mutate(marginal_color = colSums(.[2:9]))\n\n# A tibble: 8 × 10\n  clarity     D     E     F     G     H     I     J marginal_clarity marginal_…¹\n  <ord>   <int> <int> <int> <int> <int> <int> <int>            <dbl>       <dbl>\n1 I1         42   102   143   150   162    92    50              691        6775\n2 SI2      1370  1713  1609  1548  1563   912   479             8715        9797\n3 SI1      2083  2426  2131  1976  2275  1424   750            12315        9542\n4 VS2      1697  2470  2201  2347  1643  1169   731            11527       11292\n5 VS1       705  1281  1364  2148  1169   962   542             7629        8304\n6 VVS2      553   991   975  1443   608   365   131             4935        5422\n7 VVS1      252   656   734   999   585   355    74             3581        2808\n8 IF         73   158   385   681   299   143    51             1739       51132\n# … with abbreviated variable name ¹​marginal_color\n\n\n\nSome of the last questions on these - https://openintro.shinyapps.io/ims-02-explore-01/#section-distribution-of-one-variable\nConditional on one of two variables or the other to answer this question?\nConditional tables on both variables and which one is the right proportion?\n\nNumeric variables 19. Plot with mean, meadian and mode - label each\n\nMean or median better measure of center in these distributions\nWhich plot is better to display a"
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "📖 Read Solutions to AEs"
  },
  {
    "objectID": "weeks/week-5.html#participate",
    "href": "weeks/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\n🖥️\n🖥️"
  },
  {
    "objectID": "weeks/week-5.html#practice",
    "href": "weeks/week-5.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\n📋\n📋"
  },
  {
    "objectID": "weeks/week-5.html#perform",
    "href": "weeks/week-5.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\n⌨️ Course evaluation\n✍️\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "supplemental/log-transformations.html",
    "href": "supplemental/log-transformations.html",
    "title": "Study list for exam 1",
    "section": "",
    "text": "functions\noperators\npipes\n\n\nfilter()\n%/%\n%>%\n\n\ndistinct()\n%%\n“+”\n\n\ncount()\n!=\n\n\n\nselect()\nrowSums()\n\n\n\nmutate()\ncolSums()\n\n\n\nView()\n\n\n\n\nglimpse()\n\n\n\n\npivot_wider()\n\n\n\n\ngroup_by()\n\n\n\n\nchisq.test()\n\n\n\n\nggplot()\n\n\n\n\ngeom_hist()\n\n\n\n\ngeom_bar()\n\n\n\n\ngeom_point()\n\n\n\n\nlab()\n\n\n\n\nfacet_wrap()\n\n\n\n\n\nBenefits and downsides of these visualization methods: histogram and boxplot.\nConditional probability tables - which variable is it conditioned on.\nMean, median, mode and which is best in skewed distributions. Identify in a plot\nMeasures of spread: standard deviation, variance, quartiles, percentiles, interquartile range.\nChi-squared expected counts given a contingency table of counts.\nIndependent events\nDisjoint events\nVenn diagrams\nCompliments\nThe three laws of probability - Kolomogorov’s axioms"
  }
]