[
  {
    "objectID": "01_introduction.html",
    "href": "01_introduction.html",
    "title": "Chapter one: Setup and getting data",
    "section": "",
    "text": "Starting with packages\nQuarto is a recently developed framework that interactively connects to multiple programming languages and allows for advanced statistical work to be linked to word processing with ease. It will be the basis for our course and for data analysis.\n\n\n\nFigure @ref(fig:2) Opening a new quarto file\n\n\nThe R programming language was first released on 29 February 2000. Ross Ihaka and Robert Gentleman wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. R is now an internationally recognized language used all over the world. It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on CRAN. Today we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")\n\n\n\nIncluding your own data\nTo add data to your directory, first create a folder that\n\n\n\nFigure @ref(fig:3) Adding a folder.\n\n\nand name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R.\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”"
  },
  {
    "objectID": "slides/01-introduction.html",
    "href": "slides/01-introduction.html",
    "title": "Chapter one: Setup and getting data",
    "section": "",
    "text": "Starting with packages\nQuarto is a recently developed framework that interactively connects to multiple programming languages and allows for advanced statistical work to be linked to word processing with ease. It will be the basis for our course and for data analysis.\n\n\n\nFigure @ref(fig:2) Opening a new quarto file\n\n\nThe R programming language was first released on 29 February 2000. Ross Ihaka and Robert Gentleman wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. R is now an internationally recognized language used all over the world. It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on CRAN. Today we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")\n\n\n\nIncluding your own data\nTo add data to your directory, first create a folder that\n\n\n\nFigure @ref(fig:3) Adding a folder.\n\n\nand name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R.\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\nNotice that your environment tab will change and will show that you have data imported into R.\n\n\n\nUpdates in environment tab after importing data.\n\n\nCongratulations! You have just imported your first dataset into R which is the first step in the data science workflow!\n\n\n\nData science workflow"
  },
  {
    "objectID": "slides/01-introduction.html#downloading-software-and-creating-a-project",
    "href": "slides/01-introduction.html#downloading-software-and-creating-a-project",
    "title": "STAT 1010 - Fall 2022",
    "section": "Downloading software and creating a project",
    "text": "Downloading software and creating a project\nPrior to starting any statistics, software organization is crucial. Your high schools may have used google sheets or excel, but for our course we will be using R and RStudio. Please see our website to download them, then download quarto to get started.\nOnce this is completed, please open RStudio and do the following:\n\n\n\nFigure @ref(fig:1) Start a new project in RStudio\n\n\n\n\n\nFigure @ref(fig:2) Select “New Directory”\n\n\n\n\n\nFigure @ref(fig:3) Then select “New Project”\n\n\nHit the “Browse” button, then the “New Folder” button and call this new folder “Stats1010.” All work related to chapter 1 will be in this folder, and we will create a new project for each chapter and a new project for each homework.\n\n\n\n\n\nthen hit “Create project.”"
  },
  {
    "objectID": "computing-pipelines.html",
    "href": "computing-pipelines.html",
    "title": "Pipelines",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "computing-pipelines.html#simple-linear-regression",
    "href": "computing-pipelines.html#simple-linear-regression",
    "title": "Pipelines",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nModel fitting\nFit model:\n\npenguins_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\nTidy model output:\n\ntidy(penguins_fit)\n\nFormat model output as table:\n\ntidy(penguins_fit) %>%\n  kable(digits = 3)\n\nAugment data with model:\n\naugment(penguins_fit$fit)\n\n\n\nStatistical inference"
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Open your Stat1010 project then go to file and open a quarto document. You can add code chunks by clicking on the green button in the IDE and answer some questions directly in the document, and add further code chunks. Hit render and if there are no errors in your code, the pdf should pop up. You can then upload to either Canvas or Gradescope"
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.1.2: https://cran.r-project.org/\nDownload and install a daily build of RStudio: https://dailies.rstudio.com/\nInstall Quarto CLI: https://quarto.org/docs/getting-started/installation.html\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here."
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#discussion-forum",
    "href": "course-support.html#discussion-forum",
    "title": "Course support",
    "section": "Discussion forum",
    "text": "Discussion forum\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The online discussion forum is the best venue for these! We will use Ed discussion as the online discussion forum. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go Ed discussion), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email dr. gwynn sturdevant at gwynnc@wharton.upenn.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STAT 1010” and only “STAT 1010” in the subject line. You can also contact me privately on Canvas. Barring extenuating circumstances, I will respond to STAT 1010 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Weingarten learning center. The Weingarten Center offers a variety of resources to support all Penn students in reaching their academic goals. They offer multiple workshops throughout the semester and students can request workshops. All services are free and confidential. To contact the Weingarten Center, call 215-573-9235. The office is located in Stouffer Commons at 3702 Spruce Street, Suite 300.\nLearning Consultations offers individual consultations and group workshops that support students in developing more efficient and effective study skills and learning strategies. Learning specialists work with students to address time and project management, academic reading and writing, note-taking, problem-solving, exam preparation, test-taking, self-regulation, and flexibility.\n\nTutoring offers free access to on-campus tutors for many Penn courses in both drop-in and weekly contract format. Tutoring may be individual or in small groups. Tutors will assist with applying course information, understanding key concepts, and developing course-specific strategies. Tutoring support is available throughout the term but is best accessed early in the semester. First-time users must meet with a staff member; returning users may submit their requests online.\n\nAdditionally, Marks Family Writing Center provides expert help in writing for undergraduate and graduate students. Communication Within the Curriculum helps students express themselves orally with clarity and confidence. Language Direct provides tutoring for foreign languages. Van\nPelt Library supports students in research and instructional technologies through a range of workshops and consultations."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nCounseling and Psychological Services (CAPS) provides professional psychological and psychiatric services to students who need support in fulfilling their academic, social, and personal objectives. CAPS directly supports student mental health through counseling, crisis management, consultation, education and outreach, and training. CAPS has a satellite office in Huntsman Hall, and students with urgent concerns can talk with a CAPS clinician 24/7 at 215.898.7021 (press 1) or visit CAPS' main office at 3624 Market Street during business hours.\n\nStudent Health Service provides students with accessible, cost-effective, culturally-sensitive, and student-focused healthcare, including care for acute and chronic health problems, preventive health services, and health and wellness education.\n\nAlcohol and Other Drug Program Initiatives (AOD) works to reduce harm related to alcohol and other drug use at Penn.\n\nPenn Violence Prevention (PVP) engages the Penn community in the prevention of sexual violence, relationship violence, stalking, and sexual harassment on campus. PVP provides education and outreach and the staff serves as confidential resources for students.\n\nPublic Safety: From riding your bike on campus, to preventing unattended theft, the Division of Public Safety wants to make sure you have the information you need to protect your safety and your belongings.\n\nPenn Recreation: Penn offers many opportunities for students to participate in competitive team sports and stay physically fit at state-of-the-art, world-class training centers.\n\nWharton Wellness is a division-sponsored student organization that works to implement initiatives targeted at specific wellness issues in the Wharton community by creating experiences, fostering a positive culture of well-being, and connecting clubs/students to wellness resources.\n\nIt is important to me that you have the resources you need to be able to focus on learning in this course – this includes both the necessary academic materials as well as taking care of your day-to-day needs. Students experiencing difficulty affording the course materials should reach out to the Penn First Plus office (pennfirstplus@upenn.edu). Students who are struggling to afford sufficient food to eat every day and/or lack a safe and suitable space to live should contact Student Intervention Services (vpul-sisteam@pobox.upenn.edu). Students may also wish to contact their Financial Aid Counselor or Academic Advisor about these concerns. You are welcome to notify me if any of these challenges are affecting your success in this course, as long as you are comfortable doing so – I may have resources to support you."
  },
  {
    "objectID": "course-support.html#technology-accommodations",
    "href": "course-support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For technology assistance requests, please go here. Please note that supplies are limited. Additional support is also available through Student Intervention Services."
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-sakai",
    "href": "course-support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission and discussion will take place on GitHub instead.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "exams/exam-1.html",
    "href": "exams/exam-1.html",
    "title": "Exam 1",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Topic ideas due Fri, Feb 18\nProposal due Fri, Mar 18\nDraft report due Fri, Apr 8\nPeer review due Fri, Apr 15\nFinal report due Mon, Apr 25\nVideo presentation + slides and final GitHub repo due Thu, Apr 28\nPresentation comments due Sat, Apr 30"
  },
  {
    "objectID": "project-description.html#introduction",
    "href": "project-description.html#introduction",
    "title": "Project description",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio, and all components of the project must be reproducible (with the exception of the presentation).\n\nLogistics\nYou will work on the project with your lab groups.\nThe four primary deliverables for the final project are\n\nA written, reproducible report detailing your analysis\nA GitHub repository corresponding to your report\nSlides + a video presentation\nFormal peer review on another team’s project"
  },
  {
    "objectID": "project-description.html#topic-ideas",
    "href": "project-description.html#topic-ideas",
    "title": "Project description",
    "section": "Topic ideas",
    "text": "Topic ideas\nIdentify 2-3 data sets you’re interested in potentially using for the final project. If you’re unsure where to find data, you can use the list of potential data sources in the Tips + Resources section as a starting point. It may also help to think of topics you’re interested in investigating and find data sets on those topics.\nThe purpose of submitting project ideas is to give you time to find data for the project and to make sure you have a data set that can help you be successful in the project. Therefore, you must use one of the data sets submitted as a topic idea, unless otherwise notified by the teaching team.\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns\nAt least 6 of the columns must be useful and unique predictor variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful predictor variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nObservations should reasonably meet the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nFor each data set, include the following:\n\nIntroduction and data\n\nState the source of the data set.\nDescribe when and how it was originally collected (by the original data curator, not necessarily how you found the data)\nDescribe the observations and the general characteristics being measured in the data\n\n\n\nResearch question\n\nDescribe a research question you’re interested in answering using this data.\n\n\n\nGlimpse of data\n\nUse the glimpse function to provide an overview of each data set\n\nSubmit the PDF of the topic ideas to Gradescope. Mark all pages associated with each data set."
  },
  {
    "objectID": "project-description.html#project-proposal",
    "href": "project-description.html#project-proposal",
    "title": "Project description",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is to help you think about your analysis strategy early.\nInclude the following in the proposal:\n\nSection 1 - Introduction\nThe introduction section includes\n\nan introduction to the subject matter you’re investigating\nthe motivation for your research question (citing any relevant literature)\nthe general research question you wish to explore\nyour hypotheses regarding the research question of interest.\n\n\n\nSection 2 - Data description\nIn this section, you will describe the data set you wish to explore. This includes\n\ndescription of the observations in the data set,\ndescription of how the data was originally collected (not how you found the data but how the original curator of the data collected it).\n\n\n\nSection 3 - Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes:\n\nDescription of the response variable.\nVisualization and summary statistics for the response variable.\nList of variables that will be considered as predictors\nRegression model technique (multiple linear regression and logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of your project repo, in the data folder. Link to this file from your proposal writeup.\n\n\nSubmission\nPush all of your final changes to the GitHub repo, and submit the PDF of your proposal to Gradescope.\n\n\nProposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction\n3 pts\n\n\nData description\n2 pts\n\n\nAnalysis plan\n4 pts\n\n\nData dictionary\n1 pts\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting."
  },
  {
    "objectID": "project-description.html#draft-report",
    "href": "project-description.html#draft-report",
    "title": "Project description",
    "section": "Draft report",
    "text": "Draft report\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model."
  },
  {
    "objectID": "project-description.html#peer-review",
    "href": "project-description.html#peer-review",
    "title": "Project description",
    "section": "Peer review",
    "text": "Peer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’s projects to review. Each team should push their draft to their GitHub repo by the due date. One lab in the following week will be dedicated to the peer review, and all reviews will be due by the end of that lab session.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided. The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions.\n\nPairings\n\nSection 1 - M 1:45PM - 3:00PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\nchaa_chaa_chaa\nyay_stats\nstat_over_flow\n\n\ndekk\nchaa_chaa_chaa\nyay_stats\n\n\neight\ndekk\nchaa_chaa_chaa\n\n\nhousecats\neight\ndekk\n\n\nkrafthouse\nhousecats\neight\n\n\nrrawr\nkrafthouse\nhousecats\n\n\nstat_over_flow\nrrawr\nkrafthouse\n\n\nyay_stats\nstat_over_flow\nrrawr\n\n\n\n\n\nSection 2 - M 3:30PM - 4:45PM\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\na_plus_plus_plus\nwe_r\ntina\n\n\npredictors\na_plus_plus_plus\nwe_r\n\n\nsixers\npredictors\na_plus_plus_plus\n\n\nsoy_nuggets\nsixers\npredictors\n\n\ntina\nsoy_nuggets\nsixers\n\n\nwe_r\ntina\nsoy_nuggets\n\n\n\n\n\nSection 3 - M 5:15PM - 6:30PM\n\n\n\n\n\n\n\n\nTeam being reviewed\nReviewer 1\nReviewer 2\n\n\n\n\ndown_to_earth_goats\nthe_three_musketeers\nteam_five\n\n\nginger_and_stats\ndown_to_earth_goats\nthe_three_musketeers\n\n\npineapple_wedge_and_diced_papaya\nginger_and_stats\ndown_to_earth_goats\n\n\nstatchelorettes\npineapple_wedge_and_diced_papaya\nginger_and_stats\n\n\nstatisix\nstatchelorettes\npineapple_wedge_and_diced_papaya\n\n\nstats_squad\nstatisix\nstatchelorettes\n\n\nteam_five\nstats_squad\nstatisix\n\n\nthe_three_musketeers\nteam_five\nstats_squad\n\n\n\n\n\n\nProcess and questions\nSpend ~30 mins to review each team’s project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team’s repo.\nOpen the repo of the team you’re reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description.html#written-report",
    "href": "project-description.html#written-report",
    "title": "Project description",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo = FALSE.\nYou will submit the PDF of your final report on Gradescope.\nThe PDF you submit must match the files in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long. is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion + conclusion\n6 pts\n\n\nOrganization + formatting\n4 pts\n\n\n\nClick here for a PDF of the written report rubric.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#video-presentation-slides",
    "href": "project-description.html#video-presentation-slides",
    "title": "Project description",
    "section": "Video presentation + slides",
    "text": "Video presentation + slides\n\nSlides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nFor submission, convert these slides to a .pdf document, and submit the PDF of the slides on Gradescope.\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nVideo presentation\nFor the video presentation, you can speak over your slide deck, similar to the lecture content videos. The video presentation must be no longer than 8 minutes. It is fine if the video is shorter than 8 minutes, but it cannot exceed 8 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Conversations.\n\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum.\n\n\n\nTo post the video to the discussion forum\n\nClick the Presentations tab in the course Sakai site.\nClick the Presentations topic.\nClick “Start a new conversation”.\nMake the title “Your Team Name: Project Title”. For example, “Teaching Team: Our Awesome Presentation”.\nClick the Warpwire icon (between the table and shopping cart icons).\nSelect your video, then click “Insert 1 item.” This will embed your video in the conversation.\nUnder the video, paste the URL to your video.\nYou’re done!"
  },
  {
    "objectID": "project-description.html#presentation-comments",
    "href": "project-description.html#presentation-comments",
    "title": "Project description",
    "section": "Presentation comments",
    "text": "Presentation comments\nEach student will be assigned 2 presentations to watch. Your viewing assignments will be posted later in the semester.\nWatch the group’s video, then click “Reply” to post a question for the group. You may not post a question that’s already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e. it shouldn’t be “Why did you use a bar plot instead of a pie chart”?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group’s specific presentation, i.e demonstrating that you’ve watched the presentation.\nThis portion of the project will be assessed individually.\n\nPairings\nFind your team name in the first column, watch videos from teams in the second column and leave comments.\n\n\n\n\n\n\n\n\nReviewer\nFirst video to review\nSecond video to review\n\n\n\n\nGinger and Stats\nEight\nWe R\n\n\nKrafthouse\nGinger and Stats\nEight\n\n\nSoy Nuggets\nKrafthouse\nGinger and Stats\n\n\nDown To Earth Goats\nSoy Nuggets\nKrafthouse\n\n\nA+++\nDown To Earth Goats\nSoy Nuggets\n\n\nTeam Five\nA+++\nDown To Earth Goats\n\n\nRrawr\nTeam Five\nA+++\n\n\nHousecats\nRrawr\nTeam Five\n\n\nDekk\nHousecats\nRrawr\n\n\nStat OverFlow\nDekk\nHousecats\n\n\nThe Three Musketeers\nStat OverFlow\nDekk\n\n\nPredictors\nThe Three Musketeers\nStat OverFlow\n\n\nStats Squad\nPredictors\nThe Three Musketeers\n\n\nStatisix\nStats Squad\nPredictors\n\n\nSixers\nStatisix\nStats Squad\n\n\nYay Stats\nSixers\nStatisix\n\n\nTINA\nYay Stats\nSixers\n\n\nStatchelorettes\nTINA\nYay Stats\n\n\nPineapple Wedge and Diced Papaya\nStatchelorettes\nTINA\n\n\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\nStatchelorettes\n\n\nWe R\nChaa Chaa Chaa\nPineapple Wedge and Diced Papaya\n\n\nEight\nWe R\nChaa Chaa Chaa"
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\n/data: Folder that contains the data set for the final project.\n/previous-work: Folder that contains the topic-ideas and project-proposal files.\n/presentation: Folder with the presentation slides.\n\nIf your presentation slides are online, you can put a link to the slides in a README.md file in the presentation folder.\n\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#peer-teamwork-evaluation",
    "href": "project-description.html#peer-teamwork-evaluation",
    "title": "Project description",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project video deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#overall-grading",
    "href": "project-description.html#overall-grading",
    "title": "Project description",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nTopic ideas\n5 pts\n\n\nProject proposal\n10 pts\n\n\nPeer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nSlides + video presentation\n20 pts\n\n\nReproducibility + organization\n5 pts\n\n\nVideo comments\n5 pts\n\n\nPeer teamwork evaluation\n5 pts\n\n\n\nNote: No late project reports or videos are accepted.\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.\n\n\n\nLate work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-syllabus.html#course-info",
    "href": "course-syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nSection 1\nMon & Wed\n8:30 am - 10:00 am\nSHDH 1206\n\n\nSection 2\nMon & Wed\n10:15 am - 11:45 am\nSHDH 1206\n\n\nSection 3\nMon & Wed\n1:45 pm - 3:15 pm\nSHDH 1206"
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the semester, you will be able to…\n\nunderstand data manipulation, and find basic summaries\nreason under uncertainity\nmake predictions\nunderstand probability\ncommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "course-syllabus.html#community",
    "href": "course-syllabus.html#community",
    "title": "Syllabus",
    "section": "Community",
    "text": "Community\n\nWharton’s Code of Conduct\nAs a student in this course, you have agreed to uphold the Wharton’s Student Code of Conduct as well as the practices specific to this course.\n\n\nInclusive community\nMy goal as your lecturer is to help you accomplish or discover your passion and find your spark. You all belong here. It is also my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Diversity, Inclusion and Belonging at the Wharton School. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups. Please feel free to leave anonymous comments in my mailbox on the 4th floor of the Academic Research Building.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Weingarten Center is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the the Weingarten Center to request or update accommodations under these circumstances; it can take up to 4 weeks to review documents and get approval.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website at stats1010-f22.github.io/website.\nI will regularly send course announcements via email and canvas, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the Ed discussion forum. There is a chance another student has already asked a similar question, so please check the other posts in Conversations before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\nEmails should be reserved for questions not appropriate for the public forum. If you email me, please include “STAT 1010” in the subject line and ONLY STAT 1010. Barring extenuating circumstances, I will respond to STAT 1010 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\n\nCheck out the Support page for more resources."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin\nStatistics for Business by Robert Stine and Dean Foster"
  },
  {
    "objectID": "course-syllabus.html#lectures-and-labs",
    "href": "course-syllabus.html#lectures-and-labs",
    "title": "Syllabus",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nThe goal of both the lectures is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded. In addition to application exercises will be periodic activities help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. More information on loaner laptops can be found here."
  },
  {
    "objectID": "course-syllabus.html#teams",
    "href": "course-syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture. All team members are expected to contribute equally to the completion of the labs and project and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team’s overall mark."
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nAssessment for the course is comprised of five components: application exercises, homework assignments, exams, projects, and teamwork.\n\nApplication exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises give you an opportunity to apply the statistical concepts and code introduced in the readings and lectures. Due dates for AEs will be announced as they are assigned.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and submitted as a PDF in Canvas.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be four exams consisting of multiple choice questions. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on the conceptual understanding of the content. The content of the exam will be related to the content in the prepare, practice, and perform assignments. More detail about the exams will be given during the semester.\nThe lowest exam grade will be dropped at the end of the semester.\n\n\nProject\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting, data-driven research question. The project will be completed with your teams, and each team will present their work. More information about the project will be provided during the semester."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n7%\n\n\nHomework\n35% (7 x 5%)\n\n\nProject\n15%\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n13%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "course-syllabus.html#five-tips-for-success",
    "href": "course-syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TA and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TA, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. If something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, and eventually you won’t know where to begin asking questions. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours, and let me help you identify a good (re)starting point."
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic integrity\nTL;DR: Don’t cheat!\nAll students must adhere to Wharton’s Code of Academic Integrity: Wharton is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nRegardless of course delivery format, it is your responsibility to understand and follow Wharton policies regarding academic integrity, including doing one’s own work, following proper citation of sources, and adhering to guidance around group work projects. Ignoring these requirements is a violation of the Wharton Community Standard. If you have any questions about how to follow these requirements, please contact Julie Nettleton, Director of the Center for Community Standards and Accountability (CSA).\n\n\nCollaboration policy\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\n\n\n\nPolicy on sharing and reusing code\nI am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. On individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email dr. sturdevant before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let dr. sturdevant know if you need help contacting your academic dean.\n\n\nRegrade request policy\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Wharton attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you’re going to miss a class and you’re feeling well enough to do so, notify your teammates ahead of time. Additionally, please fill out a Course Absence Notice (CAN) so that I am notified in case of an attendance quiz. Overall these policies are put in place to ensure communication between team members, respect for each others’ time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have symptoms related to COVID-19, have had a known exposure to COVID-19, or have tested positive for COVID-19. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health at 215-898-0300. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class. For the safety of all students, I require that students wear masks in class and prefer N95 or KN95 masks.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously or watching a recording of the class.\n\n\nPolicy on video recording course content\nLectures will be recorded and available on Canvas, so students should not need to create their own recordings of lectures. If you feel that you need record the lectures yourself, you must get written permission from me ahead of time and these recordings should be used for personal study only, not for distribution. The full policy on recording of lectures falls under the University of Pennsylvania’s V.L. Policy on Unauthorized Copying of Copyrighted Media, available at https://catalog.upenn.edu/faculty-handbook/v/v-l/. Unauthorized distribution may result in a civil suite, criminal charges, and/or penalties and fines."
  },
  {
    "objectID": "course-syllabus.html#learning-during-a-pandemic",
    "href": "course-syllabus.html#learning-during-a-pandemic",
    "title": "Syllabus",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis.\n\nNote: If you’ve read this far in the syllabus, send me an email with a picture of your pet if you have one or your favorite memes with STAT1010 in the subject line!"
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAugust 30: First day of classes\nSeptember 5: Labor Day holiday, no classes are held\nSeptember 13: Course Selection Period ends\nOctober 6 - 9: Fall term break, no classes are held\nOctober 10: Drop period ends\nOctober 10: Indigenous People’s Day (classes in session)\nOctober 28: Grade Type Change Deadline\nNovember 7: Last day to withdraw from a course\nNovember 22-23: Thur-Fri class schedule on Tue-Wed\nNovember 24-27: Thanksgiving Break\nDecember 12: Last day of classes\nDecember 13-14: Reading Days\nDecember 15 - 22: Final exams\nDecember 22: Fall term ends\n\nClick here for the full University of Pennsylvania academic calendar."
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).\nEither way you can also fill out the form here, which will notify our the R TA for the department as well as our undergraduate coordinator. They’ll be able to help diagnose the issue."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 1010: Introduction to Business Statistics",
    "section": "",
    "text": "Week\nDate\nTopic\nPrepare\nSlides\nAE\nHW\nExam\nProject\n\n\n\n\n\n1\nMon, 29 Aug\nNo class - opening exercises\n\n\n\n\n\n\n\n\n\n\nWed, 31 Aug\nStarting with R\n\n🖥️\n📋\n\n\n\n\n\n\n2\nMon, 5 Sept\nNo class - Labor Day\n\n\n\n\n\n\n\n\n\n\nWed, 7 Sept\nContinuation of Intro to R\n📖\n🖥️\n\n\n\n\n\n\n\n3\nMon, 12 Sept\nCategorical variables\n📖\n🖥️\n📋\n\n\n\n\n\n\n\nWed, 14 Sept\nNumeric variables\n\n🖥️\n📋\n✍️\n\n\n\n\n\n4\nMon, 19 Sept\nIntro to probability\n📖\n🖥️\n📋\n✍️\n\n\n\n\n\n\nWed, 21 Sept\nMore probability rules\n\n🖥️\n📋\n\n\n\n\n\n\n5\nMon, 26 Sept\nRevision of AE 1-4\n📖\n\n📋\n\n\n\n\n\n\n\nWed, 28 Sept\nRevision of HW-1\n📖\n\n📋\n\n\n\n\n\n\n6\nMon, 3 Oct\nExam 1\n\n\n\n\n✅\n\n\n\n\n\nWed, 5 Oct\nRandom variables\n📖\n🖥️\n📋\n\n\n\n\n\n\n7\nMon, 10 Oct\nAssociation between quantitative variables\n📖\n🖥️\n\n\n\n\n\n\n\n\nWed, 12 Oct\nAssociation between random variables\n\n🖥️\n📋\n✍️\n\n\n\n\n\n8\nMon, 17 Oct\nProbability models for counts\n📖\n🖥️\n\n\n\n\n\n\n\n\nWed, 19 Oct\nThe normal probability model\n\n🖥️\n\n\n\n\n\n\n\n9\nMon, 24 Oct\nSamples and surveys\n📖\n🖥️\n\n\n\n\n\n\n\n\nWed, 26 Oct\nSampling variation and quality\n\n🖥️\n📋\n\n\n\n📂\n\n\n10\nMon, 31 Oct\nRevision for Exam 2\n\n🖥️\n\n\n\n\n\n\n\n\nWed, 2 Nov\nExam 2\n\n\n\n\n✅\n\n\n\n\n11\nMon, 7 Nov\nConfidence intervals\n\n🖥️\n📋\n\n\n\n\n\n\n\nWed, 9 Nov\nStatistical tests\n\n🖥️\n\n\n\n\n\n\n\n12\nMon, 14 Nov\nComparison\n\n🖥️\n\n\n\n\n\n\n\n\nWed, 16 Nov\nInference for counts\n\n🖥️\n📋\n\n\n\n\n\n\n13\nMon, 21 Nov\nLinear patterns\n\n🖥️\n\n\n\n\n\n\n\n\nWed, 22 Nov\nNo class - Thanksgiving"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Discussion forum\n🔗 on Ed discussion\n\n\n\n\nLecture streaming and recordings (email for permission)\n🔗 on Canvas\n\n\nSubmit AE\n🔗 on Canvas\n\n\nSubmit HWK\n🔗 on Gradescope\n\n\nGradebook\n🔗 on Canvas"
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Teaching Assistant\n\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\n\nPatrick Chao\nMon & Wed\n4pm - 5pm\nZoom"
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\n\nMartha Aboagye\nThursday 7 - 9 pm\nZoom\n\n\n\nRichard Fremgen\nLead TA for Section 3 (5:15 pm)\nTues 7 - 9 pm\nZoom\n\n\n\nEmily Gentles\nLead TA for Section 1 (1:45pm)\nWednesday 1 - 3 pm\nOld Chem 203B (On Zoom until January 18)\n\n\n\nSara Mehta\nMon 2 - 4 pm\nZoom\n\n\n\nRick Presman\nHead TA\nLead TA for Section 2 (3:30pm)\nThursday 3:30 - 4:30 pm\nFri 9 - 10 am\nZoom"
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "Prepare",
    "text": "Prepare\n📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-1.html#participate",
    "href": "weeks/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 1 - Download R and plotting your first graph"
  },
  {
    "objectID": "weeks/week-1.html#practice",
    "href": "weeks/week-1.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\n📋 diamonds"
  },
  {
    "objectID": "weeks/week-1.html#perform",
    "href": "weeks/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "supplemental/slr-derivations.html",
    "href": "supplemental/slr-derivations.html",
    "title": "Deriving the Least-Squares Estimates for Simple Linear Regression",
    "section": "",
    "text": "This document contains the mathematical details for deriving the least-squares estimates for slope (\\(\\beta_1\\)) and intercept (\\(\\beta_0\\)). We obtain the estimates, \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) by finding the values that minimize the sum of squared residuals, as shown in Equation 1.\n\\[\nSSR = \\sum\\limits_{i=1}^{n}[y_i - \\hat{y}_i]^2 = [y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)]^2 = [y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i]^2\n\\tag{1}\\]\nRecall that we can find the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize /eq-ssr by taking the partial derivatives of Equation 1 and setting them to 0. Thus, the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize the respective partial derivative also minimize the sum of squared residuals. The partial derivatives are shown in Equation 2.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} &= -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)  \\\\\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)\n\\end{aligned}\n\\tag{2}\\]\nThe derivation of deriving \\(\\hat{\\beta}_0\\) is shown in Equation 3.\n\\[\n\\begin{aligned}\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}(y_i + \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow - \\sum\\limits_{i=1}^{n}y_i + n\\hat{\\beta}_0 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i = 0 \\\\&\\Rightarrow n\\hat{\\beta}_0  = \\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i \\\\&\\Rightarrow \\hat{\\beta}_0  = \\frac{1}{n}\\Big(\\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i\\Big)\\\\&\\Rightarrow \\hat{\\beta}_0  = \\bar{y} - \\hat{\\beta}_1 \\bar{x} \\\\\\end{aligned}\n\\tag{3}\\]\nThe derivation of \\(\\hat{\\beta}_1\\) using the \\(\\hat{\\beta}_0\\) we just derived is shown in Equation 4.\n\\[\n\\begin{aligned}&\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} = -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0  \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + \\hat{\\beta}_0\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\\\text{(Fill in }\\hat{\\beta}_0\\text{)}&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\&\\Rightarrow  (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\bar{y}\\sum\\limits_{i=1}^{n}x_i - \\hat{\\beta}_1\\bar{x}\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow n\\bar{y}\\bar{x} - \\hat{\\beta}_1n\\bar{x}^2 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 - \\hat{\\beta}_1n\\bar{x}^2  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\&\\Rightarrow \\hat{\\beta}_1\\Big(\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2\\Big)  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\ &\\hat{\\beta}_1 = \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2}\\end{aligned}\n\\tag{4}\\]\nTo write \\(\\hat{\\beta}_1\\) in a form that’s more recognizable, we will use the following:\n\\[\n\\sum x_iy_i - n\\bar{y}\\bar{x} = \\sum(x - \\bar{x})(y - \\bar{y}) = (n-1)\\text{Cov}(x,y)\n\\tag{5}\\]\n\\[\n\\sum x_i^2 - n\\bar{x}^2 - \\sum(x - \\bar{x})^2 = (n-1)s_x^2\n\\tag{6}\\]\nwhere \\(\\text{Cov}(x,y)\\) is the covariance of \\(x\\) and \\(y\\), and \\(s_x^2\\) is the sample variance of \\(x\\) (\\(s_x\\) is the sample standard deviation).\nThus, applying Equation 5 and Equation 6, we have\n\\[\n\\begin{aligned}\\hat{\\beta}_1 &= \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2} \\\\&= \\frac{\\sum\\limits_{i=1}^{n}(x-\\bar{x})(y-\\bar{y})}{\\sum\\limits_{i=1}^{n}(x-\\bar{x})^2}\\\\&= \\frac{(n-1)\\text{Cov}(x,y)}{(n-1)s_x^2}\\\\&= \\frac{\\text{Cov}(x,y)}{s_x^2}\\end{aligned}\n\\tag{7}\\]\nThe correlation between \\(x\\) and \\(y\\) is \\(r = \\frac{\\text{Cov}(x,y)}{s_x s_y}\\). Thus, \\(\\text{Cov}(x,y) = r s_xs_y\\). Plugging this into Equation 7, we have\n\\[\n\\hat{\\beta}_1 = \\frac{\\text{Cov}(x,y)}{s_x^2} = r\\frac{s_ys_x}{s_x^2} = r\\frac{s_y}{s_x}\n\\tag{8}\\]"
  },
  {
    "objectID": "slides/01_introduction.html",
    "href": "slides/01_introduction.html",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "",
    "text": "For our course we will be using R and RStudio."
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "STA 1010: Introduction to Business Statistics",
    "section": "",
    "text": "The course goals are as follows:\n\nRecognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the scope of inference.\nUse statistical software to summarize data numerically and visually, and to perform data analysis.\nHave a conceptual understanding of the unified nature of statistical inference.\nApply estimation and testing methods to analyze single variables or the relationship between two variables in order to understand natural phenomena and make data-based\ndecisions.\nModel numerical response variables using a single or multiple explanatory variables.\nInterpret results correctly, effectively, and in context without relying on statistical jargon.\nCritique data-based claims and evaluate data-based decisions.\nComplete a research project demonstrating mastery of statistical data analysis from exploratory analysis to inference to modeling."
  },
  {
    "objectID": "slides/01_introduction.html#downloading-software-and-creating-a-project",
    "href": "slides/01_introduction.html#downloading-software-and-creating-a-project",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Downloading software and creating a project",
    "text": "Downloading software and creating a project\nFor our course we will be using R and RStudio."
  },
  {
    "objectID": "slides/01_introduction.html#start-a-project",
    "href": "slides/01_introduction.html#start-a-project",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Start a project",
    "text": "Start a project\nOpen RStudio and do the following:\n\nFigure @ref(fig:1) Start a new project in RStudio"
  },
  {
    "objectID": "slides/01_introduction.html#new-directory",
    "href": "slides/01_introduction.html#new-directory",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "New directory",
    "text": "New directory\n\nSelect “New Directory”"
  },
  {
    "objectID": "slides/01_introduction.html#directory-type",
    "href": "slides/01_introduction.html#directory-type",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Directory type",
    "text": "Directory type\n\nThen select “New Project”"
  },
  {
    "objectID": "slides/01_introduction.html#new-folder",
    "href": "slides/01_introduction.html#new-folder",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "New folder",
    "text": "New folder\nHit the “Browse” button, then the “New Folder” button and name it “Stats1010.” All work related to this class will be in this folder, and we will create a new document for each chapter and homework.\n\nthen hit “Create project.”"
  },
  {
    "objectID": "slides/01_introduction.html#why",
    "href": "slides/01_introduction.html#why",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Why?",
    "text": "Why?\nThe R programming language was first released on 29 February 2000. Ross Ihaka and Robert Gentleman wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. R is now an internationally recognized language used all over the world. It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on CRAN. Today we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")"
  },
  {
    "objectID": "slides/01_introduction.html#including-your-own-data",
    "href": "slides/01_introduction.html#including-your-own-data",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Including your own data",
    "text": "Including your own data\nTo add data to your directory, first create a folder that\n\nFigure @ref(fig:3) Adding a folder.and name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R."
  },
  {
    "objectID": "slides/01_introduction.html#importing-data",
    "href": "slides/01_introduction.html#importing-data",
    "title": "Lec 1 - Downloading software and creating a project",
    "section": "Importing data",
    "text": "Importing data\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lec_1_images/first_line_of_code.html",
    "href": "slides/lec_1_images/first_line_of_code.html",
    "title": "Introduction to the diamonds dataset",
    "section": "",
    "text": "You own a jewelry business and are working to price your diamonds. To facilitate, you explore the diamond dataset in R and pay special attention to the cost of the diamond. Let’s explore together."
  },
  {
    "objectID": "slides/lec_1_images/first_line_of_code.html#what-should-the-price-of-your-diamonds-be",
    "href": "slides/lec_1_images/first_line_of_code.html#what-should-the-price-of-your-diamonds-be",
    "title": "Introduction to the diamonds dataset",
    "section": "What should the price of your diamonds be?",
    "text": "What should the price of your diamonds be?\nBased upon the above plot, and since the diamonds are nice, they should all cost above $150,000, right?"
  },
  {
    "objectID": "slides/01_introduction.html#name-the-document",
    "href": "slides/01_introduction.html#name-the-document",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Name the document",
    "text": "Name the document\nName the document “lec_01” and hit create\n\nNaming the document"
  },
  {
    "objectID": "slides/01_introduction.html#insert-an-r-code-chuck",
    "href": "slides/01_introduction.html#insert-an-r-code-chuck",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Insert an R code chuck",
    "text": "Insert an R code chuck\nInsert a code chunk\n\nInsert code chunk"
  },
  {
    "objectID": "slides/01_introduction.html#write-your-first-line-of-coding",
    "href": "slides/01_introduction.html#write-your-first-line-of-coding",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Write your first line of coding",
    "text": "Write your first line of coding\nClick here or the qr code below to write your first line of code\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/01_introduction.html#what-if-it-breaks",
    "href": "slides/01_introduction.html#what-if-it-breaks",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "What if it breaks?",
    "text": "What if it breaks?\nUse the QR code below or click here.\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_02.html#why",
    "href": "slides/lect_02.html#why",
    "title": "Lec 2 - The here package and adding your own data",
    "section": "Why?",
    "text": "Why?\nToday we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")"
  },
  {
    "objectID": "slides/lect_02.html#including-your-own-data",
    "href": "slides/lect_02.html#including-your-own-data",
    "title": "Lec 2 - The here package and adding your own data",
    "section": "Including your own data",
    "text": "Including your own data\nTo add data to your directory, first create a folder that\n\nFigure @ref(fig:3) Adding a folder.and name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R."
  },
  {
    "objectID": "slides/lect_02.html#importing-data",
    "href": "slides/lect_02.html#importing-data",
    "title": "Lec 2 - The here package and adding your own data",
    "section": "Importing data",
    "text": "Importing data\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "documents/about_R.html",
    "href": "documents/about_R.html",
    "title": "About R",
    "section": "",
    "text": "The R programming language was first released on [29 February 2000](https://www.hermetic.ch/y2k/feb29.htm). [Ross Ihaka](https://en.wikipedia.org/wiki/Ross_Ihaka) and [Robert Gentleman](https://en.wikipedia.org/wiki/Robert_Gentleman_(statistician)) wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. [R is now an internationally recognized language used all over the world](https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html). It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on [CRAN](https://cran.r-project.org/)."
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Department of Data Science and Statistics at Wharton go to the UPDATE website, UPDATE."
  },
  {
    "objectID": "ae/ae-0-movies.html",
    "href": "ae/ae-0-movies.html",
    "title": "Movie budgets and revenues",
    "section": "",
    "text": "Important\n\n\n\nThis application exercise is a demo only. You do not have a corresponding repository for it and you’re not expected to turn in anything for it.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB)."
  },
  {
    "objectID": "ae/ae-0-movies.html#data",
    "href": "ae/ae-0-movies.html#data",
    "title": "Movie budgets and revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies <- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies\n\n# A tibble: 7,668 × 15\n   name   rating genre  year released score  votes director writer star  country\n   <chr>  <chr>  <chr> <dbl> <chr>    <dbl>  <dbl> <chr>    <chr>  <chr> <chr>  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.2 e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.3 e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# … with 7,658 more rows, and 4 more variables: budget <dbl>, gross <dbl>,\n#   company <chr>, runtime <dbl>\n\n\nThe ___ dataset has ___ observations and ___ variables."
  },
  {
    "objectID": "ae/ae-0-movies.html#analysis",
    "href": "ae/ae-0-movies.html#analysis",
    "title": "Movie budgets and revenues",
    "section": "Analysis",
    "text": "Analysis\n\nGross over time\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list <- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\nThen, we will filter for these genres and visualize the average gross revenue over time.\n\nmovies %>%\n  filter(genre %in% genre_list) %>% \n  group_by(genre,year) %>%\n  summarise(avg_gross = mean(gross)) %>%\n  ggplot(mapping = aes(x = year, y = avg_gross, color= genre)) +\n    geom_point() + \n    geom_line() +\n    scale_color_viridis_d() +\n    scale_y_continuous(labels = label_dollar()) +\n    labs(\n      x = \"Year\",\n      y = \"Average Gross Revenue (US Dollars)\",\n      color = \"Genre\",\n      title = \"Gross Revenue Over Time\"\n    )\n\n`summarise()` has grouped output by 'genre'. You can override using the\n`.groups` argument.\n\n\nWarning: Removed 47 rows containing missing values (geom_point).\n\n\nWarning: Removed 23 row(s) containing missing values (geom_path).\n\n\n\n\n\nThe plot suggests …\n\n\nBudget and gross\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies %>%\n  filter(genre %in% genre_list, budget > 0) %>% \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d() +\n  labs(\n    x = \"Log-transformed Budget\",\n    y = \"Log-transformed Gross Revenue\"\n  )\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 35 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 35 rows containing missing values (geom_point)."
  },
  {
    "objectID": "ae/ae-0-movies.html#exercises",
    "href": "ae/ae-0-movies.html#exercises",
    "title": "Movie budgets and revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nIn the remaining time, discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)?"
  },
  {
    "objectID": "ae/ae-0-movies.html#appendix",
    "href": "ae/ae-0-movies.html#appendix",
    "title": "Movie budgets and revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies %>% \n  distinct(genre) %>%\n  arrange(genre) %>% \n  datatable()"
  },
  {
    "objectID": "ae/ae-0-first_line_of_code.html",
    "href": "ae/ae-0-first_line_of_code.html",
    "title": "Introduction to the diamonds dataset",
    "section": "",
    "text": "Scenario\nYou own a jewelry business and are working to price your diamonds. To facilitate, you explore the diamond dataset in R and pay special attention to the cost of the diamond. Let’s explore together.\nTo accomplish this, please paste each line of code into your RStudio instance, and answer the accompanying questions.\n\n\nCoding basics\nGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread.\n\nWhen writing code, load all libraries first.\n“##” is used to write comments in R and should be used to justify next steps and anything unusual or unexpected steps\nComments are really important and are notes to your future self to remind you about steps that you took and decisions that you made.\n\n\n## loading library\nlibrary(tidyverse) # for data analysis and visualisation\n\n\n\nData\nThe diamonds dataset includes basic information about 53940 diamonds including price and other characteristics.\n\n## View the dataset in a separate tab\nglimpse(diamonds)\n\nThe ___ dataset has ___ observations and ___ variables.\n\n## What are the variables in this dataset?\n?diamonds\n\n\nWhat do the “4 c’s” of every diamond mean? What kind of variables are they? (hint: This video may help, copy this into your notes under the title data types)\n\nggplot is an R package that is used to create data visualizations. We will be using it throughout this course. The basic format for every ggplot command is:\n\n## DO NOT COPY INTO YOUR QUARTO DOCUMENT\n## THIS IS TO SHOW YOU THE BASIC FORMAT OF ALL ggplots\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\n\n\n## What is the distribution of price?\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price), binwidth = 1) \n\n\nWhat kind of variable is price? What happens if you draw a histogram with another kind of variable?\n\n\n## What happens if you draw a histogram with a different type of variable?\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = OTHER_VAR), binwidth = 1) \n\n\nWhat does the binwidth in the geom_histogram() function do? (hint: draw multiple plots changing this value) What binwidth value is most appropriate for this data?\n\n\n## Find an appropriate binwidth\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price), binwidth = OTHER_VALUE) \n\nThe distribution of diamond prices is right skewed (long right tail).\n\nIn your notes, copy these histograms and the words used to describe them.\n\nOne interesting feature of this graph is the dip in diamonds priced at about $1000. Let’s explore this a little further and look at some basic dplyr commands.\nThe pipe operator “%>%” tells R to take the output from one function and sends it to the input in the next function.\n\n## Filtering on price\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% \n  View()\n\n\nWhat does the filter function do?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  View()\n\n\nWhat does this “%/%” operator do? (hint: run 10 %/% 3, 10 %/% 5, 7 %/% 3, 7 %/% 5 in the console)\nWhat does the mutate function do? (hint: pay special attention to the dimensions of the data)\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  View()\n\n\nWhat does the select function do?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  count(price_hundred) %>% ## Count\n  View()\n\n\nCan you identify the values where the dip is using the information above? Why or why not?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  mutate(price_remainder = price %% 100) %>% ## Finding price_remainder\n  count(price_hundred, price_remainder) %>% ## Count\n  View()\n\n10. What does the “%%” operator do?\n\nCan you identify the values where the dip is using the information above? Why or why not?\n\nCut may impact upon price\n\n## Cut and price\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price, color = cut, fill = cut),\n                 binwidth = 100) \n\n\nWhich cut do you suspect is the most common in the dataset? How many diamonds with that cut are in the dataset?\n\n\n## Most common cute\ndiamonds %>% \n  INSERT_FUNCTION_HERE(cut)\n\n\nThe variables color or clarity might impact upon the price. Draw a histogram and color it using one of them.\n\n\n## Impact of color and clarity\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price, color = VAR_NAME, \n                               fill = VAR_NAME), \n                 binwidth = YOUR_BIN_WIDTH) \n\n\nWhat do the fill and color inputs do in the above coding?\nWhat kind of variables should we use for the fill and color inputs? What happens if another type of variable is used?\n\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_histogram(mapping = aes(x = price, color = VAR_NAME, \n                                   fill = VAR_NAME), \n                     binwidth = YOUR_BIN_WIDTH) \n\nSo far we have been looking at only 1 continuous variable. To look at two continous variables, we draw scatterplots.\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_point(mapping = aes(x = price, y = depth)) \n\n\nWhat kinds of variables do you think you could use to color this plot? Please use an appropriate variable from diamonds dataset and do so.\n\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_point(mapping = aes(x = price, y = depth))"
  },
  {
    "objectID": "ae/ae-0-first_line_of_code.html#exercises",
    "href": "ae/ae-0-first_line_of_code.html#exercises",
    "title": "Introduction to the diamonds dataset",
    "section": "Exercises",
    "text": "Exercises\n\nWhat do the “4 c’s” of every diamond mean? What kind of variables are they? (hint: This video may help)\nWhat do the inputs (stackratio, alpha, and stadir) in the geom_dotplot() function do? (hint: draw multiple plots changing the values)\nBased upon the above plot, how much should your charge for your diamonds? Why?"
  },
  {
    "objectID": "course-syllabus.html#lectures",
    "href": "course-syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nThe goal of the lectures is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded. In addition to application exercises will be periodic activities to help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. If you are in need of a loaner laptop please seek support here."
  },
  {
    "objectID": "course-syllabus.html#name-tags",
    "href": "course-syllabus.html#name-tags",
    "title": "Syllabus",
    "section": "Name tags",
    "text": "Name tags\nEvery one of you are important to me. To facilitate interactions, I would like to learn your names. To help with this, please wear name tags in class that include pronouns so that I can call you by your name and begin to connect with each of you."
  },
  {
    "objectID": "slides/01_introduction.html#text",
    "href": "slides/01_introduction.html#text",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Text",
    "text": "Text"
  },
  {
    "objectID": "slides/01_introduction.html#workspace-image",
    "href": "slides/01_introduction.html#workspace-image",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Workspace image",
    "text": "Workspace image\n\nSaving workspace"
  },
  {
    "objectID": "slides/01_introduction.html#rainbow-parenthesis",
    "href": "slides/01_introduction.html#rainbow-parenthesis",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Rainbow parenthesis",
    "text": "Rainbow parenthesis\n\nParenthesis are important"
  },
  {
    "objectID": "slides/01_introduction.html#code-font",
    "href": "slides/01_introduction.html#code-font",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Code font",
    "text": "Code font\n\nUpdate background and font color of code"
  },
  {
    "objectID": "slides/01_introduction.html#panel-layout",
    "href": "slides/01_introduction.html#panel-layout",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Panel layout",
    "text": "Panel layout\n\nUpdate options"
  },
  {
    "objectID": "slides/01_introduction.html#another-attempt",
    "href": "slides/01_introduction.html#another-attempt",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Another attempt",
    "text": "Another attempt\n{background-image=“https://www.purina.com.au/-/media/project/purina/main/breeds/dog/dog_boston-terrier_desktop.jpg?h=475&la=en&w=825&hash=DC3F38D08CCE086118327D827C002A62” background-size=“cover”}"
  },
  {
    "objectID": "slides/01_introduction.html#text-background-image-httpsgithub.comstats1010-f22websiteblobmainslideslec_1_imageswitten_cs.png-background-sizecover",
    "href": "slides/01_introduction.html#text-background-image-httpsgithub.comstats1010-f22websiteblobmainslideslec_1_imageswitten_cs.png-background-sizecover",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Text {background-image= “https://github.com/stats1010-f22/website/blob/main/slides/lec_1_images/witten_CS.png” background-size=“cover”}",
    "text": "Text {background-image= “https://github.com/stats1010-f22/website/blob/main/slides/lec_1_images/witten_CS.png” background-size=“cover”}"
  },
  {
    "objectID": "slides/01_introduction.html#pane-layout",
    "href": "slides/01_introduction.html#pane-layout",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Pane layout",
    "text": "Pane layout\n\nUpdate panes and their layout"
  },
  {
    "objectID": "course-support.html#lectures",
    "href": "course-support.html#lectures",
    "title": "Course support",
    "section": "Lectures",
    "text": "Lectures\nIf you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-canvas",
    "href": "course-support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas, Gradescope, or Zoom, contact Wharton Student Computing. You can also access the self-service help documentation for Zoom here, Canvas here, and for Gradescope here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-2.html#participate",
    "href": "weeks/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 2"
  },
  {
    "objectID": "weeks/week-2.html#practice",
    "href": "weeks/week-2.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\n📋 diamonds"
  },
  {
    "objectID": "weeks/week-2.html#perform",
    "href": "weeks/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html",
    "href": "ae/ae-1-dcbikeshare.html",
    "title": "AE 02: Bike rentals in DC",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-1-dcbikeshare-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#bike-rentals-in-dc",
    "href": "ae/ae-1-dcbikeshare.html#bike-rentals-in-dc",
    "title": "AE 02: Bike rentals in DC",
    "section": "Bike rentals in DC",
    "text": "Bike rentals in DC\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#data",
    "href": "ae/ae-1-dcbikeshare.html#data",
    "title": "AE 02: Bike rentals in DC",
    "section": "Data",
    "text": "Data\nOur dataset contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare <- read_csv(\"data/dcbikeshare.csv\")"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#daily-counts-and-temperature",
    "href": "ae/ae-1-dcbikeshare.html#daily-counts-and-temperature",
    "title": "AE 02: Bike rentals in DC",
    "section": "Daily counts and temperature",
    "text": "Daily counts and temperature\n\nExercise 1\nVisualize the distribution of daily bike rentals and temperature as well as the relationship between these two variables.\n\nggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250)\n\n\n\nggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point()\n\n\n\n\n\n\nExercise 2\nDescribe the distribution of daily bike rentals and the distribution of temperature based on the visualizations created in Exercise 1. Include the shape, center, spread, and presence of any potential outliers.\n[Add your answer here]\n\n\nExercise 3\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day.\n[Add your answer here]\n\n\nExercise 4\nDescribe the relationship between daily bike rentals and temperature based on the visualization created in Exercise 1. Comment on how we expect the number of bike rentals to change as the temperature increases.\n[Add your answer here]\n\n\nExercise 5\nSuppose you want to fit a model so you can use the temperature to predict the number of bike rentals. Would a model of the form\n\\[\\text{count} = \\beta_0 + \\beta_1 ~ \\text{temp\\_orig} + \\epsilon\\]\nbe the best fit for the data? Why or why not?\nNo."
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#daily-counts-temperature-and-season",
    "href": "ae/ae-1-dcbikeshare.html#daily-counts-temperature-and-season",
    "title": "AE 02: Bike rentals in DC",
    "section": "Daily counts, temperature, and season",
    "text": "Daily counts, temperature, and season\n\nExercise 6\nIn the raw data, seasons are coded as 1, 2, 3, 4 as numerical values, corresponding to winter, spring, summer, and fall respectively. Recode the season variable to make it a categorical variable (a factor) with levels corresponding to season names, making sure that the levels appear in a reasonable order in the variable (i.e., not alphabetical).\n\n# add code developed during livecoding here\n\n\n\nExercise 7\nNext, let’s look at how the daily bike rentals differ by season. Let’s visualize the distribution of bike rentals by season using density plots. You can think of a density plot as a “smoothed out histogram”. Compare and contrast the distributions. Is this what you expected? Why or why not?\n\n# add code developed during livecoding here\n\n[Add your answer here]\n\n\nExercise 8\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, first create a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here\n\n\n\nExercise 9\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?\n\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#modeling",
    "href": "ae/ae-1-dcbikeshare.html#modeling",
    "title": "AE 02: Bike rentals in DC",
    "section": "Modeling",
    "text": "Modeling\n\nExercise 10\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here\n\n\n\nExercise 11\nUsing the data you filtered in Exercise 10, fit a linear model for predicting daily bike rentals from temperature for this season.\n\n# add code developed during livecoding here\n\n\n\nExercise 12\nUse the output to write out the estimated regression equation.\n[Add your answer here]\n\n\nExercise 13\nInterpret the slope in the context of the data.\n[Add your answer here]\n\n\nExercise 14\nInterpret the intercept in the context of the data.\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-1-dcbikeshare.html#synthesis",
    "href": "ae/ae-1-dcbikeshare.html#synthesis",
    "title": "AE 02: Bike rentals in DC",
    "section": "Synthesis",
    "text": "Synthesis\n\nExercise 15\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2022. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?\n[Add your answer here]\n\nThe following exercises will be completed only if time permits.\n\n\nExercise 16\nPick another season. Based on the visualization in Exercise 8, would you expect the slope of the relationship between temperature and daily bike rentals to be smaller or larger than the slope of the model you’ve been working with so far? Explain your reasoning.\n[Add your answer here]\n\n\nExercise 17\nFor this season you picked in Exercise 16, fit a linear model for predicting daily bike rentals from temperature. Note, you will need to filter your data for this season first. Use the output to write out the estimated regression equation and interpret the slope and the intercept of this model.\n\n# add your code here\n\n[Add your answer here]"
  },
  {
    "objectID": "slides/here_lecture.html#why",
    "href": "slides/here_lecture.html#why",
    "title": "Here lecture",
    "section": "Why?",
    "text": "Why?\nToday we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")"
  },
  {
    "objectID": "slides/here_lecture.html#including-your-own-data",
    "href": "slides/here_lecture.html#including-your-own-data",
    "title": "Here lecture",
    "section": "Including your own data",
    "text": "Including your own data\nTo add data to your directory, first create a folder that\n\nFigure @ref(fig:3) Adding a folder.and name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R."
  },
  {
    "objectID": "slides/here_lecture.html#importing-data",
    "href": "slides/here_lecture.html#importing-data",
    "title": "Here lecture",
    "section": "Importing data",
    "text": "Importing data\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_04.html#definition-of-numerical-variable",
    "href": "slides/lect_04.html#definition-of-numerical-variable",
    "title": "Lec 4 - Exploring numerical data",
    "section": "Definition of numerical variable",
    "text": "Definition of numerical variable\nA numerical or quantitative variable is a variable that can be measured."
  },
  {
    "objectID": "slides/lect_04.html#the-purpose-of-exploratory-data-analysis-eda",
    "href": "slides/lect_04.html#the-purpose-of-exploratory-data-analysis-eda",
    "title": "Lec 4 - Exploring numeric data",
    "section": "The purpose of Exploratory Data Analysis (EDA)",
    "text": "The purpose of Exploratory Data Analysis (EDA)\n\nEDA is about learning the structure of a dataset through a series of numerical and graphical techniques.\nWhen you do EDA, you’ll look for both\n\ngeneral trends and\ninteresting outliers in your data.\n\n\ngenerate questions that will help inform subsequent analysis."
  },
  {
    "objectID": "ae/ae-5.html",
    "href": "ae/ae-5.html",
    "title": "The birthday simulation (AE-5)",
    "section": "",
    "text": "Computers let you assemble, manipulate, and visualize data sets, all at speeds that would have wowed yesterday’s scientists. In short, computers give you superpowers! But if you wish to use them, you’ll need to pick up some programming skills. Steve Job said that “computers are bicycles for our minds” because the efficiency rating of humans on bicycles is so incredible, and computers give us similar powers.\nOne reason computers are so incredible is that they allow us to simulate a multitude of events. Today we will simulate the probability that two of you in this section of Stat1010 have the same birthdays.\n\nlibrary(tidyverse) # for data manipulation\nlibrary(vctrs) # to find the length of a tibble\n\nSuppose you are in a classroom with 100 people. If we assume this is a randomly selected group of 100 people, what is the chance that at least two people have the same birthday? Although it is somewhat advanced, we can deduce this mathematically. We will do this later. Here we use a Monte Carlo simulation. For simplicity, we assume nobody was born on February 29. This actually doesn’t change the answer much.\nFirst, note that birthdays can be represented as numbers between 1 and 365, so a sample of 100 birthdays can be obtained like this:\n\nall_bdays <- as_tibble(1:365) # data from where we can sample\n\nbdays_class <- \n  all_bdays %>% # data from where to sample\n  slice_sample(n = 100, replace = TRUE) # sample of size 100 with replacement\n\nTo check if in this particular set of 100 people we have at least two with the same birthday, we can use the functions group_by and filter, which returns a tibble with a vector of duplicated dates. Here is an example:\n\nbdays_class %>% \n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) # those have more than 1\n\nTo estimate the probability of a shared birthday in the group, we repeat this experiment by sampling sets of 100 birthdays over and over. Prior to replicating, we need to write this as a function.\n\nbdays_dups <- \n  all_bdays %>% # data from where to sample\n  slice_sample(n = 100, replace = TRUE) %>% # take a sample of n 100\n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) %>% # those have more than 1\n  vec_n(.) # the number that are duplicated\n\nA function has an input (in this case \\(n\\))\n\nWhat does \\(n\\) represent in this coding?\n\n\nnum_of_same_birthdays <- function(n){\n  all_bdays %>% # data from where to sample\n  slice_sample(n = n, replace = TRUE) %>% # take a sample\n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) %>% # those have more than 1\n  vec_size(.)  # the number that are duplicated\n}\n\nTo run this function, we do this:\n\nnum_of_same_birthdays(10) # run the function\n\n\nHow many students are there in class today?\nRun the coding above but include the number of students in class today.\n\nThe law of large numbers says that if we do this many times we should have an estimate of the number of people that have the same birthdays in class today. The function replicate can be used to run functions multiple times.\n\nB <- 500 # the number of times to run\nresults <- replicate(B, # replicate this number of times\n          ifelse( # if there are some duplicated birthdays\n            num_of_same_birthdays(50) >= 1, # our function\n            1, # give me a 1\n            0)) # if not, give me a 0\n\nmean(results) # take the mean\n\nWere you expecting the probability to be this high?\nPeople tend to underestimate these probabilities. To get an intuition as to why it is so high, think about what happens when the group size is close to 365. At this stage, we run out of days and the probability is one.\nSay we want to use this knowledge to bet with friends about two people having the same birthday in a group of people. When are the chances larger than 50%? Larger than 75%?\nLet’s create a look-up table. We can create a function to compute this for any group size. This function runs our function \\(500\\) times for every value of $n$. Statisticians will usually do this \\(10000\\) times, but this will take a very very very very looooooooooonnnnnggggg time, so we are simplifying.\n\ncompute_prob <- # name the function\n  function(n, B = 500){ # function inputs\n  results <- # store results\n    replicate(B, # run num_of_same_birthdays B times \n              ifelse( # if there are some duplicated birthdays\n            num_of_same_birthdays(n) >= 1, # our function\n            1, # give me a 1\n            0)) # if not, give me a 0\n  \n  mean(results) # find the mean\n}\n\nUsing the function map_dbl, we can perform element-wise operations on any function. Note that this may take awhile to run.\n\nn <- seq(1, 60) # which values of n are important\nprob <- # save the results as prob\n  map_dbl(n,  # for each value of n \n          compute_prob) # run the function\n\nWe can now make a plot of the estimated probabilities of two people having the same birthday in a group of size n:\n\nas_tibble(n, prob) %>% # the format for ggplot\n  ggplot() + # draw a graph\n  geom_point(aes(x = n, y = prob)) # of points\n\nNow let’s compute the exact probabilities rather than use Monte Carlo approximations. Not only do we get the exact answer using math, but the computations are much faster since we don’t have to generate experiments.\nTo make the math simpler, instead of computing the probability of it happening, we will compute the probability of it not happening, or the compliment. For this, we use the multiplication rule.\nLet’s start with the first person. The probability that person 1 has a unique birthday is 1. The probability that person 2 has a unique birthday, given that person 1 already took one, is 364/365. Then, given that the first two people have unique birthdays, person 3 is left with 363 days to choose from. We continue this way and find the chances of all \\(n\\) people having a unique birthday is:\n\\[1×\\frac{364}{365}×\\frac{363}{365}…\\frac{365−n+1}{365}\\] We can write a function that does this for any number:\n\nexact_prob <- function(n){\n  1 - \n    prod(365:(365-n+1))/ # the product from the numerator above\n    365^(n) # the denominator from above\n}\n\n\nRun this coding for the number of people that are in class today.\n\nNow, we run this on multiple values of \\(n\\)\n\neprob <- map_dbl(n, exact_prob) # run on multiple values of n\n\nNext we plot the results.\n\nas_tibble(n, eprob) %>% # the format for ggplot\n  ggplot() + # draw a graph\n  geom_point(aes(x = n, y = eprob)) # of points\n\nOn mercury, the year is only 88 days. Update the coding above to simulate the expected number of people with the same birthdays on Mercury.\nAssuming we have the same number of people, would you expect the number of people with the same birthdays to be higher or lower than those on earth?"
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "📖 Read chapter 14 of Introduction to Data Science\n📖 Read chapter 2 of Probability, Statistics, and Data: A fresh approach using R"
  },
  {
    "objectID": "weeks/week-4.html#participate",
    "href": "weeks/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 5\n🖥️ Lecture 6"
  },
  {
    "objectID": "weeks/week-4.html#practice",
    "href": "weeks/week-4.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\n📋 Exploring probabilities\n📋 The birthday simulation"
  },
  {
    "objectID": "weeks/week-4.html#perform",
    "href": "weeks/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test - week 3\n✍️ HW 1 - Titanic\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "📖 Read chapter 4 of Introduction to Modern Statistics\n📖 Read chapter 5 of Introduction to Modern Statistics"
  },
  {
    "objectID": "weeks/week-3.html#participate",
    "href": "weeks/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 3\n🖥️ Lecture 4"
  },
  {
    "objectID": "weeks/week-3.html#practice",
    "href": "weeks/week-3.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\n📋 Exploring qualitative variables\n📋 Exploring numeric variables"
  },
  {
    "objectID": "weeks/week-3.html#perform",
    "href": "weeks/week-3.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test - week 3\n✍️ HW 6 - Statistics Experience\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "hw/hw-6.html",
    "href": "hw/hw-6.html",
    "title": "HW 6 - Statistics Experience",
    "section": "",
    "text": "The world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience\n2️⃣ Make a slide summarizing on your experience\nYou must complete both parts to receive credit."
  },
  {
    "objectID": "hw/hw-6.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/hw-6.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "HW 6 - Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professional in industry, a speaker from the RLadies directory, or other local data science groups.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\nrstudio::conf 2022\nrstudio::global 2021 talks\nrstudio::conf 2020 talks\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask your professor if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team. Kaggle and Drivendata both lead online competitions. This is a comprehensive list of hackathons, and more information can be found here or here.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask your professor to make sure it counts toward the experience. Many of these books are available through the Van Pelt Library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some don’t by Nate Silver\nHow Charts Lie by Alberto Cairo\nList of books about data science ethics\n\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a project for your TidyTuesday submission - The Quarto file with all the code needed to reproduce your visualization. - A pdf that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n✅ The visualization should include features or customization that are beyond what we’ve done in class ."
  },
  {
    "objectID": "hw/hw-6.html#part-2-summarize-your-experience",
    "href": "hw/hw-6.html#part-2-summarize-your-experience",
    "title": "HW 6 - Statistics Experience",
    "section": "Part 2: Summarize your experience",
    "text": "Part 2: Summarize your experience\nMake one slide summarizing your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nName and brief description of the event/podcast/competition/etc.\nSomething you found new, interesting, or unexpected\nHow the event/podcast/competition/etc. connects to something we’ve done in class.\nCitation or link to web page for event/competition/etc.\n\nClick here to see a template to help you get started on your slide. Your slide does not have to follow this exact format; it just needs to include the information mentioned above and be easily readable (i.e. use a reasonable font size!). Creativity is encouraged!"
  },
  {
    "objectID": "hw/hw-6.html#submission",
    "href": "hw/hw-6.html#submission",
    "title": "HW 6 - Statistics Experience",
    "section": "Submission",
    "text": "Submission\nSubmit the reflection as a PDF under the HW 6 - Statistics Experience assignment on Convas by Tuesday, Nov 22 at 5 pm ET. It must be submitted by the deadline on Canvas to be considered for grading."
  },
  {
    "objectID": "hw/hw-1.html",
    "href": "hw/hw-1.html",
    "title": "HW 1 - Titanic dataset",
    "section": "",
    "text": "For this homework assignment we will be exploring the Titanic dataset.\n\n\nIn this assignment, you will…\n\nDownload and import data into R\nExplore categorical variables\nCompute the expected counts of a \\(\\chi^2\\) distribution and\nPerform a \\(\\chi^2\\) test on some variables"
  },
  {
    "objectID": "hw/hw-1.html#getting-started",
    "href": "hw/hw-1.html#getting-started",
    "title": "HW 1 - Titanic dataset",
    "section": "Getting started",
    "text": "Getting started\n\nLog in to RStudio\nClick on your Stat1010.Rproj.\nGo to File ➛ New File ➛ Quarto Document and name the document hw-1 click create"
  },
  {
    "objectID": "hw/hw-1.html#packages",
    "href": "hw/hw-1.html#packages",
    "title": "HW 1 - Titanic dataset",
    "section": "Packages",
    "text": "Packages\nThe following packages will be used in this assignment:\n\nlibrary(tidyverse) # for data manipulation and data visualization\nlibrary(here) # to organize files"
  },
  {
    "objectID": "hw/hw-1.html#data-titanic",
    "href": "hw/hw-1.html#data-titanic",
    "title": "HW 1 - Titanic dataset",
    "section": "Data: Titanic",
    "text": "Data: Titanic\nOn April 15, 1912, the largest passenger liner ever made collided with an iceberg during her maiden voyage. When the Titanic sank it killed 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck resulted in such loss of life wasthat there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others.\nThe titanic.csv file contains data for 887 of the real Titanic passengers. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their passenger-class, their sex, and the fare they paid\n\nPclass: The class of passengers on the titanic, with \\(1st\\) being the highest class, and \\(3rd\\) the lowest.\nSurvived: A variable that records whether or not a passenger survived the sinking of the titanic.\n\nPart 1: Download and import the data\n\nDownload the file into your Stat1010 R project in the data folder.\nImport your data into R.\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document to ensure that the data loads without errors.\n\n\nPart 2: Exploring categorical variables\n\nHow many observations and how many variables in this dataset?\nClassify all the variables into two categories: qualitative or quantitative\nHow many levels of passenger class are there in the variable?\nHow many passengers survived the sinking of the titanic?\nMake a contingency table of class and survival. Which combination of class and survival is the most common?\n\nWhat proportion of \\(3rd\\) class passengers survived?\nWhat proportion of \\(1st\\) class passengers survived?\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document.\n\n\n\nDraw a plot that conditions on class and displays the proportions of each that survived and update labels. What does the plot suggest regarding the chance of survival and your class? Does it suggest that they are associated?\nAssuming Survived and Pclass are independent, write R coding to find the expected counts for all cells of the contingency table. (Hint: you will need to use the rowSums(.[2:3]) and colSums(.[2:4]) functions, depending on the order that you compute the two.)\nPerform a \\(\\chi^2\\) test on the two variables Survived and Pclass. Include both \\(H_0\\) and \\(H_A\\) and interpret the \\(p-value\\). What conclusions can you draw about the independence of Survived and Pclass?\n\n\n\n\n\n\n\nWarning\n\n\n\nBefore submitting, make sure you render your document,"
  },
  {
    "objectID": "hw/hw-1.html#submission",
    "href": "hw/hw-1.html#submission",
    "title": "HW 1 - Titanic dataset",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nThen submit the pdf following the link on the course website."
  },
  {
    "objectID": "hw/hw-1.html#grading",
    "href": "hw/hw-1.html#grading",
    "title": "HW 1 - Titanic dataset",
    "section": "Grading",
    "text": "Grading\nTotal points available: 25 points.\n\n\n\nComponent\nPoints\n\n\n\n\nPart 1 Qu 1\n2\n\n\nPart 1 Qu 2\n3\n\n\nPart 2 Qu 1\n2\n\n\nPart 2 Qu 2\n2\n\n\nPart 2 Qu 3\n1\n\n\nPart 2 Qu 4\n2\n\n\nPart 2 Qu 5 Pt 1\n1\n\n\nPart 2 Qu 5 Pt 2\n1\n\n\nPart 2 Qu 6\n3\n\n\nPart 2 Qu 7\n4\n\n\nPart 2 Qu 8\n4"
  },
  {
    "objectID": "ae/ae-2-exploring-categorical-vars.html",
    "href": "ae/ae-2-exploring-categorical-vars.html",
    "title": "Exploring categorical data AE-2",
    "section": "",
    "text": "Load packages, data\n\n## loading libraries\nlibrary(tidyverse) # for data analysis and visualisation\nlibrary(here) # to organize files\nlibrary(praise) # for ocassional good vibes!\n\nLet’s look at the data on the web prior to importing it and also to ensure that we know what it should look like when it is imported into R.\nNow press “raw”\n\nThen copy the url:\n\nDownload the file by inserting the URL below:\n\nfs::dir_create(here(\"data\")) # create a data folder \ndownload.file(\n  url = URL_HERE, # url of file to download\n  destfile = here(\"data/comics.csv\") # directory/name_of_file\n)\n\nThen click on the data folder in the “Files” panel.\n\nDouble click on “comics.csv” and click on “Import Dataset…”\n\nCheck the data in the “Data Preview” pane and ensure that it looks as it should.\n\nNext, click on the clipboard icon to copy the code from the “Code Preview” pane, then click “Import”.\n\n#PASTE THE CODE FROM \"Code Preview\" HERE\n\n\n\nData\nThe comics dataset includes basic information scraped from the superheroDb for a kaggle competition.\n\n## An overview of the dataset and type of variables\nglimpse(comics)\n\nThe first superhero is named “A-Bomb” he is male, with yellow eyes, human, with no hair. Marvel Comics created him and his skin color is not listed, but his height and weight are.\n\nAre there any differences between the data on the website above and the one in R? What are they? (Hint: which function can you use to see the whole dataset?)\n\npraise()\n\nThe ___ dataset has ___ observations and ___ variables.\nClassify all variables in the dataset as either: quantitative discrete, quantitative continuous, qualitative nominal, qualitative ordinal. Which of these variables is also categorical?\n\n\n\nCounts\n\nHow many publishers are there in this dataset?\n\ncomics %>% \n  distinct(Publisher) # finds the levels of publisher\n\nHow many levels of the variable Alignment are there in this dataset?\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\n\nA common way to represent the number of cases that fall into each combination of levels of two categorical variables, such as these, is with what’s called a “contingency table.” Note that each superhero appears in exactly one cell, statisticians call this mutually exclusive.\n\npraise()\n\n\nWhich is the most common category in this contingency table? How many superheros are in that category? (note: please look at both of the next two blocks of code.)\n\ncomics %>% \n  count(Publisher, Alignment) %>% # counts all combinations\n  View()\n\n\nThe long format above is difficult to see clearly. The format we normally use for contingency tables is the wide format.\nThe third line of coding below takes a long table and makes it wide by moving the Alignment variable to the columns, and filling the values of the table with the count variable (n). The names_from argument tells R where the names of the new columns are coming from (i.e. what variable), and the values_from argument tells R where the values in the table are coming from. Here, the values we want in our table are stored as a variable labeled n in our table.\n\ncomics %>% \n  count(Publisher, Alignment) %>%  # counts all combinations\n  pivot_wider(names_from = Alignment, \n              values_from = n) # pivots from long to wide \n\n\nThere are about ___ good superheros for each bad superhero.\n\nggplot(data = comics) + # the dataset\n  geom_bar(mapping = aes(x = Alignment)) # a bar chart of Alignment\n\nLook at the next two plots and find the difference between them. What would make you use one plot over the other? Which plot shows that females are much more likely to be good superheros than bad? Which one shows that good superheros are more likely to be missing gender? And which that females are more likely to be good superheros than males? All of these mean that the variables gender and alignment are associated, the value of one impacts upon the value of the other.\n\nggplot(data = comics) + # add the data\n  geom_bar(mapping = aes(x = Gender, # bar chart of gender\n                         fill = Alignment)) +  # colored by alignment\n  labs(title = \"Gender colored with alignment\") # add title\n\n\nggplot(data = comics) + # add the data\n  geom_bar(mapping = aes(x = Alignment, # bar chart of alignment\n                         fill = Gender)) + # colored by gender\n  labs(title = \"Alignment colored with gender\")  # add title\n\n\nWe note that the commonly held belief that gender is binary is no longer the scientific consensus and that gender is a complex spectrum.\n\nStatisticians want to discuss the strength of association of variables. They want to ensure that this association is not the result of random noise, but instead is a function of the underlying population of interest (all superheros).\n\npraise()\n\n\n\nChi-Squared test\nTo test for independence in 2 categorical variables, statisticians use a Chi-squared test. This is a hypothesis test so it has both a null hypothesis (\\(H_0\\)) and an alternative hypothesis (\\(H_A\\)).\n\\(H_0\\) = the variables are independent, there is no relationship between the two categorical variables.\n\\(H_A\\) = Knowing the value of one variable helps to predict the value of the other variable\nJust like a fair court case, where a defendant is assumed to be innocent until proven guilty, here we assume \\(H_0\\) until proven otherwise. The proof that we present at the case is a formula relating the actual values in our sample to what we would expect to get under the independence assumption.\nTo perform a Chi-squared test of independence on gender and alignment we must find the marginal distributions of both gender and alignment.\n\n\nMarginal distribution\n\nThe marginal distribution is the count of each variable.\n\ncomics %>% \n  count(Alignment, Gender) %>% \n  pivot_wider(names_from = Alignment, \n              values_from = n)\n\n\nWe take the original two-way table (with two categorical variables) and added up the cells across each level of align (ie \\(1+7+19+2 = 29\\)) to get the marginal distribution for each variable.\n\ncomics %>% # the dataset\n  count(Gender) # and marginal distribution of gender\n\n\npraise()\n\n\ncomics %>% # the dataset\n  count(Alignment) # and marginal distribution of the Alignment\n\nIf these are independent, we would expect \\(\\frac{200}{29+200+505}\\) of the \\(207\\) (about \\(56.4\\)) bad superheros to be female, and the same proportion of \\(496\\) (about \\(135.1\\)) good superheros to be female, and so on.\n\nAssuming independence of Alignment and Gender, how many good superheros would we expect to be male? (hint: use the “$$” to make\\(\\frac{1}{2}\\))\n\nMore information, including mathematical notation can be found here.\nFortunately, `R` does all of this for us.\n\n# the \"$\" sign pulls out the Gender values and Alignment value from the comics dataset\nchisq.test(comics$Gender, comics$Alignment)\n\nWe get a warning because the missing values (“-”) expected counts are probably quite small. You can safely use the chi-square test with critical values from the chi-square distribution when no more than 20% of the expected counts are less than \\(5\\) and all individual expected counts are 1 or greater. In particular, all four expected counts in a \\(2 \\times 2\\) table should be 5 or greater.\n\npraise()\n\nThe \\(p-value\\) for this test \\(0.0003298\\) is very small which means that we have very strong evidence against \\(H_0\\) — that there is independence between Alignment and Gender — and we can reject the null hypothesis. This suggests that the association between Gender and Alignment is not likely due to chance.\n\nThere are a few characters with missing data “-” in the Alignment and Gender variables? How many are in each?\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\nSince there are only a few missing values (<10%) in each category, there is no reason to keep them especially since our analysis is largely about these two variables.\nWhat does the “!=” operator do?\n\ncomics_filtered <- # assign a name to a new dataset\n  comics %>% # tell R which dataset to start with\n  INSERT_FUNCTION(Alignment != \"-\", # remove \"-\" values in Alignment\n                  Gender != \"-\") # remove \"-\" values in Gender\n\nRemake the “Alignment colored with gender” plot and the “Gender colored with alignment” plots with this new dataset.\nRedo the Chi-Squared test for independence between Alignement and Gender. Include all hypotheses, and computations for at least \\(2\\) expected values. Does this change our conclusion?\n\npraise()\n\nSide-by-side barcharts allow us to represent the counts from a contingency table graphically. Telling R to make a side-by-side barchart involves adding the words position = \"dodge” to the coding from above. Now created the other bar chart side-by-side, the “Gender colored with alignment.” use the comics_filter dataset.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of alignment\n                         fill = INSERT), # colored by gender\n           position = INSERT) + # side_by_side\n  labs(title = \"Alignment colored with gender\")  # add title\n\n\n\n\nProportions\nWe have been focusing mostly on counts. Proportional data is also interesting to explore and it is easy to get R to produce those for us.\n\nWhat combination of Gender and Alignment has the highest proportion? What is the value? What is the sum of all of the proportions in the table below? (Note: Use the View() function to go through each line of code and ensure you know what each step does.)\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>% # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\n\n\n\nConditional proportions\n\nIf we’re curious about systematic associations between variables, we should look to conditional proportions. An example of a conditional proportion is the proportion of female superheroes that are good. To build a table of these conditional proportions, we need to specify a grouping variable before we calculate the proportions. What proportion of female characters are good? What do the rows sum to? (Note: Use the View() function to go through each line of code and ensure you know what each step does.)\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  group_by(Gender) %>% # conditions on gender\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>%  # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\nWhat proportion of good characters are male? What do the columns sum to?\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  group_by(Alignment) %>% # conditions on gender\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>%  # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\n\npraise()\n\nPlotting proportions is similar to the side-by-side bar chart completed earlier. Instead of position = \"dodge\" we use position = \"fill\" . Draw one such plot below using Gender for the x axis and color it using Alignment.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of ?\n                         fill = INSERT), # colored by ?\n           position = INSERT) # fill\n\nNow, change the label of the y axis from count by including the coding\nlabs(y = \"Proportion of superheroes\")\n\npraise()\n\nDoes the above plot condition on gender or alignment? How do you know? (hint: what sums to 1?)\nCondition on the other variable.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of ?\n                         fill = INSERT), # colored by ?\n           position = INSERT)  + # fill\n  lab(y = \"INSERT Y AXIS TITLE HERE\")\n\nAnother way to view the differences in variables is to facet. What is the advantage of a facet plot over a stacked barchart?\n\nggplot(comics) + # which dataset\n  geom_bar(mapping = aes(x = Gender)) + # bar chart of Gender\n  facet_wrap(~Alignment) # broken down by Alignment"
  },
  {
    "objectID": "ae/ae-3.html",
    "href": "ae/ae-3.html",
    "title": "Exploring numeric data (AE-3)",
    "section": "",
    "text": "Important\n\n\n\nThis application exercise is due on 20 Sept at 2:00pm."
  },
  {
    "objectID": "ae/ae-3.html#dotplot",
    "href": "ae/ae-3.html#dotplot",
    "title": "Exploring numeric data (AE-3)",
    "section": "Dotplot",
    "text": "Dotplot\n\nLook at the coding below and one at a time remove each of the dotsize, alpha, and stackdir from the code. What does each of these inputs do? How does each input impact upon the plot?\n\n\nggplot(data = diamonds) + # the data\n  geom_dotplot(mapping = aes(x = price), # plot of price\n               dotsize = 0.005, # make the dots tiny\n               alpha = 0.3, # less opaque\n               stackdir = \"center\") #"
  },
  {
    "objectID": "ae/ae-3.html#dotplot-vs-boxplot",
    "href": "ae/ae-3.html#dotplot-vs-boxplot",
    "title": "Exploring numeric data (AE-3)",
    "section": "Dotplot vs boxplot",
    "text": "Dotplot vs boxplot\nA boxplot provides summary information for the distribution of a variable. Here are some explanations (using different data) showing the purpose of the box portion of the boxplot.\nThe left line of the box is the quartile 1 (\\(Q_1\\)) or Q1 \n\npraise()\n\nThe middle line of the box is the median (\\(Q_2\\)) \nThe right line of the box is the quartile 3 (\\(Q_3\\)) \n\nLooking at the above plots, count the percentage of yellow dots in each of the dotplots. Is there anything interesting about these values?\nCompare and contrast a dotplot and a boxplot? What are the advantages and disadvantages of each? Think carefully about bimodal data and which plot you would use to show that aspect of a variable. Also think about outliers."
  },
  {
    "objectID": "ae/ae-3.html#boxplots",
    "href": "ae/ae-3.html#boxplots",
    "title": "Exploring numeric data (AE-3)",
    "section": "Boxplots",
    "text": "Boxplots\n\nDraw a boxplot of the price data from the diamonds dataset.\n\n\nggplot(data = INSERT) + # the data\n  INSERT(aes(x = INSERT)) # the variable\n\n\nBoxplot descriptions\n\n\nUse the information above to describe the boxplot of price.\n\n\n\nInterquartile range (IQR)\nThe IQR of a variable is the length of the box in a boxplot. \\[ IQR = Q_3 - Q_1\\]\n\npraise()"
  },
  {
    "objectID": "ae/ae-3.html#density-plot",
    "href": "ae/ae-3.html#density-plot",
    "title": "Exploring numeric data (AE-3)",
    "section": "Density plot",
    "text": "Density plot\n\n ggplot(data = diamonds) + # the data\n       geom_density(aes(x = price), # plot of price\n                    bw = 1) # plot of price\n\n\nWhat does the “bw” input in the geom_density function do? What is an appropriate value of “bw” for this data?\n\n\nggplot(data = diamonds) + # the data\n  geom_density(aes(x = price), # plot of price\n               bw = INSERT) + # binwidth\n  facet_wrap(~clarity) # faceting\n\n\nWhat does the above plot suggest about the prices of diamonds for all levels of the variable clarity?\n\n\npraise()\n\n\nDraw a density plot for each value of cut. Describe the distribution of diamond price for each value of cut.\n\n\nggplot(data = diamonds) + # the data\n  geom_density(aes(x = price), # plot of price\n               bw = INSERT) + # binwidth\n  facet_wrap(~INSERT) # faceting"
  },
  {
    "objectID": "ae/ae-3.html#measures-of-center",
    "href": "ae/ae-3.html#measures-of-center",
    "title": "Exploring numeric data (AE-3)",
    "section": "Measures of center",
    "text": "Measures of center\nWe use the summarise() function when we expect the result to be one number.\n\nMean\n\ndiamonds %>% # the dataset\n  summarise(mean = mean(price)) # function that is used to compute mean of price\n\n9, Now compute the means of the variables \\(x\\), \\(y\\), \\(z\\), and \\(carat\\). (hint: You will need to insert a code chunk for each of these variables.)\n\npraise()\n\nLast class we learned about the group_by() and used it to compute conditional probabilities. Today we will use it to compare the means of different subgroups.\n\ndiamonds %>% # the data\n  group_by(cut) %>% # for each value of cut\n  summarise(mean = mean(price), # find the mean\n            median = median(price)) # and the median\n\n\nCompare the average values of price for each level of the cut variable. Considering the distributions of price for each level of cut in question 8, is the grouped mean a good measure of center for each level of cut? Why or why not?\n\n\n\nMedian\n\nHow would you find the overall median of price?"
  },
  {
    "objectID": "ae/ae-3.html#measures-of-spread",
    "href": "ae/ae-3.html#measures-of-spread",
    "title": "Exploring numeric data (AE-3)",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nVariance\nR also computes measures of spread.\n\ndiamonds %>% # the data\n  summarise(var = var(price)) # find the variance\n\nBesides the direct method above, we can also do this computationally, by using the definition and finding the mean, subtracting, and squaring, then dividing.\n\ndiamonds %>% # the data\n  mutate(\n    mean_price = mean(price), # mean of price\n    deviation = price - mean_price, # subtraction from notes\n    deviation_sq = deviation^2) %>% # then square it\n  summarise(\n    mean_sq_deviation = sum(deviation_sq)/ # sum them\n      (nrow(diamonds) - 1)) # divide by n - 1\n\n\nRun each line of code above and ensure that you understand how this computation was developed. This shows us how to find \\(s_{price}^2\\) directly.\nFind \\(s_{x}^2\\), \\(s_{y}^2\\), and \\(s_{z}^2\\) both directly, and computationally: having R do the computation. (hint: you will need to insert 6 code chunks)\n\n\npraise()\n\n\n\nStandard deviation\n\nR also computes the standard deviation \\(s\\) directly:\n\n\n    diamonds %>% # the data\n      summarise(sd = sd(price)) # find the sd\n\nCan you use the computational approach (finding the mean_sq_deviation) from above to find the standard deviation of price \\(s_{price}\\)? (hint: you will need to use the sqrt() operator)\n\n\nIQR\n\nThe \\(IQR\\) can also be computed directly or indirectly:\n\n\ndiamonds %>% # the data\n  summarise(\n    q1 = quantile(price, 0.25), # find Q1\n    q3 = quantile(price, 0.75), # find Q3\n    iqr = q3 - q1 # now the IQR\n  )\n\n\n\nRange\n\ndiamonds %>% # the data\n  summarise(\n    min = min(price), # find min\n    max = max(price), # find max\n    range = max - min # and range\n  )\n\n\nOf all of the measures of spread, which do you think are sensitive to skewed data and outliers? Why?"
  },
  {
    "objectID": "ae/ae-4.html",
    "href": "ae/ae-4.html",
    "title": "Introduction to probability (AE-4)",
    "section": "",
    "text": "One ball will be drawn at random from a box containing: 3 cyan balls, 5 magenta balls, and 7 yellow balls. What is the probability that the ball will be cyan?\nWhat is the probability that the ball will not be cyan?\nInstead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling without replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nNow repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling with replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nTwo events A and B are independent if Pr(A and B)=Pr(A)P(B). Under which situation are the draws independent?\n\nYou don’t replace the draw.\nYou replace the draw.\nNeither\nBoth\n\nSay you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?\nIf you roll a 6-sided die six times, what is the probability of not seeing a 6?"
  },
  {
    "objectID": "slides/lect_04.html#definition-of-numeric-variable",
    "href": "slides/lect_04.html#definition-of-numeric-variable",
    "title": "Lec 4 - Exploring numeric data",
    "section": "Definition of numeric variable",
    "text": "Definition of numeric variable\nA numeric or quantitative variable is a variable that can be measured."
  },
  {
    "objectID": "slides/lec-1.html#meet-the-professor",
    "href": "slides/lec-1.html#meet-the-professor",
    "title": "Welcome to STA 210!",
    "section": "Meet the professor",
    "text": "Meet the professor\n\n\n\n\n\nDr. Mine Çetinkaya-Rundel (she/her)\n\n\n\n\nProfessor of the Practice & Director of Undergraduate Studies, Department of Statistical Science\nAffiliated Faculty, Computational Media, Arts & Cultures\nFind out more at mine-cr.com"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-tas",
    "href": "slides/lec-1.html#meet-the-tas",
    "title": "Welcome to STA 210!",
    "section": "Meet the TAs",
    "text": "Meet the TAs\n\nMartha Aboagye (she/her, UG)\nRich Fremgen (he/him, MS)\nEmily Gentles (she/her, MS)\nSara Mehta (she/her, UG)\nRick Presman (he/him, PhD)\nShari Tian (she/her, UG)\nAaditya Warrier (he/him, UG)"
  },
  {
    "objectID": "slides/lec-1.html#check-out-conversations",
    "href": "slides/lec-1.html#check-out-conversations",
    "title": "Welcome to STA 210!",
    "section": "Check out Conversations",
    "text": "Check out Conversations\n\nGo to Conversations 💬\nAnswer the discussion question: How are you doing?"
  },
  {
    "objectID": "slides/lec-1.html#what-is-regression-analysis",
    "href": "slides/lec-1.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis",
    "text": "What is regression analysis\n\n\n“In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or predictors). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or ‘criterion variable’) changes when any one of the independent variables is varied, while the other independent variables are held fixed.”\n\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/lec-1.html#course-faq",
    "href": "slides/lec-1.html#course-faq",
    "title": "Welcome to STA 210!",
    "section": "Course FAQ",
    "text": "Course FAQ\n\n\nWhat background is assumed for the course? Introductory statistics or probability course.\nWill we be doing computing? Yes. We will use R.\nWill we learn the mathematical theory of regression? Yes and No. The course is primarily focused on application; however, we will discuss some of the mathematics of simple linear regression. The 1-credit course STA 211: Mathematics of Regression you can take simultaneously / after dives into more of the mathematics."
  },
  {
    "objectID": "slides/lec-1.html#course-learning-objectives",
    "href": "slides/lec-1.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nAnalyze real-world data to answer questions about multivariable relationships.\nFit and evaluate linear and logistic regression models.\nAssess whether a proposed model is appropriate and describe its limitations.\nUse Quarto to write reproducible reports and GitHub for version control and collaboration.\nCommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "slides/lec-1.html#examples-of-regression-in-practice",
    "href": "slides/lec-1.html#examples-of-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Examples of regression in practice",
    "text": "Examples of regression in practice\n\n\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\nHow FiveThirtyEight’s 2020 Presidential Forecast Works — And What’s Different Because Of COVID-19\nEffect of Forensic Evidence on Criminal Justice Case Processing\nWhy it’s so freaking hard to make a good COVID-19 model"
  },
  {
    "objectID": "slides/lec-1.html#homepage",
    "href": "slides/lec-1.html#homepage",
    "title": "Welcome to STA 210!",
    "section": "Homepage",
    "text": "Homepage\nsta210-s22.github.io/website\n\nAll course materials\nLinks to Sakai, GitHub, RStudio containers, etc.\nLet’s take a tour!"
  },
  {
    "objectID": "slides/lec-1.html#course-toolkit",
    "href": "slides/lec-1.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta210-s22\nRStudio containers: cmgr.oit.duke.edu/containers\nDiscussion forum: Conversations\nAssignment submission and feedback: Gradescope\n\n\n\n\n\n\n\nImportant\n\n\nReserve an RStudio Container (titled STA 210) before lab on Monday!"
  },
  {
    "objectID": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "href": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to STA 210!",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Introduce new content and prepare for lectures by completing the readings (and sometimes watching the videos)\nParticipate: Attend and actively participate in lectures and labs, office hours, team meetings\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what you’ve learned to analyze real-world data\n\nLab assignments x 7 (first individual, later team-based)\nHomework assignments x 5 (individual)\nThree take-home exams\nTerm project presented during the final exam period"
  },
  {
    "objectID": "slides/lec-1.html#cadence",
    "href": "slides/lec-1.html#cadence",
    "title": "Welcome to STA 210!",
    "section": "Cadence",
    "text": "Cadence\n\n\nLabs: Start and make large progress on Monday in lab section, finish up by Friday 5pm of that week\nHWs: Posted Friday morning, due following Friday 5pm\nExams: Exam review Thursday in class, exam posted Friday morning, no lab on Monday of following week, due Monday 11:59pm\nProject: Deadlines throughout the semester, with some lab and lecture time dedicated to working on them, and most work done in teams outside of class"
  },
  {
    "objectID": "slides/lec-1.html#teams",
    "href": "slides/lec-1.html#teams",
    "title": "Welcome to STA 210!",
    "section": "Teams",
    "text": "Teams\n\nTeam assignments\n\nAssigned by me\nApplication exercises, labs, and project\nPeer evaluation during teamwork and after completion\n\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/lec-1.html#grading",
    "href": "slides/lec-1.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n3%\n\n\nHomework\n35% (7% x 5)\n\n\nProject\n15%\n\n\nLab\n14% (2% x 7)\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n3%\n\n\n\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/lec-1.html#support",
    "href": "slides/lec-1.html#support",
    "title": "Welcome to STA 210!",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions on the discussion forum\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/lec-1.html#announcements",
    "href": "slides/lec-1.html#announcements",
    "title": "Welcome to STA 210!",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Sakai (Announcements tool) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/lec-1.html#diversity-inclusion",
    "href": "slides/lec-1.html#diversity-inclusion",
    "title": "Welcome to STA 210!",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know!\nPlease let me know your preferred pronouns. You’ll also be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/lec-1.html#accessibility",
    "href": "slides/lec-1.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/lec-1.html#covid-policies",
    "href": "slides/lec-1.html#covid-policies",
    "title": "Welcome to STA 210!",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask at all times!\nRead and follow university guidance"
  },
  {
    "objectID": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "href": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "title": "Welcome to STA 210!",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/lec-1.html#collaboration-policy",
    "href": "slides/lec-1.html#collaboration-policy",
    "title": "Welcome to STA 210!",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/lec-1.html#sharing-reusing-code-policy",
    "href": "slides/lec-1.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 210!",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/lec-1.html#academic-integrity",
    "href": "slides/lec-1.html#academic-integrity",
    "title": "Welcome to STA 210!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/lec-1.html#most-importantly",
    "href": "slides/lec-1.html#most-importantly",
    "title": "Welcome to STA 210!",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "slides/lec-1.html#five-tips-for-success",
    "href": "slides/lec-1.html#five-tips-for-success",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings.\nDo the homework and lab.\nDon’t procrastinate and don’t let a week pass by with lingering questions."
  },
  {
    "objectID": "slides/lec-1.html#learning-during-a-pandemic",
    "href": "slides/lec-1.html#learning-during-a-pandemic",
    "title": "Welcome to STA 210!",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis."
  },
  {
    "objectID": "slides/lec-1.html#this-weeks-tasks",
    "href": "slides/lec-1.html#this-weeks-tasks",
    "title": "Welcome to STA 210!",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nGet a GitHub account if you don’t have one (some advice for choosing a username here)\nComplete the Getting to know you survey if you haven’t yet done so!\nRead the syllabus\nWatch out for next week’s announcement email, in your inbox sometime tomorrow"
  },
  {
    "objectID": "slides/lec-1.html#midori-says",
    "href": "slides/lec-1.html#midori-says",
    "title": "Welcome to STA 210!",
    "section": "Midori says…",
    "text": "Midori says…"
  },
  {
    "objectID": "slides/lect_03.html#definition-of-categorical-variable",
    "href": "slides/lect_03.html#definition-of-categorical-variable",
    "title": "Lec 3 - Exploring categorical data",
    "section": "Definition of categorical variable",
    "text": "Definition of categorical variable\nA categorical or qualitative variable is a variable that can not be measured. They are descriptors or grouping factors."
  },
  {
    "objectID": "slides/lect_03.html#the-purpose-of-exploring-categorical-variables",
    "href": "slides/lect_03.html#the-purpose-of-exploring-categorical-variables",
    "title": "Lec 3 - Exploring categorical data",
    "section": "The purpose of exploring categorical variables",
    "text": "The purpose of exploring categorical variables\n\nExploratory Data Analysis is about learning the structure of a dataset through a series of numerical and graphical techniques.\nWhen you do EDA, you’ll look for both\n\ngeneral trends and\ninteresting outliers in your data.\n\n\ngenerate questions that will help inform subsequent analysis."
  },
  {
    "objectID": "supplemental/chi-squared.html",
    "href": "supplemental/chi-squared.html",
    "title": "Chi-squared test expected values",
    "section": "",
    "text": "Information about the Chi-Squared test can be found here. We have two hypotheses:\n\\(H_0\\) = the variables are independent, there is no relationship between the two categorical variables.\n\\(H_A\\) = Knowing the value of one variable helps to predict the value of the other variable.\nUnder the null hypothesis, the distribution of one variable is independent to the distribution of the other. This means that the expected count for one cell, can be found using the column total times the row total divided by the total number of observations."
  },
  {
    "objectID": "course-faq.html#how-do-i-find-the-expected-values-for-a-chi-squared-distribution",
    "href": "course-faq.html#how-do-i-find-the-expected-values-for-a-chi-squared-distribution",
    "title": "FAQ",
    "section": "How do I find the expected values for a Chi-Squared distribution?",
    "text": "How do I find the expected values for a Chi-Squared distribution?\nInformation about the Chi-Squared test can be found here. We have two hypotheses:\n\\(H_0\\) = the variables are independent, there is no relationship between the two categorical variables.\n\\(H_A\\) = Knowing the value of one variable helps to predict the value of the other variable.\nUnder the null hypothesis, the distribution of one variable is independent to the distribution of the other. This means that the expected count for one cell, can be found using the column total times the row total divided by the total number of observations."
  },
  {
    "objectID": "ae/ae-6.html",
    "href": "ae/ae-6.html",
    "title": "Revision 1 for exam 1",
    "section": "",
    "text": "What tidyverse function would you use to extract rows?\na. filter()\n\n\n\ncount()\nselect()\ndistinct()\n\n\n\nWhat tidyverse function would you use to extract colums?\n\n\n\nfilter()\ncount()\nc. select()\ndistinct()\n\n\n\nTo find the maximum number of times that a categorical variable appears which function should I use?\n\n\n\nfilter()\nb. count()\nselect()\ndistinct()\n\n\n\nWhat does the “%>%” operator do?\n\na. used in tidyverse between layers of dplyr coding\nb. used in ggplot to add more layers of coding\n\n\nWill this code run without an error? diamonds %>% mutate(price_hundred = price %/% 100)\n\n\n\nIt will produce an error\nb. It will not produce an error\n\n\n\nWhat does the binwidth input in ggplot do?\n\n\n\nIt controls the opacity of the plot\nIt can be used to update the labels\nc. It controls the smoothness of a density plot\nIt controls the size of dots\n\n\n\nWhat punctuation must be placed before a function or dataset to access more information?\n\n\n\n“.”\n“+”\nc. “?”\n“!”\n\n\n\nWhere should the variable names go in the following line of code: ggplot(data = A) + B(mapping = aes(C))\n\n\n\nA\nB\nc. C\n\n\n\nWhat does the here package do?\n\n\n\nfor data manipulation and display\nb. to organize files\nnone of the above\n\n\n\nWhich of the following variables are discrete?\na. number of employees in a company.\n\n\n\ndistance traveled to and from work\ntaxes paid in 2019\npurchases from 2018\n\n\n\nWhat is the difference between distinct() and count()?\n\n\n\nthey are the same\nb. distinct() gives the levels in a variable, count() gives the marginal distribution\ndistinct() gives the marginal distribution, count() gives the levels in a variable\n\n\n\nWhat operator is used in ggplot?\n\n\n\n“.”\nb. “+”\n“?”\n“!”\n\nCategorical variables\n\nFind the expected count for clarity VS1 and color I for a \\(\\chi^2\\) distribution assuming independence.\n\n\\(8171\\times 5422/53940\\)\n\n\n# A tibble: 8 × 10\n  clarity     D     E     F     G     H     I     J marginal_clarity marginal_…¹\n  <ord>   <int> <int> <int> <int> <int> <int> <int>            <dbl>       <dbl>\n1 I1         42   102   143   150   162    92    50              741        6775\n2 SI2      1370  1713  1609  1548  1563   912   479             9194        9797\n3 SI1      2083  2426  2131  1976  2275  1424   750            13065        9542\n4 VS2      1697  2470  2201  2347  1643  1169   731            12258       11292\n5 VS1       705  1281  1364  2148  1169   962   542             8171        8304\n6 VVS2      553   991   975  1443   608   365   131             5066        5422\n7 VVS1      252   656   734   999   585   355    74             3655        2808\n8 IF         73   158   385   681   299   143    51             1790       53940\n# … with abbreviated variable name ¹​marginal_color\n\n\n[1] 821.3415\n\n\n\nWhat proportion of the very good cut diamonds are colored I?\n0.0997\n\n\n\n# A tibble: 5 × 8\n  cut            D      E      F      G      H      I      J\n  <ord>      <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Fair      0.0241 0.0229 0.0327 0.0278 0.0365 0.0323 0.0424\n2 Good      0.0977 0.0952 0.0953 0.0771 0.0845 0.0963 0.109 \n3 Very Good 0.223  0.245  0.227  0.204  0.220  0.222  0.241 \n4 Premium   0.237  0.239  0.244  0.259  0.284  0.263  0.288 \n5 Ideal     0.418  0.398  0.401  0.433  0.375  0.386  0.319 \n\n\n\n\n# A tibble: 5 × 8\n# Groups:   cut [5]\n  cut           D     E     F     G     H      I      J\n  <ord>     <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>\n1 Fair      0.101 0.139 0.194 0.195 0.188 0.109  0.0739\n2 Good      0.135 0.190 0.185 0.178 0.143 0.106  0.0626\n3 Very Good 0.125 0.199 0.179 0.190 0.151 0.0997 0.0561\n4 Premium   0.116 0.169 0.169 0.212 0.171 0.104  0.0586\n5 Ideal     0.132 0.181 0.178 0.227 0.145 0.0971 0.0416\n\n\n\nWhich of the lines below is the mean, median, or mode?\n\n\n\n\n\n\n\nred is median, green is mean\nred is mean, green is mode\nred is mode, green is mean\nd. red is mean, green is median\n\n\n\nIs the mean or median a better measure of center in this distribution.\n\nThe mean is a better estimate in a a symmetric distribution, median in a skewed distribution\n\n\n\n\n\n\nWhich plot is best at displaying outliers:\n\n\n\nhistogram\ndotplot\nplot of proportions\nd. boxplot"
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "📖 Read Solutions to AEs\n📖 Read Solutions to HW-1"
  },
  {
    "objectID": "weeks/week-5.html#participate",
    "href": "weeks/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\n🖥️\n🖥️"
  },
  {
    "objectID": "weeks/week-5.html#practice",
    "href": "weeks/week-5.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\n📋 Revision 1 for exam 1\n📋 Revision 2 for exam 1"
  },
  {
    "objectID": "weeks/week-5.html#perform",
    "href": "weeks/week-5.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\n⌨️ Course evaluation\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "supplemental/log-transformations.html",
    "href": "supplemental/log-transformations.html",
    "title": "Study list for exam 1",
    "section": "",
    "text": "functions\noperators\npipes\n\n\nfilter()\n%/%\n%>%\n\n\ndistinct()\n%%\n“+”\n\n\ncount()\n!=\n\n\n\nselect()\nrowSums()\n\n\n\nmutate()\ncolSums()\n\n\n\nView()\n\n\n\n\nglimpse()\n\n\n\n\npivot_wider()\n\n\n\n\ngroup_by()\n\n\n\n\nchisq.test()\n\n\n\n\nggplot()\n\n\n\n\ngeom_hist()\n\n\n\n\ngeom_bar()\n\n\n\n\ngeom_point()\n\n\n\n\nlab()\n\n\n\n\nfacet_wrap()\n\n\n\n\n\nBenefits and downsides of these visualization methods: histogram and boxplot.\nConditional probability tables - which variable is it conditioned on.\nMean, median, mode and which is best in skewed distributions. Identify in a plot\nMeasures of spread: standard deviation, variance, quartiles, percentiles, interquartile range.\nChi-squared expected counts given a contingency table of counts.\nIndependent events\nDisjoint events\nVenn diagrams\nCompliment\nThe three laws of probability - Kolomogorov’s axioms\nClassification of variables"
  },
  {
    "objectID": "ae/ae-7.html",
    "href": "ae/ae-7.html",
    "title": "Revision 2 for exam 1",
    "section": "",
    "text": "Find the matching item from the second column\n\n\n\n\n\n\n\n1. Independent events\na. \\(P(A \\cap B) \\neq P(A) \\times P(B)\\)\n\n\n\n\n\nDisjoint events\n\nb. \\(0\\leq p \\leq 1\\)\n\n\n\nUnion\n\nc. \\(A, B\\) disjoint \\(P(A\\cup B) = P(A) +P(B)\\)\n\n\n\nIntersection\n\nd. \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\n\nComplement of A\n\ne. \\(P(A \\cup B) \\leq P(A) + P(B)\\)\n\n\n\nSample space\n\nf. \\(A \\cap B\\)\n\n\n\nAddition rule\n\ng. \\(P(A \\cap B) = 0\\)\n\n\n\nComplement rule\n\nh. \\(P(S) = 1\\)\n\n\n\nBoole’s inequality\n\ni. \\(P(A^c) = 1 - P(A)\\)\n\n\n\nDependent events\n\nj. \\(P(A \\cap B) = P(A) \\times P(B)\\)\n\n\n\nKolmogorov’s axiom\n\nk. \\(A \\cup B\\)\n\n\n\nl. \\(A^c\\)\n\n\n\nm. \\(S\\)\n\n\n\n\n\n\nWhen \\(A \\subset B\\), then \\(A \\cup B = A\\)\n\nTrue\nFalse\n\nWhen \\(A \\subset B\\), then \\(A \\cap B = A\\)\n\nTrue\nFalse\n\nOne ball will be drawn at random from a box containing: 4 cyan balls, 3 magenta balls, and 5 yellow balls. What is the probability that the ball will be cyan?\nWhat is the probability that the ball will not be cyan?\nInstead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling without replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nNow repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling with replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nTwo events A and B are independent if Pr(A and B)=Pr(A)P(B). Under which situation are the draws independent?\n\nYou don’t replace the draw.\nYou replace the draw.\nNeither\nBoth\n\nSay you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?\nIf you roll a 6-sided die six times, what is the probability of seeing neither a 5 or 6?\nPlease match the following venn diagrams with the corresponding set theory notation.\n\n\n\n22.\na.\\(B \\subset A\\)\n\n\n\n\n23.\nb. \\(A\\) & \\(B\\) disjoint\n\n\n24.\nc. \\(A\\)\n\n\n25.\nd. \\(A \\cup B\\)\n\n\n26.\ne. \\(A \\cap B\\)\n\n\n27.\nf. \\(A^c\\)\n\n\n\n\n\nSolutions\n\n\n\n\n\n\n\n1\nj\n\n\n\n\n2\ng\n\n\n3\nk\n\n\n4\nf\n\n\n5\nl\n\n\n6\nm\n\n\n7\nd\n\n\n8\ni\n\n\n9\ne\n\n\n10\na\n\n\n11\nh, c, b\n\n\n12\nFalse\n\n\n13\nTrue\n\n\n14\n\\(\\frac{4}{4+3+5} = \\frac{4}{12}\\)\n\\(= \\frac{1}{3}\\)\n\n\n15\n\\(1 - \\frac{1}{3} = \\frac{2}{3}\\)\n\n\n16\nLet \\(C_1 = \\{1st\\:draw \\: is \\:cyan\\}\\) and\n\\(C_2 = \\{2nd\\: draw\\: is\\: cyan\\}\\)\nWe want :\\(P(C_1 \\cap C_2^c) = P(C_1) \\times P(C_2^c \\vert C_1)\\)\nThis is \\(\\frac{1}{3} \\times (1 -\\frac{3}{11}) = \\frac{8}{33}\\)\n\n\n17\nBecause they are independent:\\(P(C_1 \\cap C_2^c) = P(C_1) \\times P(C_2^c)\\)\n= \\(\\frac{1}{3} \\times \\frac{2}{3} = \\frac{2}{9}\\)\n\n\n18\nb\n\n\n19\n\\(\\frac{5}{12}\\)\n\n\n20\nLet \\(A = \\{5 \\: or \\: 6 \\: pips\\: facing\\: up\\}\\)\nWe want:\\(P(A^c \\cap A^c \\cap A^c \\cap A^c \\cap A^c \\cap A^c) = P(A^c)^6\\) because of independence of rolling a die.\n\\(= (\\frac{2}{3})^6 = \\frac{64}{729}\\)\n\n\n21\nNo question\n\n\n22\nc\n\n\n23\nf\n\n\n24\nb\n\n\n25\ne\n\n\n26\nd\n\n\n27\na"
  },
  {
    "objectID": "project-description.html#data",
    "href": "project-description.html#data",
    "title": "Showcase your inner data scientist",
    "section": "Data",
    "text": "Data\nIn order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset’s variables should include categorical variables, discrete numerical variables, and continuous numerical variables.\nIf you are using a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late.\nNote on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class.\nBelow are a list of data repositories that might be of interest to browse. You’re not limited to these resources, and in fact you’re encouraged to venture beyond them. But you might find something interesting there:\n\nTidyTuesday\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland’s official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nIf you know of others, let me know, and we’ll add here…"
  },
  {
    "objectID": "project-description.html#deliverables",
    "href": "project-description.html#deliverables",
    "title": "Showcase your inner data scientist",
    "section": "Deliverables",
    "text": "Deliverables\n\nProposal - due 26 October\nPresentation - due 5 & 7 Dec\nExecutive summary - due 9 Dec\n\n\nProposal\nThis is a draft of the introduction section of your project as well as a data analysis plan and your dataset.\n\nSection 1 - Introduction: The introduction should introduce your general research question and your data (where it came from, how it was collected, what are the cases, what are the variables, etc.).\nSection 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame. Add the README for the data, the codebook, and the output of glimpse() or skim() to the end of your proposal.\nSection 3 - Data analysis plan:\n\nAny outcomes (response, Y) and predictor (explanatory, X) variables you will use to answer your question.\nThe comparison groups you will use, if applicable.\nVery preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project.)\nThe method(s) that you believe will be useful in answering your question(s). (You can update these later as you work on your project.)\nWhat results from these specific statistical methods are needed to support your hypothesized answer?\n\n\nEach section should be no more than 1 page (excluding figures). You can check a print preview to confirm length.\nThe grading scheme for the project proposal is as follows. Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it. If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).\n\n\n\nTotal\n10 pts\n\n\n\n\nData\n3 pts\n\n\nProposal\n5 pts\n\n\nWorkflow, organization, code quality\n1 pt\n\n\nTeamwork\n1 pt\n\n\n\n\n\nPresentation\n5 minutes maximum, and each team member should say something substantial. You can either present live during your workshop or pre-record and submit your video to be played during the workshop.\nPrepare a slide deck using the template I will give to you. This template uses quarto, and allows you to make presentation slides using R Markdown syntax. There isn’t a limit to how many slides you can use, just a time limit (5 minutes total). Each team member should get a chance to speak during the presentation. Your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found.\nBefore you finalize your presentation, make sure your chunks are turned off with echo = FALSE.\nPresentations will take place on 5 and 7 December. You can choose to do your presentation live or pre-record it. During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations. The presentation line-up will be generated randomly.\nThe grading scheme for the presentation is as follows:\n\n\n\n\n\n\n\nTotal\n50 pts\n\n\n\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\n4 pts\n\n\nContent: Is the research question well designed and is the data being used relevant to the research question?\n5 pts\n\n\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\n5 pts\n\n\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\n6 pts\n\n\nContent: Did the team use appropriate statistical procedures and interpretations of results accurately?\n10 pts\n\n\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n10 pts\n\n\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n10 pts\n\n\n\n\n\nExecutive summary\nAlong with your presentation slides, we want you to provide a brief summary of your project.\nThis executive summary should provide information on the dataset you’re using, your research question(s), your methodology, and your findings.\nThe executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it’s concise but detailed enough.\n\n\nProject organization\nThe following folders and files in your project. Please download the template here:\n\npresentation.qmd + presentation.html: Your presentation slides\nREADME.Rmd + README.md: Your write-up\n/data: Your dataset in CSV or RDS format and your data dictionary\n/proposal: Your project proposal\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted."
  },
  {
    "objectID": "project-description.html#tips",
    "href": "project-description.html#tips",
    "title": "Showcase your inner data scientist",
    "section": "Tips",
    "text": "Tips\n\nYou’re working in the same google doc as your teammates now, so make sure that the coding is in the correct order.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution.\nSet aside time to work together and apart (physically).\nWhen you’re done, review the documents to make sure you’re happy with the final state of your work. Then go get some rest!\nCode: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your quarto file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion.\n\nTeamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-description.html#marking",
    "href": "project-description.html#marking",
    "title": "Showcase your inner data scientist",
    "section": "Marking",
    "text": "Marking\n\n\n\nTotal\n100 pts\n\n\n\n\nProposal\n10 pts\n\n\nPresentation\n50 pts\n\n\nExecutive summary\n15 pts\n\n\nReproducibility and organization\n10 pts\n\n\nTeam peer evaluation\n10 pts\n\n\nClassmates’ evaluation\n5 pts\n\n\n\n\nCriteria\nYour project will be assessed on the following criteria:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60% - Student is not making a sufficient effort.\n\n\n\nTeam peer evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points. You will additionally report a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.\n\n\nLate work policy\n\nThere is no late submission / make up for the presentation. You must be in class on the day of the presentation to get credit for it or pre-record and submit your presentation by 9am in the morning of the presentations.\nThe late work policy for the write-up is 5% of the maximum obtainable mark per calendar day up to seven calendar days after the deadline. If you intend to submit work late for the project, you must notify the course organizer before the original deadline as well as soon as the completed work is submitted."
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 6",
    "section": "",
    "text": "📖 Read"
  },
  {
    "objectID": "weeks/week-6.html#practice",
    "href": "weeks/week-6.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\n📋\n📋"
  },
  {
    "objectID": "weeks/week-6.html#perform",
    "href": "weeks/week-6.html#perform",
    "title": "Week 6",
    "section": "Perform",
    "text": "Perform\n✅ Exam 1\n\n\nBack to course schedule ⏎\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "supplemental/exam-1-studyguide.html",
    "href": "supplemental/exam-1-studyguide.html",
    "title": "Study list for exam 1",
    "section": "",
    "text": "functions\noperators\npipes\n\n\nfilter()\n%/%\n%>%\n\n\ndistinct()\n%%\n“+”\n\n\ncount()\n!=\n\n\n\nselect()\nrowSums()\n\n\n\nmutate()\ncolSums()\n\n\n\nView()\n\n\n\n\nglimpse()\n\n\n\n\npivot_wider()\n\n\n\n\ngroup_by()\n\n\n\n\nchisq.test()\n\n\n\n\nggplot()\n\n\n\n\ngeom_hist()\n\n\n\n\ngeom_bar()\n\n\n\n\ngeom_point()\n\n\n\n\nlabs()\n\n\n\n\nfacet_wrap()\n\n\n\n\n\nBenefits and downsides of these visualization methods: histogram and boxplot.\nConditional probability tables - which variable is it conditioned on.\nMean, median, mode and which is best in skewed distributions. Identify in a plot\nMeasures of spread: standard deviation, variance, quartiles, percentiles, interquartile range.\nChi-squared expected counts given a contingency table of counts.\nIndependent events\nDisjoint events\nVenn diagrams\nCompliment\nThe three laws of probability - Kolomogorov’s axioms\nClassification of variables"
  },
  {
    "objectID": "slides/lect_08.html#price-vs-x",
    "href": "slides/lect_08.html#price-vs-x",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Price vs \\(x\\)",
    "text": "Price vs \\(x\\)"
  },
  {
    "objectID": "slides/lect_08.html#visual-association-test",
    "href": "slides/lect_08.html#visual-association-test",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Visual association test",
    "text": "Visual association test\n\nAsk them to run the coding in RStudio and see what they get - can connect some of their computers to the big screen\nCan they see a difference between their plots and the real plot? What is the difference?\n\n\n\n\n\n\n\n\n\n\ndiamonds %>% # filtered data\n  slice_sample(n = nrow(.)) %>% # random sample rows\n  pull(carat) %>% # take out the variable carat\n  bind_cols(., diamonds$price) %>% # price in the same order and bound to carat in different order\n  ggplot() + # into ggplot\n  geom_point(aes(y = ...2, x = ...1)) + # using the new names\n  labs(title = \"Simulated association test\", \n       x = \"Weight of diamond in carat\", \n       y = \"Price of diamonds in US$\")"
  },
  {
    "objectID": "slides/lect_08.html#describing-a-scatter-plot",
    "href": "slides/lect_08.html#describing-a-scatter-plot",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Describing a scatter plot",
    "text": "Describing a scatter plot\n\nWhat is the difference between the actual plot and the simulated plots?\nDiscuss each point.\nBig words make you sound smart to people that aren’t that smart.\n\n\n\n\nTrend or direction\n\npositive\nnegative\n\nCurvature\n\nlinear\nnonlinear\n\nexponential\nquadratic\n\n\n\n\n\nVariation\n\nhomoscedasticity (similar variance)\nheteroscedasticity (different variance)\n\nOutliers\n\nany weird points (explore these)\n\nGroupings"
  },
  {
    "objectID": "slides/lect_08.html#describe-these-plots",
    "href": "slides/lect_08.html#describe-these-plots",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Describe these plots",
    "text": "Describe these plots\n\nWhat are the relationships between each plot?\nWhat do the numbers mean?"
  },
  {
    "objectID": "slides/lect_08.html#measuring-association-1",
    "href": "slides/lect_08.html#measuring-association-1",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Measuring association",
    "text": "Measuring association\n\nRemind them of the variance and what we did with the squares. What squares could we use now?"
  },
  {
    "objectID": "slides/lect_08.html#covariance",
    "href": "slides/lect_08.html#covariance",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Covariance",
    "text": "Covariance\n\nIf the product is negative then there it contributes to a negative trend - downhill from left to right.\nSame if positive\nhard to get ones that are negative for this dataset b/c tbere is a really strong positive association"
  },
  {
    "objectID": "repo-structure/presentation/presentation.html",
    "href": "repo-structure/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "Our project will demonstrate that the praise package is by far the best R package."
  },
  {
    "objectID": "weeks/week-08.html",
    "href": "weeks/week-08.html",
    "title": "Week 8",
    "section": "",
    "text": "📖 Read Chpts 11 & 12 from Stine and Foster\n📖 Read FGLI: Chpts 11 & 12 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-08.html#participate",
    "href": "weeks/week-08.html#participate",
    "title": "Week 8",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 10\n🖥️ Lecture 11"
  },
  {
    "objectID": "weeks/week-08.html#perform",
    "href": "weeks/week-08.html#perform",
    "title": "Week 8",
    "section": "Perform",
    "text": "Perform\n✍️ HW 2 - Titanic\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-09.html",
    "href": "weeks/week-09.html",
    "title": "Week 9",
    "section": "",
    "text": "📖 Read Chpts 13 & 14 from Stine and Foster\n📖 Read FGLI: Chpts 13 & 14 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-09.html#participate",
    "href": "weeks/week-09.html#participate",
    "title": "Week 9",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 12: Samples and survey\n🖥️ Lecture 13: Sampling variation and quality"
  },
  {
    "objectID": "weeks/week-09.html#perform",
    "href": "weeks/week-09.html#perform",
    "title": "Week 9",
    "section": "Perform",
    "text": "Perform\n✍️ HW 2 - Titanic\n📂 Proposal for project\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-04.html",
    "href": "weeks/week-04.html",
    "title": "Week 4",
    "section": "",
    "text": "📖 Read chapter 14 of Introduction to Data Science\n📖 Read chapter 2 of Probability, Statistics, and Data: A fresh approach using R"
  },
  {
    "objectID": "weeks/week-04.html#participate",
    "href": "weeks/week-04.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 5\n🖥️ Lecture 6"
  },
  {
    "objectID": "weeks/week-04.html#practice",
    "href": "weeks/week-04.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\n📋 Exploring probabilities\n📋 The birthday simulation"
  },
  {
    "objectID": "weeks/week-04.html#perform",
    "href": "weeks/week-04.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test - week 3\n✍️ HW 1 - Titanic\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "🖥️ Happy Halloween"
  },
  {
    "objectID": "weeks/week-10.html#practice",
    "href": "weeks/week-10.html#practice",
    "title": "Week 10",
    "section": "Practice",
    "text": "Practice\n📋 Revision for exam 2"
  },
  {
    "objectID": "weeks/week-10.html#perform",
    "href": "weeks/week-10.html#perform",
    "title": "Week 10",
    "section": "Perform",
    "text": "Perform\n✅ Exam 2\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "📖 Read Chpts 15 & 16 from Stine and Foster\n📖 Read FGLI: Chpts 15 & 16 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-11.html#participate",
    "href": "weeks/week-11.html#participate",
    "title": "Week 11",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 14\n🖥️ Lecture 15"
  },
  {
    "objectID": "weeks/week-11.html#practice",
    "href": "weeks/week-11.html#practice",
    "title": "Week 11",
    "section": "Practice",
    "text": "Practice\n📋 AE - 10\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-05.html",
    "href": "weeks/week-05.html",
    "title": "Week 5",
    "section": "",
    "text": "📖 Read Solutions to AEs\n📖 Read Solutions to HW-1"
  },
  {
    "objectID": "weeks/week-05.html#practice",
    "href": "weeks/week-05.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\n📋 Revision 1 for exam 1\n📋 Revision 2 for exam 1"
  },
  {
    "objectID": "weeks/week-05.html#perform",
    "href": "weeks/week-05.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\n⌨️ Course evaluation\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 12",
    "section": "",
    "text": "📖 Read Chpts 19 from Stine and Foster\n📖 Read FGLI: Chpts 19 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-13.html#participate",
    "href": "weeks/week-13.html#participate",
    "title": "Week 12",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 18\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-07.html",
    "href": "weeks/week-07.html",
    "title": "Week 7",
    "section": "",
    "text": "📖 Read Chpts 6 & 10 from Stine and Foster\n📖 Read FGLI: Chpts 6 & 10 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-07.html#participate",
    "href": "weeks/week-07.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 8\n🖥️ Lecture 9"
  },
  {
    "objectID": "weeks/week-07.html#practice",
    "href": "weeks/week-07.html#practice",
    "title": "Week 7",
    "section": "Practice",
    "text": "Practice\n📋 AE 9"
  },
  {
    "objectID": "weeks/week-07.html#perform",
    "href": "weeks/week-07.html#perform",
    "title": "Week 7",
    "section": "Perform",
    "text": "Perform\n✍️ HW 2 - Titanic\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-06.html",
    "href": "weeks/week-06.html",
    "title": "Week 6",
    "section": "",
    "text": "📖 Read Chpt 9 from Stine and Foster\n📖 Read FGLI: Chpt 9 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-06.html#participate",
    "href": "weeks/week-06.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 7"
  },
  {
    "objectID": "weeks/week-06.html#practice",
    "href": "weeks/week-06.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\n📋 Random variables"
  },
  {
    "objectID": "weeks/week-06.html#perform",
    "href": "weeks/week-06.html#perform",
    "title": "Week 6",
    "section": "Perform",
    "text": "Perform\n✅ Exam 1\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "📖 Read Chpts 17 & 18 from Stine and Foster\n📖 Read FGLI: Chpts 17 & 18 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-12.html#participate",
    "href": "weeks/week-12.html#participate",
    "title": "Week 12",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 16\n🖥️ Lecture 17"
  },
  {
    "objectID": "weeks/week-12.html#practice",
    "href": "weeks/week-12.html#practice",
    "title": "Week 12",
    "section": "Practice",
    "text": "Practice\n📋 AE - 11\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-02.html",
    "href": "weeks/week-02.html",
    "title": "Week 2",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-02.html#participate",
    "href": "weeks/week-02.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 2"
  },
  {
    "objectID": "weeks/week-02.html#practice",
    "href": "weeks/week-02.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\n📋 diamonds"
  },
  {
    "objectID": "weeks/week-02.html#perform",
    "href": "weeks/week-02.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-03.html",
    "href": "weeks/week-03.html",
    "title": "Week 3",
    "section": "",
    "text": "📖 Read chapter 4 of Introduction to Modern Statistics\n📖 Read chapter 5 of Introduction to Modern Statistics"
  },
  {
    "objectID": "weeks/week-03.html#participate",
    "href": "weeks/week-03.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 3\n🖥️ Lecture 4"
  },
  {
    "objectID": "weeks/week-03.html#practice",
    "href": "weeks/week-03.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\n📋 Exploring qualitative variables\n📋 Exploring numeric variables"
  },
  {
    "objectID": "weeks/week-03.html#perform",
    "href": "weeks/week-03.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test - week 3\n✍️ HW 6 - Statistics Experience\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-01.html",
    "href": "weeks/week-01.html",
    "title": "Week 1",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-01.html#participate",
    "href": "weeks/week-01.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 1 - Download R and plotting your first graph"
  },
  {
    "objectID": "weeks/week-01.html#practice",
    "href": "weeks/week-01.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\n📋 diamonds"
  },
  {
    "objectID": "weeks/week-01.html#perform",
    "href": "weeks/week-01.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "hw/hw-2.html",
    "href": "hw/hw-2.html",
    "title": "HW 2 - Titanic dataset",
    "section": "",
    "text": "For this homework assignment we will be exploring the Titanic dataset.\n\n\nIn this assignment, you will…\n\nImport data into R\nExplore numeric variables\nCompute means for subgroups and compare them\nComment on and produce a pairs plot of numeric variables\nAddress overplotting"
  },
  {
    "objectID": "hw/hw-2.html#getting-started",
    "href": "hw/hw-2.html#getting-started",
    "title": "HW 2 - Titanic dataset",
    "section": "Getting started",
    "text": "Getting started\n\nLog in to RStudio\nClick on your Stat1010.Rproj that we made the first day of class.\nGo to File ➛ New File ➛ Quarto Document and name the document hw-2 click create."
  },
  {
    "objectID": "hw/hw-2.html#packages",
    "href": "hw/hw-2.html#packages",
    "title": "HW 2 - Titanic dataset",
    "section": "Packages",
    "text": "Packages\nThe following packages will be used in this assignment:\n\nlibrary(tidyverse) # for data manipulation and data visualization\nlibrary(here) # to organize files"
  },
  {
    "objectID": "hw/hw-2.html#data-titanic",
    "href": "hw/hw-2.html#data-titanic",
    "title": "HW 2 - Titanic dataset",
    "section": "Data: Titanic",
    "text": "Data: Titanic\nOn April 15, 1912, the largest passenger liner ever made collided with an iceberg during her maiden voyage. When the Titanic sank it killed 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck resulted in such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others.\nThe titanic.csv file contains data for 887 of the real Titanic passengers. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their passenger-class, their sex, and the fare they paid\n\nPclass: The class of passengers on the titanic, with \\(1st\\) being the highest class, and \\(3rd\\) the lowest.\nSurvived: A variable that records whether or not a passenger survived the sinking of the titanic.\nFare: A variable that records the passenger fare.\n\n\nImport the data into R\nFor each value of Pclass, compute the mean fare and standard deviation paid by the passengers in that class. Comment on them in context.\nFor each value of Survived, compute the mean fare and standard deviation paid by the passengers with that survival status. Comment on them in context.\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document.\n\n\n\nDraw a pairs plot of all numeric variables in the dataset and comment on all scatterplots and histograms. Be sure to use variable names.\nExplore any outliers by filtering and looking at the data. Answer questions like this, but include others that spark your curiosity. Include a minimum of 2 additional outliers.\n\nWhich was the biggest family aboard?\nWhich and how many people paid the highest fair?\n\nDraw one plot containing 3 boxplots of the Fare paid for each category of Pclass. What conclusions can you draw from this plot? Consider our last assignment and how the passenger class predicted survival.\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document.\n\n\n\nDraw a scatterplot of Pclass and Fare, and color it by the survival variable. (Hint: use the function geom_jitter() to avoid overplotting.) Comment on the plot.\n\n\n\n\n\n\n\nWarning\n\n\n\nBefore submitting, make sure you render your document,"
  },
  {
    "objectID": "hw/hw-2.html#submission",
    "href": "hw/hw-2.html#submission",
    "title": "HW 2 - Titanic dataset",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nThen submit the pdf following the link on the course website."
  },
  {
    "objectID": "hw/hw-2.html#grading",
    "href": "hw/hw-2.html#grading",
    "title": "HW 2 - Titanic dataset",
    "section": "Grading",
    "text": "Grading\nTotal points available: 38 points\n\n\n\nComponent\nPoints\n\n\n\n\nQu 1\n2\n\n\nQu 2\n4\n\n\nQu 3\n4\n\n\nQu 4\n15\n\n\nQu 5\n4\n\n\nQu 6\n5\n\n\nQu 7\n4"
  },
  {
    "objectID": "ae/ae-12.html",
    "href": "ae/ae-12.html",
    "title": "Chi-squared test: AE - 11",
    "section": "",
    "text": "Match each item on the left with its correct description on the right.\n\nNumber of degrees of freedom in the chi-squared test of independence in a 2 × 2 table\nNumber of constraints on frequencies in the chi-squared test of goodness of fit of a binomial distribution\nP-value if \\(\\chi^2\\) = 9.488 when testing for independence in a 3 × 3 table\nP-value if \\(\\chi^2\\) = 16.812 when testing the null hypothesis that a categorical variable with 7 levels has a uniform distribution\nSmallest possible value of \\(\\chi^2\\)\nImpossible value for \\(\\chi^2\\)\nReject the null hypothesis of independence in a 3 × 4 contingency table if \\(\\chi^2\\) is larger than this value and \\(\\alpha = 0.05\\)\nReject the null hypothesis of independence in a 6 × 3 contingency table if \\(\\chi^2\\) is larger than this value and \\(\\alpha = 0.01\\)\nThe expected cell count in a table should be larger than this number when using \\(\\chi^2\\)\nNumber of degrees of freedom if using chi-squared to test whether four proportions are the same\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na. 0\nb. 0.01\nc. 23.209\nd. 10\ne. 1\nf. 0.05\ng. 3\nh. 2\ni. 12.592\nj. -1\n\n\n\nTrue/False\n\nThe chi-squared test of independence only detects linear association between the variables in a contingency table.\nA statistically significant \\(\\chi^2\\) in the test of independence implies a causal relationship between the variables that define a contingency table.\nThe expected size of the chi-squared statistic \\(\\chi^2\\) increases with the number of observations \\(n\\) in the table.\nA stock market analyst recorded the number of stocks that went up or went down each day for 5 consecutive days, producing a contingency table with two rows (up or down) and five columns (Monday through Friday). Are these data suitable for applying the chi-squared test of independence?\nThe human resources group regularly interviews prospective clerical employees and tests their skill at data entry. The following table shows the number of errors made by 60 prospective clerks when entering a form with 80 numbers. (Five clerks made four errors.) Test the null hypothesis that the number of errors follows a Poisson distribution. Find the\n\n\n\nerrors\nClerks\n\n\n\n\n0\n12\n\n\n1\n20\n\n\n2\n9\n\n\n3\n14\n\n\n4 or more\n5\n\n\n\na. Rate (or mean) of the Poisson distribution\nb. Expected number of employees who do not make an error\nc. Degrees of freedom of \\(\\chi^2\\)\nd. \\(\\chi^2\\)\ne. p-value for testing H0."
  },
  {
    "objectID": "ae/ae-9.html",
    "href": "ae/ae-9.html",
    "title": "Associations AE-9",
    "section": "",
    "text": "library(tidyverse) # for data manipulation and plots\nlibrary(praise) # for good vibes\n\nChapter 6: Association between quantitative variables\n\nIf the covariance between \\(x\\) and \\(y\\) is \\(0\\), then the correlation between \\(x\\) and \\(y\\) is \\(0\\) as well\n\nTrue\nFalse\n\nA retailer calculated the correlation line between the price of an item (\\(x\\)) and the amount sold (\\(y\\)). The correlation line is the same if the \\(x\\) and \\(y\\) variables are exchanged.\n\nTrue\nFalse\n\n\n\npraise()\n\n\nIf the correlation between number of customers and sales in dollars in retail stores is \\(r=0.6\\), then what would be the correlation if the sales were measured in thousands of dollars? In euros? (1 euro is worth about \\(\\$US0.97\\))\n\nChapter 10: Association between random variables\n\nMix and match\n\n\n\n\n\n\n\n1. Consequence of positive covariance\na. \\(p(x, y)\\)\n\n\n\n\n\nCovariance between X and Y\n\nb. \\(\\rho\\)\n\n\n\nProperty of uncorrelated random variables\n\nc. \\(p(x, y) = p(x)p(y)\\)\n\n\n\nWeighted sum of two random variables\n\nd. \\(\\rho \\sigma_X \\sigma_Y\\)\n\n\n\nSharpe ratio of a random variable\n\ne. \\(Var(X+Y) > Var(X) +Var(Y)\\)\n\n\n\nImplies \\(X\\) and \\(Y\\) are independent random variables\n\nf. \\(p(x) = p(y)\\)\n\n\n\nImplies \\(X\\) and \\(Y\\) are identically distributed\n\ng. \\(X_1, X_2, X_3\\)\n\n\n\nSymbol for correlation between random variables\n\nh. \\(Var(X, Y) = Var(X) +Var(Y)\\)\n\n\n\nSymbol for a joint probability distribution\n\ni. \\(S(Y)\\)\n\n\n\nSequence of iid random variables\n\nj. \\(3X - 2Y\\)\n\n\n\nIndependent random variables \\(X\\) and \\(Y\\) have the means and standard deviations as given in the following table. Use these parameters to find the expected value and SD of the following random variables that are derived from \\(X\\) and \\(Y\\)\n\n\\(2X - 100\\)\n\\(0.5Y\\)\n\\(X+Y\\)\n\\(X-Y\\)\n\n\n\n\nMean\nSD\n\n\n\\(X\\)\n1000\n200\n\n\n\\(Y\\)\n2000\n600\n\n\n\n\n\n\npraise()\n\n\nRepeat the calculations above but now \\(X\\) and \\(Y\\) are not independent and have \\(Cov(X, Y) = 12,500\\).\nWhat’s the covariance between a random variable \\(X\\) and a constant?\nA student budgets $60 weekly for gas and quick meals off-campus. Let \\(X\\) denote the amount spent for gas and \\(Y\\) the amount spent for quick meals in a typical week. Assume the student sticks to the budget.\n\nCan we model \\(X\\) and \\(Y\\) as independent random variables? Why or why not?\nSuppose we assume \\(X\\) and \\(Y\\) are dependent. What is the effect of this dependence on the variance of \\(X+Y\\)?"
  },
  {
    "objectID": "ae/ae-11.html",
    "href": "ae/ae-11.html",
    "title": "Confidence intervals: AE - 10",
    "section": "",
    "text": "1.\\(y \\pm 2se(\\bar{y})\\) (a)  Sampling distribution of X\n2. \\(\\hat{p} \\pm se(\\hat{p})\\) (b)  Margin of error\n3. \\(2se (\\bar{X})\\) (c)  100% confidence interval for p\n4. \\(N(\\mu,\\sigma^2/n)\\) (d)  Estimated standard error of \\(\\bar{Y}\\)\n5. \\(s/\\sqrt{n}\\) (e)  Estimated standard error of \\(\\hat{p}\\)\n6. \\(\\sigma/\\sqrt{n}\\) (f)  An interval with about 95% coverage\n7. \\(1/(0.05)^2\\) (g)  Actual standard error of \\(\\bar{Y}\\)\n8. [0, 1] (h) About 2 for moderate sample sizes\n9. \\(\\sqrt{\\hat{p}(1 -\\hat{p})/n}\\) (i)   An interval with 68% coverage\n10. \\(t_{0.025, n-1}\\) (j)   Sample size needed for 0.05 margin of error\n11. True or False: By increasing the sample size from \\(n = 100\\) to \\(n = 400\\), we can reduce-the margin of error by \\(50\\%\\).\n12. If the 95% confidence interval for the average purchase of customers at a department store is $50 to $110, then $100 is a plausible value for the population mean at this level of confidence.\n13. If zero lies inside the 95% confidence interval for \\(\\mu\\), then zero is also inside the 99% confidence interval for \\(\\mu\\).\n14. The clothing buyer for a department store wants to order the right mix of sizes. As part of a survey, she measured the height (in inches) of men who bought suits at this store. Her software reported the following confidence interval:\nWith 95.00% confidence, 70.8876 < \\(\\mu\\) < 74.4970\n(a) Explain carefully what the software output means.\n(b) What’s the margin of error for this interval?\n(c) How should the buyer round the endpoints of the interval to summarize the result in a report for store managers?\n(d) If the researcher had calculated a 99% confidence interval, would the output have shown a longer or shorter interval?\n15. Hoping to lure more shoppers downtown, a city builds a new public parking garage in the central business district. The city plans to pay for the structure through parking fees. During a two-month period (44 weekdays), daily fees collected averaged $1,264 with a standard deviation of $150.\n(a) What assumptions must you make in order to use these statistics for inference?\n(b) Write a 90% confidence interval for the mean daily income this parking garage will generate, rounded appropriately.\n(c) The consultant who advised the city on this project predicted that parking revenues would average $1,300 per day. On the basis of your confidence interval, do you think the consultant was correct? Why or why not?\n(d) Give a 90% confidence interval for the total revenue earned during five weekdays."
  },
  {
    "objectID": "ae/ae-10.html",
    "href": "ae/ae-10.html",
    "title": "Exam 2 revision",
    "section": "",
    "text": "Expected value of \\(X\\)\n\na. \\(E(X - \\mu)\\)\n\n\n\nVariance of \\(X\\)\n\nb. \\(10X\\)\n\n\n\nStandard deviation of \\(X\\)\n\nc. \\(\\frac{(X-0.04)}{\\sigma}\\)\n\n\n\nShorthand notation for \\(P(X=x)\\)\n\nd. \\(X+10\\)\n\n\n\nHas 10 times the standard deviation of \\(X\\)\n\ne. \\(E(X-\\mu)^2\\)\n\n\n\nIs always equal to zero\n\nf. \\(\\sqrt{VarX}\\)\n\n\n\nIncreases the mean of \\(X\\) by 10\n\ng. \\(\\mu\\)\n\n\n\nHas standard deviation 1\n\nh. \\(p(x)\\)\n\n\n\nPlease review AE-8, the solutions are on the Canvas page.\nSection B:\n\n\n\n\n\n\n\n\nConsequence of covariance\n\na. \\(p(x,y)\\)\n\n\n\nCovariance between \\(X\\) and \\(Y\\)\n\nb. \\(\\rho\\)\n\n\n\nProperty of uncorrelated random variables\n\nc. \\(p(x, y) = p(x)p(y)\\)\n\n\n\nWeighted sum of two random variables\n\nd. \\(\\rho\\sigma_x\\sigma_y\\)\n\n\n\nSharpe ratio of random variable\n\ne. \\(Var(X+Y) >Var(X) + Var(Y)\\)\n\n\n\nImplies \\(X\\) and \\(Y\\) are independent random variables\n\nf. \\(p(x) = p(y)\\)\n\n\n\nImplies \\(X\\) and \\(Y\\) are identically distributed\n\ng. \\(X_1, X_2, X_3\\)\n\n\n\nSymbol for the correlation between random variables\n\nh. \\(Var(X+Y) = Var(X) + Var(Y)\\)\n\n\n\nSymbol for joint probability distribution\n\ni. \\(S(Y)\\)\n\n\n\nSequence of iid random variables\n\nj. \\(3X-2Y\\)\n\n\n\nPlease review AE-9, the solutions are on the Canvas page.\nSection C:\n\\(Y\\) is a binomial random variable with parameters \\(n\\) and \\(p\\), \\(X\\) is a Poisson random variable with parameter \\(\\lambda\\) and \\(B_1\\) and \\(B_2\\) are Bernoulli trials with probability of success \\(p\\).\n\n\n\n\n\n\n\n1. Expresssion for the variance of \\(Y\\)\na. \\(np\\)\n\n\n\n\n\nProbability that the first trial \\(B_1\\) fails\n\nb. \\(e^{-\\lambda}\\)\n\n\n\nExpression for the mean of \\(X\\)\n\nc. \\(e^{-\\lambda} \\frac{\\lambda^2}{2}\\)\n\n\n\nProbability that \\(Y\\) is zero\n\nd. \\(p\\)\n\n\n\nProbability that \\(X\\) is 2\n\ne. \\(0\\)\n\n\n\nCovariance between \\(B_1\\) and \\(B_2\\)\n\nf. \\(p^n\\)\n\n\n\nExpression for the expected value of \\(X\\)\n\ng. \\(1-p\\)\n\n\n\nThe expected value of \\(B_1\\)\n\nh. \\((1-p)^n\\)\n\n\n\nProbability that \\(Y\\) is \\(n\\)\n\ni. \\(np(1-p)\\)\n\n\n\nProbability that \\(X\\) is \\(0\\).\n\nj. \\(\\lambda\\)\n\n\n\n\nAn auditor inspects 25 transactions processed by the business office of a company. The auditor selects these transactions at random from the thousands that were processed in the most recent three months. In the past, the auditor has found 10% of transactions at this type of company to have been processed incorrectly. True or False: A binomial model would be more appropriate for this problem if the auditor picked the first 25 transactions during the three-month period.\nIs the binomial model suited to these applications?\n\nThe next five cars that enter a gasoline filling stations get a fill-up.\nA poll of the 15 members of the board of directors indicates that 6 are in favor of a proposal to change the salary of the CEO.\nA company realizes that 10% of its packages are not being sealed properly. When examining a case of 24, it counts the number that are unsealed.\n\nEvery now and then even a good diamonds cutter has a problem and the diamond shatters when being cut. For one cutter, the chance of such errors is 0.1%.\n\nWhat is the probability model seems well suited to this problem? Why?\nIf this cutter works on 75 stones, what is the probability that he breaks 2 or more?\n\nA dairy farmer accidentally allowed some of his cows to graze in a pasture containing weeds that would contaminate the milk from his herd. The farmer estimates that there’s a 10% chance of a cow grazing on some of the flavorful weeds.\n\nUnder these conditions, what is the probability that none of the 12 animals in this herd ate the weeds.\nDoes the poisson model give a good estimate of the probability that no animal ate the weeds?\n\n\nSection D:\n\\(X\\) denotes a normally distributed random variable: \\(X \\sim N(\\mu, \\sigma^2)\\). A googol, the namesake of Google, is \\(10^{100}\\). The random variable \\(Z\\) denotes a standard normal random variable, \\(Z \\sim N(0,1)\\)\n\n\n\n\n\n\n\n\nMean of \\(X\\)\n\na. \\(\\frac{1}{2}\\)\n\n\n\nVariance of \\(X\\)\n\nb. \\(P(Z<1)\\)\n\n\n\nProbability of \\(X\\) being less than its mean\n\nc. \\(0.05\\)\n\n\n\nProbability of \\(X\\) being less than \\(\\mu +\\sigma\\)\n\nd. \\(\\frac{2}{3}\\)\n\n\n\nStandard deviation of \\(Z\\)\n\ne. \\(\\frac{1}{1 googol}\\)\n\n\n\nProbability that a \\(z-score\\) based on \\(X\\) is less than \\(1\\) in magnitude\n\nf. \\(\\mu\\)\n\n\n\nProportion of a normal distribution that is more than \\(20\\sigma\\) from \\(\\mu\\)\n\ng. \\(\\sigma^2\\)\n\n\n\nDifference between value of \\(P(Z<-x)\\) and value of \\(P(Z>x)\\)\n\nh. \\(1\\)\n\n\n\nDistribution of the random variable \\(\\mu +\\sigma Z\\)\n\ni. \\(0\\)\n\n\n\nProbability that \\(Z>1.96\\) plus the probability that \\(Z<-1.96\\)\n\nj. \\(N(\\mu, \\sigma^2)\\)\n\n\n\n\nThe currently age (in years) of 400 clerical employees at an insurance claims processing center is normally distributed with mean 38 and SD 6. True or False: A training program for employees under the age of 30 at the center would be expected to attract about 36 employees.\nIf \\(X_1 \\sim N(\\mu, \\sigma)\\) and \\(X_2 \\sim N(\\mu, \\sigma)\\) are iid, then what is the distribution of \\(\\frac{X_1-X_2}{\\sqrt{2}\\sigma}\\)\nA contractor built 30 similar homes in a suburban development. The homes have comparable size and amenities, but each has features that customize the appearance, landscape, and interior. The contractor expects the homes to sell for $450,000. He expects that one-third of the homes will sell either for less than $400,000 or more than $500,000.\n\nWould a normal model be appropriate to describe the distribution of sale prices?\nWhat data would help you decide if a normal model is appropriate? (These homes are unsold, their prices are unavailable)\nWhat normal model has properties that are consistent with the intuition of the contractor?\n\nA hurricane bond pays the holder a face amount, say $1 million, if a hurricane causes major damage in the United States. Suppose that the chance for such a storm is 5% per year.\n\nIf a financial firm sells these bonds for $60,000, what is the chance that the firm loses money if it only sells one?\nIf the firm sells 1,000 of these policies, each for $60,000, what is the probability that it loses money.\nHow does the difference between the probabilities of parts a and b compare to the situation of an insurance company that writes coverage to homeowners who have accidents independently of one another?\n\n\nSection E:\n\n\n\n\n\n\n\n\nSample\n\na. A complete collection of items desired to be studied\n\n\n\nCensus\n\nb. A list of all the items in the population\n\n\n\nTarget population\n\nc. A subset of a larger collection of items\n\n\n\nStatistic\n\nd. A homogeous subset of the population\n\n\n\nParameter\n\ne. A characteristic of a sample\n\n\n\nSampling frame\n\nf. Occurs if a sampling method distorts a property of the population\n\n\n\nSimple random sample\n\ng. A comprehensive study of every item of the population\n\n\n\nStratum\n\nh. The result if a respondent chooses not to answer a question\n\n\n\nBias\n\ni. A characteristic of a population\n\n\n\nNonresponse\n\nj. Sample chosen so that all subset of size \\(n\\) are equally likely.\n\n\n\n\nTrue or False: Bias due to the wording of questions causes different samples to present different impressions of the population.\nA school district has requested a survey be conducted on the socioeconomic status of their students. Their budget only allows them to conduct the survey in some of the schools, hence they need to first sample a few schools. Students living in this district generally attend a school in their neighbourhood. The district is broken into many distinct and unique neighbourhoods, some including large single-family homes and others with only low-income housing. What kind of sampling did they employ?\n\nSection F:\n\nWhich of the following \\(X\\)-bar charts indicate a process that is out of control?\n\nWhich of the following \\(X\\)-bar charts show that a process went out of control?\n\n\nWhich, if any, of these combinations of an \\(X\\)-bar and an \\(S\\)-chart suggest a problem? If there’s a problem, in which chart did you find the problem?\n\nWhich, if any, of these combinations of an \\(X\\)-bar and an \\(S\\)-chart suggest a problem? If there’s a problem, in which chart did you find the problem?\n\nThe manager of a warehouse monitors shipments. A random sample of 25 packages is selected and weighed every day. The mean weight should be \\(\\mu = 22\\) pounds, and \\(\\sigma = 5\\) pounds. True or False: An \\(X\\)-bar chart with control limits 12 pounds and 32 pounds has a 5% chance of a Type I error.\nRather than stop the production when a mean crosses the control limits in the \\(X\\)-bar chart, a manager has decided to wait until two consecutive means lie outside the control limits before stopping the process. The control limits are \\(\\mu \\pm 2\\sigma/ \\sqrt{n}\\).\n\nBy waiting for two consecutive sample means to lie outside the control limits, has the manager increased or decreased the chance for a Type I error?\nWhat is the probability of a Type I error if this procedure is used?\n\nWhere should the control limits for an \\(X\\)-bar chart be placed if the design of the process sets \\(\\alpha = 0.0027\\) with the following parameters (assume that the sample size condition for control charts has been verified)?\n\n\\(\\mu = 10, \\sigma = 5,\\) and \\(n = 18\\) cases per batch\n\\(\\mu = -4, \\sigma = 2,\\) and \\(n = 12\\) cases per batch"
  },
  {
    "objectID": "ae/ae-8.html",
    "href": "ae/ae-8.html",
    "title": "Random variables AE-8",
    "section": "",
    "text": "library(tidyverse)\nlibrary(praise)\n\n\nGiven that the random variable \\(X\\) has mean \\(\\mu = 120\\) and SD \\(\\sigma = 15\\), find the mean and SD of each of these random variables that are defined by \\(X\\).\n\n\\(X/3\\)\n\\(2X - 100\\)\n\\(X+2\\)\n\\(X-X\\)\n\nAn investor buys the stock of two companies, investing \\(\\$10000\\) in each. The stock of each company either goes up by \\(80%\\) after a month (rising to \\(\\$18000\\)) with probability \\(\\frac{1}{2}\\) or drops by \\(60%\\) (falling to \\(\\$4000\\)) with probability \\(\\frac{1}{2}\\). Assume that the changes in each are independent. Let the random variable \\(X\\) denote the value of the amounted invested after one month.\n\nFind the probability distribution of \\(X\\).\nFind the mean value of \\(X\\)\nDoe the mean value represent the experience of the typical investor?\n\n\n\npraise()\n\n\nA law firm takes cases on a contingent fee basis. If the case goes to trial, the firm expects to earn \\(\\$25000\\) as part of the settlement if it wins and nothing if it does not. The firm wins one-third of the cases that go to trial. If the case does not go to trial, the firm earns nothing. Half of the cases do not go to trial.\n\nDefine a random variable to model the earning of taking a case of this type.\nWhat is the expected value of such a case to the firm?\nWhat is the standard deviation of the earnings?\n\nThe maintenance staff of a large office building regularly replaces fluorescent ceiling lights that have gone out. During a visit to a typical floor, the staff may have to replace several lights. The manager of this staff has given the following probabilities to the number of lights (identified by the random variable \\(Y\\)) that need to be replaced on the floor:\n\n\n\n\\(Y\\)\n0\n1\n2\n3\n4\n\n\n\\(P(Y = y)\\)\n0.2\n0.15\n0.2\n0.3\n0.15\n\n\n\n\nHow many lights should the manager expect to replace on a floor?\nWhat is the standard deviation of the number of lights on a floor that are replaced?\nIf a crew takes six lights to a floor, how many should it expect to have left after replacing those that are out?\nIf a crew takes six lights to a floor, find the standard deviation of the number of lights that remain after replacing those that are out on a floor.\nIf it takes 10 minutes to replace each light, how long should the manager expect the crew to take when replacing the lights on a floor.\n\nSuppose that you’ve just bought a \\(\\$4000\\) TV. Should you also buy the \\(\\$50\\) surge protector that guarantees to protect your TV from electric surges caused by lightning?\n\nLet \\(p\\) denote the probability that your home is hit by lightning during the time that you own this TV, say five years. In order for the purchase of the surge protector to have positive long-term values, what must the chance of being hit by lightning be?\nThere are about 100 million households in the United States, and fewer than 10,000 get hit by lightening each year. Do you think the surge protector is a good deal on average? Be sure to note any assumptions that you make.\n\n\n\npraise()\n\n\nThe ATM at a local convenience store allows customers to make withdrawals of \\(\\$10\\), \\(\\$20\\), \\(\\$50\\), or \\(\\$100\\). Let \\(X\\) denote a random variable that indicates the amount withdrawn by a customer. The probability distribution of \\(X\\) is:\n\\(p(10) = 0.2\\)\n\\(p(20) = 0.5\\)\n\\(p(50) = 0.2\\)\n\\(p(100) = 0.1\\)\n\nPlot the probability distribution of \\(X\\) in R.\nWhat is the probability that a customer withdraws more than \\(\\$20\\)?\nWhat is the expected amount of money withdrawn by a customer?\nThe expected value is not a possible value value of the amount withdrawn. Interpret the expected value for a manager.\nFind the variance and standard deviation of \\(X\\)."
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %>%\n  count(manufacturer) %>%\n  mutate(manufacturer = str_to_title(manufacturer)) %>%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel <- lm(mpg ~ hp, data = mtcars)\ntidy(model) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STAT 1010.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "repo-structure/proposal/proposal.html",
    "href": "repo-structure/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "repo-structure/proposal/proposal.html#introduction",
    "href": "repo-structure/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "repo-structure/proposal/proposal.html#data",
    "href": "repo-structure/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "repo-structure/proposal/proposal.html#data-analysis-plan",
    "href": "repo-structure/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "slides/lect_18.html#sampling",
    "href": "slides/lect_18.html#sampling",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Sampling",
    "text": "Sampling\n\n\nSRS\nStratified sampling\nCluster sampling\nit would be nice to sample repeatedly to see how the mean values compare"
  },
  {
    "objectID": "slides/lect_18.html#benefits-of-averaging",
    "href": "slides/lect_18.html#benefits-of-averaging",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Benefits of averaging",
    "text": "Benefits of averaging\n\n\nreduces variation\nmore normal than the original distribution"
  },
  {
    "objectID": "slides/lect_18.html#normal-model",
    "href": "slides/lect_18.html#normal-model",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Normal model",
    "text": "Normal model\n\n\nFind kurtosis(\\(K_4\\))\nIf \\(n > 10 |K_4|\\), where \\(n\\) is the sample size, then a normal model adequately approximates the distribution of the sample mean \\(\\bar{X}\\).\nIf we know the data come from a normal distribution this is also true."
  },
  {
    "objectID": "slides/lect_18.html#standard-error",
    "href": "slides/lect_18.html#standard-error",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Standard error",
    "text": "Standard error\n\\[ SD(\\bar{X}) = SE(\\bar{X}) =\n\\frac{\\sigma}{\\sqrt{n}} \\]"
  },
  {
    "objectID": "slides/lect_18.html#sampling-distribution",
    "href": "slides/lect_18.html#sampling-distribution",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Sampling distribution",
    "text": "Sampling distribution\nIf \\(X \\sim N(\\mu_X, \\sigma_X^2)\\)\n\\[ \\bar{X} \\sim N(\\mu = \\mu_X, \\sigma^2 = \\frac{\\sigma_X^2}{n}) \\]"
  },
  {
    "objectID": "slides/lect_18.html#example",
    "href": "slides/lect_18.html#example",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Example",
    "text": "Example\n\n\nLet \\(Y \\sim N(\\mu = 5, \\sigma^2 = 16)\\), find the distribution of the mean of repeated samples of size 4.\n\n\\(\\bar{Y} \\sim N(\\mu = 5, \\sigma^2 = 4)\\)"
  },
  {
    "objectID": "slides/lect_18.html#control-limits",
    "href": "slides/lect_18.html#control-limits",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Control limits",
    "text": "Control limits\n\n\nif mean production is outside certain values, we may need to stop and recallibrate machinery\nthese values are called control limits\n\\(\\mu - L \\leq \\bar{X} \\leq \\mu + L\\)\n\\(\\mu - L\\) and \\(\\mu + L\\) are control limits"
  },
  {
    "objectID": "slides/lect_18.html#types-of-errors",
    "href": "slides/lect_18.html#types-of-errors",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Types of errors",
    "text": "Types of errors\n\n\nFalse positives - type 1 error\n\nact when you should not\nprobabiliy of occurence denoted \\(\\alpha\\)\n\nFalse negatives - type 2 error\n\ndon’t act when you should\nprobabiliy of occurence denoted \\(\\beta\\)"
  },
  {
    "objectID": "slides/lect_18.html#setting-control-limits---1",
    "href": "slides/lect_18.html#setting-control-limits---1",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Setting control limits - 1",
    "text": "Setting control limits - 1\nIf \\(\\bar{X} \\sim N(\\mu = 12, \\sigma^2 = 2.3)\\) how can we find the control limits?\n\n\nSet the control limits and find the \\(\\alpha\\) value\n\nWe want the control limits to be between 10 and 14\n\\(Pr(\\bar{X} < 10 \\textrm{ or } \\bar{X} > 14)\\)\n\\(\\begin{aligned}P(\\bar{X} < 10) &= P(\\frac{\\bar{X} - \\mu_\\bar{X}}{\\sigma_\\bar{X}} < \\frac{10-\\mu_\\bar{X}}{\\sigma_\\bar{X}}) \\\\ & = P(Z < \\frac{10-12}{\\sqrt{2.3}} = -1.318761)\\end{aligned}\\)\npnorm(-1.318761) \\(\\approx 0.09362451\\)\npnorm(10, mean = 12, sd = sqrt(2.3))"
  },
  {
    "objectID": "slides/lect_18.html#setting-control-limits---1-contd",
    "href": "slides/lect_18.html#setting-control-limits---1-contd",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Setting control limits - 1 cont’d",
    "text": "Setting control limits - 1 cont’d\nIf \\(\\bar{X} \\sim N(\\mu = 12, \\sigma^2 = 2.3)\\) how can we find the control limits?\n\n\nSet the control limits and find the \\(\\alpha\\) value\n\nWe want the control limits to be between 10 and 14\n\\(\\begin{aligned}P(\\bar{X} > 14) &= P(\\frac{\\bar{X} - \\mu_\\bar{X} }{\\sigma_\\bar{X}} > \\frac{14-\\mu_\\bar{X}}{\\sigma_\\bar{X}}) \\\\ & = P(Z > \\frac{14-12}{\\sqrt{2.3}} = 1.318761)\\end{aligned}\\)\n1 - pnorm(1.318761) \\(\\approx 0.09362451\\)\n1 - pnorm(14, mean = 12, sd = sqrt(2.3))\nthe \\(\\alpha\\) value is \\(19\\%\\) which is very high!"
  },
  {
    "objectID": "slides/lect_18.html#setting-control-limits---2",
    "href": "slides/lect_18.html#setting-control-limits---2",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Setting control limits - 2",
    "text": "Setting control limits - 2\n\n\nSet the \\(\\alpha\\) value and find the control limits\n\n\nWe want the \\(\\alpha\\) to be \\(0.025\\)\n\n\\(Pr(\\bar{X} < z_{0.0125} \\textrm{ or } \\bar{X} > z_{0.0125})\\)\nqnorm(0.0125) \\(\\approx -2.241403\\)\n\\(\\begin{aligned}-2.241403 =& \\frac{X - \\mu_\\bar{X}}{\\sigma_\\bar{X}}\\\\ & = \\frac{X - 12}{\\sqrt{2.3}} \\\\ &= -2.241403\\sqrt{2.3} +12 = 8.600744 \\end{aligned}\\)\nqnorm(0.0125, mean = 12, sd = sqrt(2.3))"
  },
  {
    "objectID": "slides/lect_18.html#setting-control-limits---2---contd",
    "href": "slides/lect_18.html#setting-control-limits---2---contd",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Setting control limits - 2 - cont’d",
    "text": "Setting control limits - 2 - cont’d\n\n\nSet the \\(\\alpha\\) value and find the control limits\n\n\nWe want the \\(\\alpha\\) to be \\(0.025\\)\n\n\\(Pr(\\bar{X} < z_{0.0125} \\textrm{ or } \\bar{X} > z_{0.0125})\\)\nqnorm(1- 0.0125) \\(\\approx 2.241403\\)\n\\(\\begin{aligned}2.241403 =& \\frac{X - \\mu_\\bar{X}}{\\sigma_\\bar{X}}\\\\ & = \\frac{X - 12}{\\sqrt{2.3}} \\\\ &= 2.241403\\sqrt{2.3} +12 = 15.39926 \\end{aligned}\\)\nqnorm(1-0.0125, mean = 12, sd = sqrt(2.3))"
  },
  {
    "objectID": "slides/lect_18.html#repeated-testing",
    "href": "slides/lect_18.html#repeated-testing",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Repeated testing",
    "text": "Repeated testing\nWe are not testing once, but multiple times. Assuming independence:\n\n\n\\(\\begin{aligned}P(\\textrm{within limits for 10 days}) =& P(\\textrm{within limits for day 1}) \\cdot P(\\textrm{within limits for day 2}) \\cdot \\dots \\cdot P(\\textrm{within limits for day 10})\\\\ &= 0.975^{10} \\approx 0.7763296 \\end{aligned}\\)\nThere is a \\(1-0.7763296 = 0.2236704\\) percent false positive rate\nManagement must decide if there is a false positive by checking for mechanical errors and inspecting equipment\nAdjust \\(\\alpha\\) value to address this"
  },
  {
    "objectID": "slides/lect_18.html#control-charts-for-variation",
    "href": "slides/lect_18.html#control-charts-for-variation",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Control charts for variation",
    "text": "Control charts for variation\nX-bar charts are slow to detect under or over filling\n\n\nS-Chart tracks the standard deviation from sample to sample\nR-Chart tracks the range from sample to sample\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_08.html#price-vs-carat",
    "href": "slides/lect_08.html#price-vs-carat",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Price vs carat",
    "text": "Price vs carat"
  },
  {
    "objectID": "slides/lect_08.html#covariance-math",
    "href": "slides/lect_08.html#covariance-math",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Covariance math",
    "text": "Covariance math\n\nThis is a measure of the squares. We’d like a measure that is one dimensional. We want to look at more than just squares.\n\n\\(cov(x, y) = \\frac{(x_1 - \\bar{x})(y_1 - \\bar{y}) + (x_2 - \\bar{x})(y_2 - \\bar{y}) + \\ldots + (x_n - \\bar{x})(y_n - \\bar{y})}{n-1}\\)"
  },
  {
    "objectID": "slides/lect_08.html#correlation-math",
    "href": "slides/lect_08.html#correlation-math",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Correlation math",
    "text": "Correlation math\n\nStandardizes the strength of the association\n\n\\[corr(x, y) = \\frac{cov(x, y)}{s_x \\cdot s_y}\\]"
  },
  {
    "objectID": "slides/lect_08.html#correlation-characteristics",
    "href": "slides/lect_08.html#correlation-characteristics",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Correlation characteristics",
    "text": "Correlation characteristics\n\nStandardizes the strength of the association\n\n\n\nReferred to as \\(r\\)\nStrength of linear association\n\\(r\\) is always between \\(-1\\) and \\(+1\\), \\(-1 \\leq r \\leq 1\\).\n\\(r\\) does not have units"
  },
  {
    "objectID": "slides/lect_08.html#computing-in-r",
    "href": "slides/lect_08.html#computing-in-r",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Computing in R",
    "text": "Computing in R\n\nStandardizes the strength of the association\n\n\n# covariance of price and carat\ncov(diamonds$price, diamonds$carat)\n\n[1] 1742.765\n\n# correlation of price and carat\ncor(diamonds$price, diamonds$carat)\n\n[1] 0.9215913\n\n# coding for the pairs plots\n# library(GGally)\n# diamonds %>% # dataset\n#  select_if(is.numeric) %>% # numeric variables\n#  filter(y < 20, # y less than 20\n#         z < 20, # z less than 20\n#         table < 90) %>% # table less than 90\n#  ggpairs(.) # make the plot"
  },
  {
    "objectID": "slides/lect_08.html#gradient-and-slope",
    "href": "slides/lect_08.html#gradient-and-slope",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Gradient and slope",
    "text": "Gradient and slope\n\nPull out your calculators and work on this\n\n\\[ m = \\frac{r \\cdot s_y}{s_x} \\] \\[ b = \\bar{y} - m \\bar{x} \\]"
  },
  {
    "objectID": "slides/lect_08.html#fitting-by-hand",
    "href": "slides/lect_08.html#fitting-by-hand",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Fitting by hand",
    "text": "Fitting by hand\n\n\n\\(r = 0.9215913\\)\n\\(s_{price} = 3989.44\\)\n\\(s_{carat} = 0.4740112\\)\n\\(m = \\frac{r \\cdot s_{price}}{s_{carat}}\\)\n\\[\\begin{aligned}\n   m &= \\frac{r \\cdot s_{price}}{s_{carat}} \\\\\n&= \\frac{0.9215913 \\cdot 3989.44}{0.4740112} \\\\\n&= 7756.426\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_08.html#fitting-by-hand-1",
    "href": "slides/lect_08.html#fitting-by-hand-1",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Fitting by hand",
    "text": "Fitting by hand\n\n\n\\(b = \\overline{price} - m \\cdot \\overline{carat}\\)\n\\(\\overline{price} = 3932.8\\)\n\\(\\overline{carat} = 0.7979397\\)\n\\(m = 7756.426\\)\n\\[\\begin{aligned}\nb &= \\overline{price} - m \\cdot \\overline{carat} \\\\\n&= 3932.8 - 7756.426 \\cdot 0.7979397\\\\\n&= -2256.36\n\\end{aligned}\\]\nOur model is: \\(\\widehat{\\text{price}} = -2256.36 + 7756.426 \\cdot \\text{carat}\\)"
  },
  {
    "objectID": "slides/lect_08.html#prediction-by-hand",
    "href": "slides/lect_08.html#prediction-by-hand",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Prediction by hand",
    "text": "Prediction by hand\n\nPull out your calculators and work on this\n\nfor carat values \\(2.5\\)\n\n\n\\(\\widehat{\\text{price}} = -2256.36 + 7756.426 \\cdot \\text{carat}\\)\n\\[\\begin{aligned}\n\\widehat{\\text{price}}  &= -2256.36 + 7756.426 \\cdot \\text{carat} \\\\\n&= -2256.36 + 7756.426 \\cdot 2.5 \\\\\n&= \\$17135\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_08.html#fit-predict-in-r",
    "href": "slides/lect_08.html#fit-predict-in-r",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Fit & predict in R",
    "text": "Fit & predict in R\n\nfirst use of tidymodels package\n\n\n# library tidymodels\nlibrary(tidymodels)\n\n## Assign the least\n## squares line\nleast_squares_fit <- \n  linear_reg() %>% \n  set_engine(\"lm\") %>% \n  fit(price ~ carat, data = diamonds) \n## NOTE: outcome first, predictor second\n\n## Find the prediction\npredict(least_squares_fit, tibble(carat = c(1, 2, 2.5, 4)))\n\n# A tibble: 4 × 1\n   .pred\n   <dbl>\n1  5500.\n2 13256.\n3 17135.\n4 28769."
  },
  {
    "objectID": "slides/lect_08.html#warnings",
    "href": "slides/lect_08.html#warnings",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Warnings",
    "text": "Warnings\n\n\nALWAYS draw plots first\nnumeric variables\nLinear relationship\nCheck for outliers\nLurking variables"
  },
  {
    "objectID": "slides/lect_08.html#more-spurious-correlations",
    "href": "slides/lect_08.html#more-spurious-correlations",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "More spurious correlations",
    "text": "More spurious correlations\n\n\nThese variables are called lurking variables or confounders.\nLurking variables are not considered in the statistical analysis\nConfounders are considered\nThere are both known and unknown confounders, uknown confounders are lurking variables.\n\n\nClick here for more spurious correlations"
  },
  {
    "objectID": "slides/lect_09.html#compute-the-sharpe-ratio",
    "href": "slides/lect_09.html#compute-the-sharpe-ratio",
    "title": "Chapter 10: Association between random variables",
    "section": "Compute the Sharpe ratio",
    "text": "Compute the Sharpe ratio\n\nhave them go back to the previous slide and see what they got\n\n\n\n\nCompany\nRandom Variable\nMean per month\nSD\n\n\n\n\nApple\nA\n2.45%\n13.3%\n\n\nMcDonalds\nM\n1.14%\n6.2%\n\n\n\nassume \\(r_f\\) is the risk-free rate of interest is \\(0.1\\%\\)"
  },
  {
    "objectID": "slides/lect_09.html#compute-the-sharpe-ratio-1",
    "href": "slides/lect_09.html#compute-the-sharpe-ratio-1",
    "title": "Chapter 10: Association between random variables",
    "section": "Compute the Sharpe ratio",
    "text": "Compute the Sharpe ratio\n\nwork through it, then what if we don’t know mu and sigma could we find it if we had a pdf?\n\n\n\n\n\n\\[\\begin{aligned}\nS(A) &= \\frac{\\mu_A - r_f}{\\sigma_A}\\\\\n&= \\frac{2.45 - 0.1}{13.3}\\\\\n&=  0.177\n\\end{aligned}\\]\n\\[\\begin{aligned}\nS(M) &= \\frac{\\mu_M - r_f}{\\sigma_M}\\\\\n&= \\frac{1.14 - 0.1}{6.2}\\\\\n&=  0.168\n\\end{aligned}\\]\n\n\n\nWe prefer Apple because it has a higher Sharpe ratio \\(0.177 > 0.168\\)"
  },
  {
    "objectID": "slides/lect_09.html#revision-2",
    "href": "slides/lect_09.html#revision-2",
    "title": "Chapter 10: Association between random variables",
    "section": "Revision 2",
    "text": "Revision 2\n\nfind the mean, stdev, and use them to find the Sharpe ratio\nput microsoft is y on the board and IBM is x\ncopy down the means and st deviation when they get them\n\nInstead of knowing \\(\\mu\\) and \\(\\sigma\\) we have a pdf\n\n\n\n\nIBM stock\nIBM stock\nMicrosoft\nMicrosoft\n\n\n\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(y\\)\n\\(P(Y = y)\\)\n\n\nIncreases\n$5\n0.11\n$4\n0.18\n\n\nNo change\n0\n0.80\n0\n0.67\n\n\nDecreases\n-$5\n0.09\n-$4\n0.15"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-by-hand",
    "href": "slides/lect_09.html#sharpe-ratio-by-hand",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio by hand",
    "text": "Sharpe ratio by hand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIBM\nIBM\nIBM\nIBM\nIBM\nIBM\nIBM\n\n\n\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(\\mu_X\\)\n\\((x-\\mu_X)^2 \\cdot p_X(x)\\)\n\\(Var(X)\\)\n\\(sd(X)\\)\nSharpe ratio\n\n\nIncreases\n$5\n0.11\n\n\n\n\n\n\n\nNo change\n0\n0.80\n\n\n\n\n\n\n\nDecreases\n-$5\n0.09"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-by-hand-1",
    "href": "slides/lect_09.html#sharpe-ratio-by-hand-1",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio by hand",
    "text": "Sharpe ratio by hand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIBM\nIBM\nIBM\nIBM\nIBM\nIBM\nIBM\n\n\n\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(\\mu_X\\)\n\\((x-\\mu_X)^2 \\cdot p_X(x)\\)\n\\(Var(X)\\)\n\\(sd(X)\\)\nSharpe ratio\n\n\nIncreases\n$5\n0.11\n0.1\n2.6411\n4.99\n2.23\n0.03805123\n\n\nNo change\n0\n0.80\n0.1\n0.0080\n4.99\n2.23\n0.03805123\n\n\nDecreases\n-$5\n0.09\n0.1\n2.3409\n4.99\n2.23\n0.03805123"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-by-hand-2",
    "href": "slides/lect_09.html#sharpe-ratio-by-hand-2",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio by hand",
    "text": "Sharpe ratio by hand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\n\n\n\n\n\n\\(y\\)\n\\(P(Y =y)\\)\n\\(\\mu_Y\\)\n\\((y-\\mu_Y)^2 \\cdot p_Y(y)\\)\n\\(Var(Y)\\)\n\\(sd(Y)\\)\nSharpe ratio\n\n\nIncreases\n$4\n0.18\n\n\n\n\n\n\n\nNo change\n0\n0.67\n\n\n\n\n\n\n\nDecreases\n-$4\n0.15"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-by-hand-3",
    "href": "slides/lect_09.html#sharpe-ratio-by-hand-3",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio by hand",
    "text": "Sharpe ratio by hand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\n\n\n\n\n\n\\(y\\)\n\\(P(Y =y)\\)\n\\(\\mu_Y\\)\n\\((y-\\mu_Y)^2 \\cdot p_Y(y)\\)\n\\(Var(Y)\\)\n\\(sd(Y)\\)\nSharpe ratio\n\n\nIncreases\n$4\n0.18\n0.12\n2.709792\n5.2656\n2.29469\n0.04575782\n\n\nNo change\n0\n0.67\n0.12\n0.009648\n5.2656\n2.29469\n0.04575782\n\n\nDecreases\n-$4\n0.15\n0.12\n2.546160\n5.2656\n2.29469\n0.04575782"
  },
  {
    "objectID": "slides/lect_09.html#the-sharpe-ratio---in-r",
    "href": "slides/lect_09.html#the-sharpe-ratio---in-r",
    "title": "Chapter 10: Association between random variables",
    "section": "The Sharpe ratio - in R",
    "text": "The Sharpe ratio - in R\n\nCan an investor do better by diversifing the investment?\n\n\n# Input the data and the pdf\nstock <- tibble(x = c(5, 0, -5), \n                p_x = c(0.11, 0.8, 0.09), \n                y = c(4, 0, -4), \n                p_y = c(.18, .67, .15))\n\n\nSharpe_ratio <- # name this the Sharpe ratio\n  stock %>% # use the data from above\n  mutate(part_mean_x = x*p_x, # find mean for each part of x \n         part_mean_y = y*p_y, # now for y\n         mean_x = sum(part_mean_x), # find mean x \n         mean_y = sum(part_mean_y),# now for y\n         part_var_x = p_x * (mean_x - x)^2, # find var for each part of x \n         part_var_y = p_y * (mean_y - y)^2,# now for y\n         var_x = sum(part_var_x), # find var of x \n         var_y = sum(part_var_y),# now for y\n         sd_x = sqrt(var_x), # find sd of x \n         sd_y = sqrt(var_y)) %>% # now for y\n  summarise(S_x = (mean_x - 0.015)/sd_x, # find Sharpe ratio of x with rf = 0.015\n            S_y = (mean_y - 0.015)/sd_y) %>% # now for y\n  slice(1)"
  },
  {
    "objectID": "slides/lect_09.html#expected-value-of-x-y",
    "href": "slides/lect_09.html#expected-value-of-x-y",
    "title": "Chapter 10: Association between random variables",
    "section": "Expected value of \\(X + Y\\)",
    "text": "Expected value of \\(X + Y\\)\n\nIf x=-5 then we subtract 5 from all y’s and multiply by \\(p_{x, y}\\) algebraically it all washes out\nWhat about independence? We want to find the standard deviation to compute the Sharpe Ratio\n\n\n\n\n\n\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\n\n\n\n\n\\(x = -5\\)\n\\(x = 0\\)\n\\(x = 5\\)\n\\(p(y)\\)\n\n\n\\(Y\\)\n\\(y=4\\)\n\\(0.00\\)\n\\(0.11\\)\n\\(0.07\\)\n\\(0.18\\)\n\n\n\\(Y\\)\n\\(y=0\\)\n\\(0.03\\)\n\\(0.62\\)\n\\(0.02\\)\n\\(0.67\\)\n\n\n\\(Y\\)\n\\(y=-4\\)\n\\(0.06\\)\n\\(0.07\\)\n\\(0.02\\)\n\\(0.15\\)\n\n\n\n\\(p(x)\\)\n\\(0.09\\)\n\\(0.80\\)\n\\(0.11\\)\n\\(1\\)\n\n\n\n\n\n\\(E(X+Y) = E(X) + E(Y)\\)\n\\(E(X+Y) = E(X) + E(Y) = 0.1 + 0.12 = 0.22\\)"
  },
  {
    "objectID": "slides/lect_09.html#are-x-and-y-independent",
    "href": "slides/lect_09.html#are-x-and-y-independent",
    "title": "Chapter 10: Association between random variables",
    "section": "Are \\(X\\) and \\(Y\\) independent?",
    "text": "Are \\(X\\) and \\(Y\\) independent?\n\nfind any p(x) X p(y) != p(x,y)\nBut we still need to find the stdev in order to find Sharpes ratio\n\n\n\n\n\n\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\n\n\n\n\n\\(x = -5\\)\n\\(x = 0\\)\n\\(x = 5\\)\n\\(p(y)\\)\n\n\n\\(Y\\)\n\\(y=4\\)\n\\(0.00\\)\n\\(0.11\\)\n\\(0.07\\)\n\\(0.18\\)\n\n\n\\(Y\\)\n\\(y=0\\)\n\\(0.03\\)\n\\(0.62\\)\n\\(0.02\\)\n\\(0.67\\)\n\n\n\\(Y\\)\n\\(y=-4\\)\n\\(0.06\\)\n\\(0.07\\)\n\\(0.02\\)\n\\(0.15\\)\n\n\n\n\\(p(x)\\)\n\\(0.09\\)\n\\(0.80\\)\n\\(0.11\\)\n\\(1\\)\n\n\n\n\n\n\\(p_x(-5) \\cdot p_y(4) = 0.18 \\cdot 0.09 \\neq 0.00\\)\n\\(p_x(-5) \\cdot p_y(-4) = 0.09 \\cdot 0.15 = 0.0135 \\neq 0.06\\)\nNO! NO! NO!"
  },
  {
    "objectID": "slides/lect_09.html#covariance-of-sum",
    "href": "slides/lect_09.html#covariance-of-sum",
    "title": "Chapter 10: Association between random variables",
    "section": "Covariance of sum",
    "text": "Covariance of sum\n\nbecause we square things and \\((a + b)^2 = a^2 + b^2 + 2ab\\) we have to add 2 of the covariance\n\n\n\n\\((a+b)^2 = a^2 + 2ab +b^2\\)\nit follows that\n\\(Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y)\\)"
  },
  {
    "objectID": "slides/lect_09.html#correlation",
    "href": "slides/lect_09.html#correlation",
    "title": "Chapter 10: Association between random variables",
    "section": "Correlation",
    "text": "Correlation\n\nwhat about our joint pdf? is it positively or negatively correlated? 3D plot\n\n\n\n\\(corr(x, y) = \\frac{cov(x, y)}{s_x \\cdot s_y}\\)\n\\[\\rho = Corr(X, Y) = \\frac{Cov(X, Y)}{\\sigma_X \\cdot \\sigma_Y}\\]\n\nAs \\(X\\) increases, what happens to \\(Y\\)?\n\n\n\n\n\n\n\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\n\n\n\n\n\\(x = -5\\)\n\\(x = 0\\)\n\\(x = 5\\)\n\\(p(y)\\)\n\n\n\\(Y\\)\n\\(y=4\\)\n\\(0.00\\)\n\\(0.11\\)\n\\(0.07\\)\n\\(0.18\\)\n\n\n\\(Y\\)\n\\(y=0\\)\n\\(0.03\\)\n\\(0.62\\)\n\\(0.02\\)\n\\(0.67\\)\n\n\n\\(Y\\)\n\\(y=-4\\)\n\\(0.06\\)\n\\(0.07\\)\n\\(0.02\\)\n\\(0.15\\)\n\n\n\n\\(p(x)\\)\n\\(0.09\\)\n\\(0.80\\)\n\\(0.11\\)\n\\(1\\)"
  },
  {
    "objectID": "slides/lect_09.html#independence-cov",
    "href": "slides/lect_09.html#independence-cov",
    "title": "Chapter 10: Association between random variables",
    "section": "Independence & Cov",
    "text": "Independence & Cov\nHow does independence impact upon correlation and covariance?\n\\[ E((X-\\mu_X)(Y-\\mu_Y))\\]\n\n\n\\[\\begin{aligned}\nCov(X,Y) &= E((X-\\mu_X)(Y-\\mu_Y))\\\\\n&= E(X - \\mu_X)E(Y-\\mu_Y)\\\\\n&= 0\n\\end{aligned}\\]\nIf \\(X\\),\\(Y\\) are independent, then \\(Cov(X, Y) = 0\\)\nThe opposite is not true (if \\(Cov(X, Y) = 0\\), then \\(X\\),\\(Y\\) are independent)"
  },
  {
    "objectID": "slides/lect_09.html#independence-var",
    "href": "slides/lect_09.html#independence-var",
    "title": "Chapter 10: Association between random variables",
    "section": "Independence & Var",
    "text": "Independence & Var\n\\(Var(X) + Var(Y) = Var(X) + Var(Y) + 2Cov(X, Y)\\)\n\n\nIf \\(X\\), \\(Y\\) are independent, \\(Cov(X, Y) = 0\\), so\n\\[Var(X+ Y) = Var(X) + Var(Y)\\]"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-of-a-sum",
    "href": "slides/lect_09.html#sharpe-ratio-of-a-sum",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio of a sum",
    "text": "Sharpe ratio of a sum\n\\[ S(X + Y) = \\frac{(\\mu_X + \\mu_Y) - 2r_f}{\\sqrt{(Var(X+Y))}} \\]"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-of-sum---r",
    "href": "slides/lect_09.html#sharpe-ratio-of-sum---r",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio of sum - R",
    "text": "Sharpe ratio of sum - R\n\nWhat if we want to invest in two subsequent days instead of investing in two stocks for 1 day?\n\n\n# input x & y\nx <- c(-5, 0, 5)\ny <- c(4, 0, -4)\n\n# input data\ndata <- bind_cols(expand_grid(x, y), \n                  probs = c(0, .03, .06, \n                            .11, .62, .07, \n                            .07, .02, .02), \n                  mu_x = rep(0.1, 9), \n                  mu_y = rep(0.12, 9), \n                  var_x = rep(4.99, 9), \n                  var_y = rep(5.2656, 9))\n\ndata %>% \n  mutate(cov_xy_part = (x - mu_x)*\n           (y - mu_y)*probs, # multiply together\n         cov_xy = sum(cov_xy_part), # sum them\n         var_xy = var_x + var_y + 2*cov_xy) %>% # using the rule\n  summarise(S_r = (mu_x + mu_y - 2*0.015)/\n                      (sqrt(var_xy))) %>% # find the Sharpe value\n  slice(1) # only the first\n\n# A tibble: 1 × 1\n     S_r\n   <dbl>\n1 0.0497\n\n\n\n\nThe Sharpe ratio for \\(X\\) is \\(0.038\\), for \\(Y\\) it’s \\(0.046\\), investing in both gives a better return \\(0.050\\)"
  },
  {
    "objectID": "slides/lect_09.html#double-for-one-day",
    "href": "slides/lect_09.html#double-for-one-day",
    "title": "Chapter 10: Association between random variables",
    "section": "Double for one day",
    "text": "Double for one day\n\\[S(2X) = \\frac{2\\mu_X - 2r_f}{\\sqrt{Var(2X)}}\\]\n\n\n\\(\\mu_X = 0.1\\)\n\\(Var(X) = 4.99\\)\n\\(r_f = .015\\)\n\\[\\begin{aligned}\n  &= \\frac{2 \\cdot 0.1 - 2 \\cdot 0.015}{\\sqrt{4 \\cdot 4.99}}\\\\\n  &= \\frac{.2 - 0.03}{\\sqrt{19.96}}\\\\\n  &= 0.038\n  \\end{aligned}\\]\nThis is the same as before, how do we compute if we invest for two subsequent days?"
  },
  {
    "objectID": "slides/lect_09.html#iid",
    "href": "slides/lect_09.html#iid",
    "title": "Chapter 10: Association between random variables",
    "section": "IID",
    "text": "IID\nIf we invested in a stock on 2 subsequent days instead of investing in 2 stocks on one day the return on those two days are:\nindependent and identically distributed (IID)\n\n\nidentically distributed - the outcomes on each day are likely to be different, but the probability of the outcomes is the same\nindependent - very common assumption for stocks (part of the reason for the 2008 financial crises)"
  },
  {
    "objectID": "slides/lect_09.html#addition-rules-for-iid-variables",
    "href": "slides/lect_09.html#addition-rules-for-iid-variables",
    "title": "Chapter 10: Association between random variables",
    "section": "Addition rules for IID variables",
    "text": "Addition rules for IID variables\n\n\n\n\n\n\nImportant\n\n\nIf \\(n\\) random variables \\((X_1, X_2, ..., X_n)\\) are iid with mean \\(\\mu_X\\) and standard deviation \\(\\sigma_X\\), then\n\\[ E(X_1 + X_2 + ... + X_n) = n \\cdot \\mu_X \\] \\[ Var(X_1 + X_2 + ... + X_n) = n \\cdot \\sigma^2_x \\] \\[ SD(X_1 + X_2 + ... + X_n) = \\sqrt{n} \\sigma_X \\]"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio---two-days",
    "href": "slides/lect_09.html#sharpe-ratio---two-days",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio - two days",
    "text": "Sharpe ratio - two days\n\nif you decide to leave money in the bank, you may end up with a constant\n\n\\[ S(X_1 + X_2) = \\frac{2\\mu_X - 2r_f}{\\sqrt{2 \\sigma^2_x}}\\]\n\n\n\\[\\begin{aligned}\n&= \\frac{0.20 - 0.03}{\\sqrt{9.98}}\\\\\n&= 0.054\n\\end{aligned}\\]\nyou expect more variance if you have two stock for one day b/c anything that happens that day is magnified\nif you have one stock for two days you reduce the variance"
  },
  {
    "objectID": "slides/lect_09.html#expectation-of-weighted-sum",
    "href": "slides/lect_09.html#expectation-of-weighted-sum",
    "title": "Chapter 10: Association between random variables",
    "section": "Expectation of weighted sum",
    "text": "Expectation of weighted sum\n\\[ E(2X + 4Y + 0.06)\\]\n\n\n\n\\[\\begin{aligned}\n&= 2E(X) + 4E(Y) + 0.06\\\\\n&= 2(0.10) + 4(0.12) + 0.06\\\\\n&= \\$0.74\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_09.html#variance-of-weighted-sum",
    "href": "slides/lect_09.html#variance-of-weighted-sum",
    "title": "Chapter 10: Association between random variables",
    "section": "Variance of weighted sum",
    "text": "Variance of weighted sum\n\\[ Var(2X + 4Y + 0.06)\\]\n\n\n\\[\\begin{aligned}\n&= 2^2Var(X) + 4^2Var(Y) + 2 \\cdot(2 \\cdot 4) \\cdot Cov(X,Y)\\\\\n&= 4(4.99) + 16(5.27) + 16(2.19)\\\\\n&= 139.32\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_10.html#ebernoulli",
    "href": "slides/lect_10.html#ebernoulli",
    "title": "Chapter 11: Probability models for counts",
    "section": "E(Bernoulli)",
    "text": "E(Bernoulli)\n\n\n\\(E(B) = 0 \\cdot P(B=0) + 1 \\cdot P(B=1)\\)\n\\[\\begin{aligned}\nE(B) &= 0 \\cdot P(B=0) + 1 \\cdot P(B=1)\\\\\n&= 0 \\cdot (1-p) + 1 \\cdot p\\\\\n&= p\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#varbernoulli",
    "href": "slides/lect_10.html#varbernoulli",
    "title": "Chapter 11: Probability models for counts",
    "section": "Var(Bernoulli)",
    "text": "Var(Bernoulli)\n\nWe usually don’t want this information about 1 person, we want it about a whole plane full of people, or a whole town.\nIn that case, we sum together \\(n\\) independent Bernoulli trials.\n\n\n\n\\(Var(B) = (0 - p)^2 \\cdot P(B=0) + (1 - p)^2 \\cdot P(B=1)\\)\n\\[\\begin{aligned}\nVar(B) &= (0 - p)^2 \\cdot P(B=0) + (1 - p)^2 \\cdot P(B=1)\\\\\n&= p^2 \\cdot (1-p) + (1 - p)^2 \\cdot p\\\\\n&= p^2 - p^3 + p(1 - 2p + p^2) \\\\\n&= p^2 - p^3 + p - 2p^2 + p^3\\\\\n&= p(1-p)\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#multiple-bernoulli-trials",
    "href": "slides/lect_10.html#multiple-bernoulli-trials",
    "title": "Chapter 11: Probability models for counts",
    "section": "Multiple Bernoulli trials",
    "text": "Multiple Bernoulli trials\n\nThis happens so often that we have another name for this distribution\n\n\\[Y = B_1 + B_2 + ...  + B_n\\]\n\n\n\\(Y\\) is the sum of independent and identically distributed random variables\nWhat is the mean and variance?"
  },
  {
    "objectID": "slides/lect_10.html#ebinomial",
    "href": "slides/lect_10.html#ebinomial",
    "title": "Chapter 11: Probability models for counts",
    "section": "E(Binomial)",
    "text": "E(Binomial)\n\\[E(Y) = E(B_1 + B_2 + ... + B_n)\\]\n\n\n\\[\\begin{aligned}\nE(Y) &= E(B_1) + E(B_2) + ... + E(B_n) \\\\\n&= p + p + ... + p \\\\\n&= np\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#varbinomial",
    "href": "slides/lect_10.html#varbinomial",
    "title": "Chapter 11: Probability models for counts",
    "section": "Var(Binomial)",
    "text": "Var(Binomial)\n\nthere are multiple ways that we can have 5 successes, so we must also learn to count\n\n\\[Var(Y) = Var(B_1 + B_2 + ... + B_n)\\]\n\n\n\\[\\begin{aligned}\nVar(Y) &= Var(B_1) + Var(B_2) + ... + Var(B_n) \\\\\n&= p(1-p) + p(1-p) + ... + p(1-p) \\\\\n&= np(1-p)\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#counting-things",
    "href": "slides/lect_10.html#counting-things",
    "title": "Chapter 11: Probability models for counts",
    "section": "Counting things",
    "text": "Counting things\n\nwe just went into groups how many groups are possible?\n\nIn a class of 85 students how many groups of 4 are possible?\n\n\n\\(85 \\cdot 84 \\cdot 83 \\cdot 82\\)\n\\(48,594,840\\) groups\nIf we don’t care about order\n\\(\\frac{85 \\cdot 84 \\cdot 83 \\cdot 82}{4 \\cdot 3 \\cdot 2 \\cdot 1}\\)\n\\(2,024,785\\) groups\nCombination written as \\({}_{n}C_{k}\\) here \\(n = 85\\), \\(k = 4\\) or \\(\\binom{85}{4}\\)\n\n\n\nexp(lfactorial(85))/exp(lfactorial(81))\n\n[1] 48594840\n\nexp(lfactorial(85))/(exp(lfactorial(81))*exp(lfactorial(4)))\n\n[1] 2024785"
  },
  {
    "objectID": "slides/lect_10.html#binomial-pdf",
    "href": "slides/lect_10.html#binomial-pdf",
    "title": "Chapter 11: Probability models for counts",
    "section": "Binomial pdf",
    "text": "Binomial pdf\nIf \\(Y \\sim Bin(n, p)\\) where\n\n$n = $ number of trials\n$p = $ probability of success\n$y = $ number of successes in \\(n\\) Bernoulli trials\n\n\nthen  \\[P(Y = y) = \\binom{n}{y}p^y(1-p)^{n-y}\\]"
  },
  {
    "objectID": "slides/lect_10.html#example",
    "href": "slides/lect_10.html#example",
    "title": "Chapter 11: Probability models for counts",
    "section": "Example",
    "text": "Example\n\n\nLet \\(Y \\sim Bin(n = 5, p = 0.2)\\) find the \\(E(Y)\\) and \\(Var(Y)\\)\n\n\n\n\\(E(Y) = np = 1\\)\n\\(Var(Y) = np(1-p) = 0.8\\)\nWhat is the probability that \\(y = 3\\)? In R: dbinom(size  = 5, prob = 0.2, x = 3) \\(0.0512\\)\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#warnings",
    "href": "slides/lect_10.html#warnings",
    "title": "Chapter 11: Probability models for counts",
    "section": "Warnings",
    "text": "Warnings\n10% Condition: if trials are selected at random, it is OK to ignore dependence caused by sampling from a finite population if the selected trials make up less than 10% of the population"
  },
  {
    "objectID": "slides/lect_10.html#limit-of-p--mins",
    "href": "slides/lect_10.html#limit-of-p--mins",
    "title": "Chapter 11: Probability models for counts",
    "section": "Limit of \\(p\\)- mins",
    "text": "Limit of \\(p\\)- mins\n\nsome of these cars may come by in the same minute..\n\nI know about 7 cars drive by my house in an hour, what’s the probability 18 cars drive by in the next 60 mins?\n\n\n\\(p = \\frac{7}{60}\\)\n\\(Y \\sim Bin(60, \\frac{7}{60})\\)\n\\(\\binom{60}{18}p^{18}(1-p)^{42}\\)"
  },
  {
    "objectID": "slides/lect_10.html#limit-of-p--secs",
    "href": "slides/lect_10.html#limit-of-p--secs",
    "title": "Chapter 11: Probability models for counts",
    "section": "Limit of \\(p\\)- secs",
    "text": "Limit of \\(p\\)- secs\nI know about 7 cars drive by my house in an hour, what’s the probability 18 cars drive by in the next 3600 secs?\n\n\n\\(p = \\frac{7}{3600}\\)\n\\(Y \\sim Bin(3600, \\frac{7}{3600})\\)\n\\(\\binom{3600}{18}p^{18}(1-p)^{3582}\\)"
  },
  {
    "objectID": "slides/lect_10.html#limit-of-p---smallest-interval",
    "href": "slides/lect_10.html#limit-of-p---smallest-interval",
    "title": "Chapter 11: Probability models for counts",
    "section": "Limit of \\(p\\) - smallest interval",
    "text": "Limit of \\(p\\) - smallest interval\nI know about 7 cars drive by my house in an hour, what’s the probability 18 cars drive by in the next much smaller than a second? Full derivation can be found here.\n\n\n\n\n\\(\\binom{n}{18}(\\frac{7}{n})^{18}(1-\\frac{7}{n})^{n-18}\\)\n\\(\\frac{n\\cdot(n-1)\\ldots(n-17)}{18!}\\cdot \\frac{7^{18}}{n^{18}}\\cdot (1-\\frac{7}{n})^{n} \\cdot \\frac{1}{(1-\\frac{7}{n})^{18}}\\)\n\\(\\frac{n\\cdot(n-1)\\ldots(n-17)}{n^{18}} \\rightarrow 1\\)\n\\(\\frac{1}{(1-\\frac{7}{n})^{18}} \\rightarrow 1\\)\n\n\n\n\n\\(\\frac{7^{18}}{18!}e^{-7}\\)"
  },
  {
    "objectID": "slides/lect_10.html#poisson-distribution---rips",
    "href": "slides/lect_10.html#poisson-distribution---rips",
    "title": "Chapter 11: Probability models for counts",
    "section": "Poisson distribution - RIPS",
    "text": "Poisson distribution - RIPS\n\n\nPoisson - fish - Rips\nR - randomly through space or time\nI - indepedent\nP - proportional to interval size\nS - singly - no multiple occurences in space or time"
  },
  {
    "objectID": "slides/lect_10.html#epois",
    "href": "slides/lect_10.html#epois",
    "title": "Chapter 11: Probability models for counts",
    "section": "E(Pois)",
    "text": "E(Pois)\n\n\\(\\lambda\\)"
  },
  {
    "objectID": "slides/lect_10.html#varpois",
    "href": "slides/lect_10.html#varpois",
    "title": "Chapter 11: Probability models for counts",
    "section": "Var(Pois)",
    "text": "Var(Pois)\n\n\\(\\lambda\\)"
  },
  {
    "objectID": "slides/lect_10.html#example-1",
    "href": "slides/lect_10.html#example-1",
    "title": "Chapter 11: Probability models for counts",
    "section": "Example",
    "text": "Example\n\n\nLet \\(Y \\sim Pois(\\lambda = 5)\\) find the \\(E(Y)\\) and \\(Var(Y)\\)\n\n\n\\(E(Y) = 5\\)\n\\(Var(Y) = 5\\)\nWhat is the probability that \\(y = 3\\)? In R: dpois(x = 3, lambda = 5) \\(0.1403739\\)\n\n\n\n\n\n02:00\n\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_11.html#binomial---normal",
    "href": "slides/lect_11.html#binomial---normal",
    "title": "Chapter 12: The normal probability model",
    "section": "Binomial -> Normal",
    "text": "Binomial -> Normal\nAs the number of trials increases, the binomial pdf becomes well approximated by a normal distribution.\n“Observed data often represent the accumulation of many small factors.”"
  },
  {
    "objectID": "slides/lect_11.html#central-limit-theorem",
    "href": "slides/lect_11.html#central-limit-theorem",
    "title": "Chapter 12: The normal probability model",
    "section": "Central limit theorem",
    "text": "Central limit theorem\n\nThere are multiple versions of the CLT\n\nThe probability distribution of a sum of independent random variables of comparable variance approaches a normal distribution as the number of summed random variables increases."
  },
  {
    "objectID": "slides/lect_11.html#shifts-scales",
    "href": "slides/lect_11.html#shifts-scales",
    "title": "Chapter 12: The normal probability model",
    "section": "Shifts & scales",
    "text": "Shifts & scales"
  },
  {
    "objectID": "slides/lect_11.html#standardizing",
    "href": "slides/lect_11.html#standardizing",
    "title": "Chapter 12: The normal probability model",
    "section": "Standardizing",
    "text": "Standardizing\n\nBooks and tables of just normal probabilities to multiple decimal places.\n\nHistorically, it could be quite hard to find probabilities, so standardizing was important.\n\n\nuse shift and scale information from above\n\\(Z = \\frac{X-\\mu_X}{\\sigma_X}\\)\nFind \\(E(Z)\\)\n\\(E(Z) = E(\\frac{X-\\mu_X}{\\sigma_X})\\)\n\\[\\begin{aligned}\nE(Z) & = E(\\frac{X-\\mu_X}{\\sigma_X})\\\\\n& = \\frac{1}{\\sigma_X}E(X-\\mu_X) \\\\\n&= 0\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_11.html#standardizing-1",
    "href": "slides/lect_11.html#standardizing-1",
    "title": "Chapter 12: The normal probability model",
    "section": "Standardizing",
    "text": "Standardizing\n\n\nuse shift and scale information from above\n\\(Z = \\frac{X-\\mu_X}{\\sigma_X}\\)\nFind \\(Var(Z)\\)\n\\[\\begin{aligned}\nVar(Z) & = Var(\\frac{X-\\mu_X}{\\sigma_X})\\\\\n& = \\frac{1}{\\sigma^2}Var(X-\\mu_X) \\\\\n&= \\frac{\\sigma^2}{\\sigma^2} = 1\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_11.html#example",
    "href": "slides/lect_11.html#example",
    "title": "Chapter 12: The normal probability model",
    "section": "Example",
    "text": "Example\nLet \\(Y \\sim N(\\mu_Y = 5, \\sigma_Y^2 = 4)\\), standardize the following and find the probability:\n\n\n\\(P(Y < 3)\\)\n\\[\\begin{aligned}\nP(Y < 3) &= P(\\frac{Y - \\mu_Y}{\\sigma_Y} < \\frac{3-\\mu_Y}{\\sigma_Y}) \\\\\n& = P(Z < \\frac{3-5}{2} = -1)\n\\end{aligned}\\]\npnorm(-1) \\(0.1586553\\)\npnorm(-1, mean = 5, sd = 2)\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_11.html#queen-bee",
    "href": "slides/lect_11.html#queen-bee",
    "title": "Chapter 12: The normal probability model",
    "section": "Queen Bee",
    "text": "Queen Bee\n\nTo the left, to the left, pnorm is to the left\n\nPercentiles are always to the left."
  },
  {
    "objectID": "slides/lect_11.html#example-1",
    "href": "slides/lect_11.html#example-1",
    "title": "Chapter 12: The normal probability model",
    "section": "Example",
    "text": "Example\n\nBoth of these probabilities are the same because of symmetry of the normal distribution. How does this generalize to all normal distributions?\n\nLet \\(Y \\sim N(\\mu_Y = 5, \\sigma_Y^2 = 4)\\), standardize the following and find the probability:\n\n\n\\(P(Y > 7)\\)\n\\[\\begin{aligned}\nP(Y > 7) &= P(\\frac{Y - \\mu_Y}{\\sigma_Y} > \\frac{7-\\mu_Y}{\\sigma_Y}) \\\\\n& = P(Z > \\frac{7-5}{2} = 1)\n\\end{aligned}\\]\npnorm(1) \\(0.8413447\\)\npnorm(1, mean = 5, sd = 2)\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_11.html#graph",
    "href": "slides/lect_11.html#graph",
    "title": "Chapter 12: The normal probability model",
    "section": "Graph",
    "text": "Graph"
  },
  {
    "objectID": "slides/lect_11.html#example-contd",
    "href": "slides/lect_11.html#example-contd",
    "title": "Chapter 12: The normal probability model",
    "section": "Example (cont’d)",
    "text": "Example (cont’d)\n\nThis and the previous example have the same probabilities attached to them b/c the distribution is symmetric\nSince they generally have the same shape what other things are true?\n\n\n\n\\(P(Z > 1) = 1 - P(Z<1)\\)\n1 - pnorm(1) \\(0.1586553\\)\n1 - pnorm(1, mean = 5, sd = 2)\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_11.html#rule",
    "href": "slides/lect_11.html#rule",
    "title": "Chapter 12: The normal probability model",
    "section": "Rule",
    "text": "Rule\n\nThis is true of all normal distributions, point of inflection, other things.\nWe will also need to learn to undo things. If we have a probability go backwards and find the z-score."
  },
  {
    "objectID": "slides/lect_11.html#undo",
    "href": "slides/lect_11.html#undo",
    "title": "Chapter 12: The normal probability model",
    "section": "Undo",
    "text": "Undo"
  },
  {
    "objectID": "slides/lect_11.html#plot---normal",
    "href": "slides/lect_11.html#plot---normal",
    "title": "Chapter 12: The normal probability model",
    "section": "Plot - normal",
    "text": "Plot - normal"
  },
  {
    "objectID": "slides/lect_11.html#plot---tale-of-2-tails",
    "href": "slides/lect_11.html#plot---tale-of-2-tails",
    "title": "Chapter 12: The normal probability model",
    "section": "Plot - tale of 2 tails",
    "text": "Plot - tale of 2 tails"
  },
  {
    "objectID": "slides/lect_11.html#tale-of-2-tails",
    "href": "slides/lect_11.html#tale-of-2-tails",
    "title": "Chapter 12: The normal probability model",
    "section": "Tale of 2 tails",
    "text": "Tale of 2 tails"
  },
  {
    "objectID": "slides/lect_11.html#fat-tails",
    "href": "slides/lect_11.html#fat-tails",
    "title": "Chapter 12: The normal probability model",
    "section": "Fat tails",
    "text": "Fat tails"
  },
  {
    "objectID": "slides/lect_11.html#thin-tails",
    "href": "slides/lect_11.html#thin-tails",
    "title": "Chapter 12: The normal probability model",
    "section": "Thin tails",
    "text": "Thin tails"
  },
  {
    "objectID": "slides/lect_11.html#bimodal",
    "href": "slides/lect_11.html#bimodal",
    "title": "Chapter 12: The normal probability model",
    "section": "Bimodal",
    "text": "Bimodal"
  },
  {
    "objectID": "slides/lect_11.html#qqplot-in-r",
    "href": "slides/lect_11.html#qqplot-in-r",
    "title": "Chapter 12: The normal probability model",
    "section": "QQPlot in R",
    "text": "QQPlot in R\n\nggplot(diamonds, aes(sample=price)) +\n  stat_qq() + # add the dots\n  stat_qq_line() # and the line"
  },
  {
    "objectID": "slides/lect_11.html#skewness",
    "href": "slides/lect_11.html#skewness",
    "title": "Chapter 12: The normal probability model",
    "section": "Skewness",
    "text": "Skewness\n\n\nfind the \\(z\\) scores for all data (\\(z_i = \\frac{x_i - \\bar{x}}{s}\\))\n\\[K_3 = \\frac{z_1^3 +z_2^3 + ... + z_n^3}{n}\\]\nIf \\(K_3 \\approx 0\\), then \\(x\\) is symmetric\nAs \\(K_3\\) gets larger than 0, more right-skewed\nAs \\(K_3\\) gets smaller than 0, more left-skewed"
  },
  {
    "objectID": "slides/lect_11.html#kurtosis",
    "href": "slides/lect_11.html#kurtosis",
    "title": "Chapter 12: The normal probability model",
    "section": "Kurtosis",
    "text": "Kurtosis\n\n\nfind the \\(z\\) scores for all data (\\(z_i = \\frac{x_i - \\bar{x}}{s}\\))\n\\[K_4 = \\frac{z_1^4 +z_2^4 + ... + z_n^4}{n} - 3\\]\nIf \\(K_4 \\approx 0\\), then \\(x\\) is approximately normal\nAs \\(K_4 < 0\\) flat uniform distribution without tails\nAs \\(K_4 > 0\\) many outliers"
  },
  {
    "objectID": "slides/lect_11.html#take-home",
    "href": "slides/lect_11.html#take-home",
    "title": "Chapter 12: The normal probability model",
    "section": "Take home",
    "text": "Take home\nIf you see departures from normality (large or small kurtosis, QQ plots that deviate from a straight line) PLOT the data and check.\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_07.html#using-proportions",
    "href": "slides/lect_07.html#using-proportions",
    "title": "Chapter 9: Random variables",
    "section": "Using proportions",
    "text": "Using proportions\n\n\n\n\\(x\\)\n\\(n\\)\n\\(P(X) = x\\)\n\n\n\n\n1.23\n3\n\n\n\n1.29\n5\n\n\n\n1.37\n4\n\n\n\n1.84\n1\n\n\n\n1.18\n6\n\n\n\n1.22\n2\n\n\n\n1.25\n4\n\n\n\nTotal\n25"
  },
  {
    "objectID": "slides/lect_07.html#mean-or-expected-value",
    "href": "slides/lect_07.html#mean-or-expected-value",
    "title": "Chapter 9: Random variables",
    "section": "Mean or expected value",
    "text": "Mean or expected value\nIf we know $P(X) = x$, then we can use this to find the mean or expected value of a random variable. The pdf includes information about both the total and the number of occurrences of \\(x\\), it does the computation for us.\n\\(\\mu = E(X)\\)\n\\(= x_1p(x_1) + x_2p(x_2) + … + x_np(x_n)\\)"
  },
  {
    "objectID": "slides/lect_07.html#price-increase-1",
    "href": "slides/lect_07.html#price-increase-1",
    "title": "Chapter 9: Random variables",
    "section": "Price increase",
    "text": "Price increase\n\n\n\n\\(x\\)\n\\(x + 5\\)\n\\(P(X) = x+5\\)\n\n\n\n\n1.23\n6.23\n0.12\n\n\n1.29\n6.29\n0.20\n\n\n1.37\n6.37\n0.16\n\n\n1.84\n6.84\n0.04\n\n\n1.18\n6.18\n0.24\n\n\n1.22\n6.22\n0.08\n\n\n1.25\n6.25\n0.16"
  },
  {
    "objectID": "slides/lect_07.html#price-increase-2",
    "href": "slides/lect_07.html#price-increase-2",
    "title": "Chapter 9: Random variables",
    "section": "Price increase",
    "text": "Price increase"
  },
  {
    "objectID": "slides/lect_07.html#stock-splits-1",
    "href": "slides/lect_07.html#stock-splits-1",
    "title": "Chapter 9: Random variables",
    "section": "Stock splits",
    "text": "Stock splits\n\n\n\n\\(x\\)\n\\(3x\\)\n\\(P(X) = x\\)\n\n\n\n\n1.23\n3.68\n0.12\n\n\n1.29\n3.87\n0.20\n\n\n1.37\n4.11\n0.16\n\n\n1.84\n5.52\n0.04\n\n\n1.18\n3.54\n0.24\n\n\n1.22\n3.66\n0.08\n\n\n1.25\n3.75\n0.16"
  },
  {
    "objectID": "slides/lect_07.html#stock-splits-2",
    "href": "slides/lect_07.html#stock-splits-2",
    "title": "Chapter 9: Random variables",
    "section": "Stock splits",
    "text": "Stock splits"
  },
  {
    "objectID": "slides/lect_13.html#sampling",
    "href": "slides/lect_13.html#sampling",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Sampling",
    "text": "Sampling\n\n\nSRS\nStratified sampling\nCluster sampling\nit would be nice to sample repeatedly to see how the mean values compare"
  },
  {
    "objectID": "slides/lect_13.html#benefits-of-averaging",
    "href": "slides/lect_13.html#benefits-of-averaging",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Benefits of averaging",
    "text": "Benefits of averaging\n\n\nreduces variation\nmore normal than the original distribution"
  },
  {
    "objectID": "slides/lect_13.html#normal-model",
    "href": "slides/lect_13.html#normal-model",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Normal model",
    "text": "Normal model\n\n\nFind kurtosis(\\(K_4\\))\nIf \\(n > 10 |K_4|\\), where \\(n\\) is the sample size, then a normal model adequately approximates the distribution of the sample mean \\(\\bar{X}\\).\nIf we know the data come from a normal distribution this is also true."
  },
  {
    "objectID": "slides/lect_13.html#standard-error",
    "href": "slides/lect_13.html#standard-error",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Standard error",
    "text": "Standard error\n\\[ SD(\\bar{X}) = SE(\\bar{X}) =\n\\frac{\\sigma}{\\sqrt{n}} \\]"
  },
  {
    "objectID": "slides/lect_13.html#sampling-distribution",
    "href": "slides/lect_13.html#sampling-distribution",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Sampling distribution",
    "text": "Sampling distribution\nIf \\(X \\sim N(\\mu_X, \\sigma_X^2)\\)\n\\[ \\bar{X} \\sim N(\\mu = \\mu_X, \\sigma^2 = \\frac{\\sigma_X^2}{n}) \\]"
  },
  {
    "objectID": "slides/lect_13.html#example",
    "href": "slides/lect_13.html#example",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Example",
    "text": "Example\n\n\nLet \\(Y \\sim N(\\mu = 5, \\sigma^2 = 16)\\), find the distribution of the mean of repeated samples of size 4.\n\n\\(\\bar{Y} \\sim N(\\mu = 5, \\sigma^2 = 4)\\)"
  },
  {
    "objectID": "slides/lect_13.html#control-limits",
    "href": "slides/lect_13.html#control-limits",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Control limits",
    "text": "Control limits\n\n\nif mean production is outside certain values, we may need to stop and recallibrate machinery\nthese values are called control limits\n\\(\\mu - L \\leq \\bar{X} \\leq \\mu + L\\)\n\\(\\mu - L\\) and \\(\\mu + L\\) are control limits"
  },
  {
    "objectID": "slides/lect_13.html#types-of-errors",
    "href": "slides/lect_13.html#types-of-errors",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Types of errors",
    "text": "Types of errors\n\n\nFalse positives - type 1 error\n\nact when you should not\nprobabiliy of occurence denoted \\(\\alpha\\)\n\nFalse negatives - type 2 error\n\ndon’t act when you should\nprobabiliy of occurence denoted \\(\\beta\\)"
  },
  {
    "objectID": "slides/lect_13.html#setting-control-limits---1",
    "href": "slides/lect_13.html#setting-control-limits---1",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Setting control limits - 1",
    "text": "Setting control limits - 1\nIf \\(\\bar{X} \\sim N(\\mu = 12, \\sigma^2 = 2.3)\\) how can we find the control limits?\n\n\nSet the control limits and find the \\(\\alpha\\) value\n\nWe want the control limits to be between 10 and 14\n\\(Pr(\\bar{X} < 10 \\textrm{ or } \\bar{X} > 14)\\)\n\\(\\begin{aligned}P(\\bar{X} < 10) &= P(\\frac{\\bar{X} - \\mu_\\bar{X}}{\\sigma_\\bar{X}} < \\frac{10-\\mu_\\bar{X}}{\\sigma_\\bar{X}}) \\\\ & = P(Z < \\frac{10-12}{\\sqrt{2.3}} = -1.318761)\\end{aligned}\\)\npnorm(-1.318761) \\(\\approx 0.09362451\\)\npnorm(10, mean = 12, sd = sqrt(2.3))"
  },
  {
    "objectID": "slides/lect_13.html#setting-control-limits---1-contd",
    "href": "slides/lect_13.html#setting-control-limits---1-contd",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Setting control limits - 1 cont’d",
    "text": "Setting control limits - 1 cont’d\nIf \\(\\bar{X} \\sim N(\\mu = 12, \\sigma^2 = 2.3)\\) how can we find the control limits?\n\n\nSet the control limits and find the \\(\\alpha\\) value\n\nWe want the control limits to be between 10 and 14\n\\(\\begin{aligned}P(\\bar{X} > 14) &= P(\\frac{\\bar{X} - \\mu_\\bar{X} }{\\sigma_\\bar{X}} > \\frac{14-\\mu_\\bar{X}}{\\sigma_\\bar{X}}) \\\\ & = P(Z > \\frac{14-12}{\\sqrt{2.3}} = 1.318761)\\end{aligned}\\)\n1 - pnorm(1.318761) \\(\\approx 0.09362451\\)\n1 - pnorm(14, mean = 12, sd = sqrt(2.3))\nthe \\(\\alpha\\) value is \\(19\\%\\) which is very high!"
  },
  {
    "objectID": "slides/lect_13.html#setting-control-limits---2",
    "href": "slides/lect_13.html#setting-control-limits---2",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Setting control limits - 2",
    "text": "Setting control limits - 2\n\n\nSet the \\(\\alpha\\) value and find the control limits\n\n\nWe want the \\(\\alpha\\) to be \\(0.025\\)\n\n\\(Pr(\\bar{X} < z_{0.0125} \\textrm{ or } \\bar{X} > z_{0.0125})\\)\nqnorm(0.0125) \\(\\approx -2.241403\\)\n\\(\\begin{aligned}-2.241403 =& \\frac{X - \\mu_\\bar{X}}{\\sigma_\\bar{X}}\\\\ & = \\frac{X - 12}{\\sqrt{2.3}} \\\\ &= -2.241403\\sqrt{2.3} +12 = 8.600744 \\end{aligned}\\)\nqnorm(0.0125, mean = 12, sd = sqrt(2.3))"
  },
  {
    "objectID": "slides/lect_13.html#setting-control-limits---2---contd",
    "href": "slides/lect_13.html#setting-control-limits---2---contd",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Setting control limits - 2 - cont’d",
    "text": "Setting control limits - 2 - cont’d\n\n\nSet the \\(\\alpha\\) value and find the control limits\n\n\nWe want the \\(\\alpha\\) to be \\(0.025\\)\n\n\\(Pr(\\bar{X} < z_{0.0125} \\textrm{ or } \\bar{X} > z_{0.0125})\\)\nqnorm(1- 0.0125) \\(\\approx 2.241403\\)\n\\(\\begin{aligned}2.241403 =& \\frac{X - \\mu_\\bar{X}}{\\sigma_\\bar{X}}\\\\ & = \\frac{X - 12}{\\sqrt{2.3}} \\\\ &= 2.241403\\sqrt{2.3} +12 = 15.39926 \\end{aligned}\\)\nqnorm(1-0.0125, mean = 12, sd = sqrt(2.3))"
  },
  {
    "objectID": "slides/lect_13.html#repeated-testing",
    "href": "slides/lect_13.html#repeated-testing",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Repeated testing",
    "text": "Repeated testing\nWe are not testing once, but multiple times. Assuming independence:\n\n\n\\(\\begin{aligned}P(\\textrm{within limits for 10 days}) =& P(\\textrm{within limits for day 1}) \\cdot P(\\textrm{within limits for day 2}) \\cdot \\dots \\cdot P(\\textrm{within limits for day 10})\\\\ &= 0.975^{10} \\approx 0.7763296 \\end{aligned}\\)\nThere is a \\(1-0.7763296 = 0.2236704\\) percent false positive rate\nManagement must decide if there is a false positive by checking for mechanical errors and inspecting equipment\nAdjust \\(\\alpha\\) value to address this"
  },
  {
    "objectID": "slides/lect_13.html#control-charts-for-variation",
    "href": "slides/lect_13.html#control-charts-for-variation",
    "title": "Chapter 14: Sampling variation and quality",
    "section": "Control charts for variation",
    "text": "Control charts for variation\nX-bar charts are slow to detect under or over filling\n\n\nS-Chart tracks the standard deviation from sample to sample\nR-Chart tracks the range from sample to sample\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_12.html#revision",
    "href": "slides/lect_12.html#revision",
    "title": "Chapter 13: Samples and surveys",
    "section": "Revision",
    "text": "Revision\n\nWe have not yet discussed the sampling process. Now is our chance!\nOne of the differences between statistics and machine learning - in ml not much thought of sampling."
  },
  {
    "objectID": "slides/lect_12.html#predictive-policing",
    "href": "slides/lect_12.html#predictive-policing",
    "title": "Chapter 13: Samples and surveys",
    "section": "Predictive policing",
    "text": "Predictive policing\n\n\nResearch question - Can police use crime data from disparate sources to anticipate and prevent future crime?\npopulation - all crime\nsample - arrests recorded in police database\nIs this a random sample?\narrests is a surrogate measurement because crime is hard to track"
  },
  {
    "objectID": "slides/lect_12.html#predictive-policing-1",
    "href": "slides/lect_12.html#predictive-policing-1",
    "title": "Chapter 13: Samples and surveys",
    "section": "Predictive policing",
    "text": "Predictive policing\n\n\nfor arrests to occur police must be present\nsome areas are over policed, so have more arrests\nthis algorithm sends police to those areas\nread more here\nuse census data to predict crime instead of arrests, we may do better"
  },
  {
    "objectID": "slides/lect_12.html#census",
    "href": "slides/lect_12.html#census",
    "title": "Chapter 13: Samples and surveys",
    "section": "Census",
    "text": "Census\n\n\nsample everyone in the population\nthis is often difficult because some individuals are hard to locate, and these people may have certain characterisitics that distinguish them from the rest of the population\nPopulations move so getting a perfect measure is hard.\nA census may be more complex than sampling"
  },
  {
    "objectID": "slides/lect_12.html#landon-vs-roosevelt",
    "href": "slides/lect_12.html#landon-vs-roosevelt",
    "title": "Chapter 13: Samples and surveys",
    "section": "Landon vs Roosevelt",
    "text": "Landon vs Roosevelt\n\n\nLiterary digest - correctly predicted presidential elections from 1916 - 1932 with mock ballots\n1936 election\n\n10 million ballots\nLandon win by landslide with 57%\n\n10 million names and addresses in 1936\npoor people were unlikely to have phones, so they over sampled the wealthy\nGallup predicted a Roosevelt win\nweighting can be used to correct biased samples"
  },
  {
    "objectID": "slides/lect_12.html#sampling-1",
    "href": "slides/lect_12.html#sampling-1",
    "title": "Chapter 13: Samples and surveys",
    "section": "Sampling",
    "text": "Sampling\n\n\ntasting is analogous to exploratory analysis\nstirring helps ensure that the taste is representative because it randomizes\nif we add ingredients and don’t stir we may get a biased sample\nif we generalize and decide that it needs more salt, that’s an inference"
  },
  {
    "objectID": "slides/lect_12.html#sampling-frame",
    "href": "slides/lect_12.html#sampling-frame",
    "title": "Chapter 13: Samples and surveys",
    "section": "Sampling frame",
    "text": "Sampling frame\n\n\nlists every member of the population of interest\ncan be complex to identify\nsample from registered voters, but really want people who will vote\nhypothetical populations are more complex\na brewery must sample hops across farmers, and different geographic regions prior to formalizing brewing"
  },
  {
    "objectID": "slides/lect_12.html#simple-random-sample",
    "href": "slides/lect_12.html#simple-random-sample",
    "title": "Chapter 13: Samples and surveys",
    "section": "Simple random sample",
    "text": "Simple random sample"
  },
  {
    "objectID": "slides/lect_12.html#stratified-sampling",
    "href": "slides/lect_12.html#stratified-sampling",
    "title": "Chapter 13: Samples and surveys",
    "section": "Stratified sampling",
    "text": "Stratified sampling"
  },
  {
    "objectID": "slides/lect_12.html#cluster-sample",
    "href": "slides/lect_12.html#cluster-sample",
    "title": "Chapter 13: Samples and surveys",
    "section": "Cluster sample",
    "text": "Cluster sample"
  },
  {
    "objectID": "slides/lect_12.html#sampling-2",
    "href": "slides/lect_12.html#sampling-2",
    "title": "Chapter 13: Samples and surveys",
    "section": "Sampling",
    "text": "Sampling\n\n\nschools or nursing homes for cluster sampling\nstrata imply some similarity, for example high income or low income people\n\n\n\n\nRandomly select cases from the population, where there is no implied connection between the points that are selected.\nStrata are made up of similar observations. We take a simple random sample from each stratum.\nClusters are usually not made up of homogeneous observations. We take a simple random sample of clusters, and then sample all observations in that cluster. Usually preferred for economical reasons."
  },
  {
    "objectID": "slides/lect_12.html#sampling-in-r",
    "href": "slides/lect_12.html#sampling-in-r",
    "title": "Chapter 13: Samples and surveys",
    "section": "Sampling in R",
    "text": "Sampling in R\n\n# SRS\ndata %>% \n  slice_sample(n = sample_size)\n\n# Stratified sampling\ndata %>% \n  group_by(strata) %>% \n  slice_sample(n = size_from_each_strata)\n\n# Cluster sampling\nrandom_cluster <- slice_sample(data$cluster, \n                               n = no_of_clusters)"
  },
  {
    "objectID": "slides/lect_12.html#not-great-sampling-methods",
    "href": "slides/lect_12.html#not-great-sampling-methods",
    "title": "Chapter 13: Samples and surveys",
    "section": "Not great sampling methods",
    "text": "Not great sampling methods\n\nmeta and other tech companies often use NZ as a sampling ground to see how a new product works prior to releasing it to the USA.\nmy cousin when she started her allergen-free cakes b/c her son couldn’t eat anything\n\n\n\nvoluntary response\nconvenience sampling - asking friends or families feedback about your product"
  },
  {
    "objectID": "slides/lect_16.html#different-types-of-comparisons",
    "href": "slides/lect_16.html#different-types-of-comparisons",
    "title": "Chapter 17: Comparison",
    "section": "Different types of comparisons",
    "text": "Different types of comparisons\nFrom our last lecture, there are two courses that participants can take to improve their ESP abilities. One series of courses focuses on somatic training of the participant and the other on eye contact between the sender and receiver. For the purposes of this exercise, we let S be the event that a person took the first somatic course, and I be the event that a person took the first eye training course. This lesson will teach us how to assess these two courses. We will answer these questions:\n\n\nDoes a higher proportion of people sign up for subsequent eye contact or somatic courses?\nAre the earning for the somatic group higher than those of the eye contact group?"
  },
  {
    "objectID": "slides/lect_16.html#data---contd",
    "href": "slides/lect_16.html#data---contd",
    "title": "Chapter 17: Comparison",
    "section": "Data - cont’d",
    "text": "Data - cont’d\nThere are a few ways that we can get data to explore these hypotheses:\n\n\nExperiment: random sample, assigns treatment, compares between treatments.\nObtain random samples from two populations.\nCompare two sets of observations: can be problematic"
  },
  {
    "objectID": "slides/lect_16.html#confounding",
    "href": "slides/lect_16.html#confounding",
    "title": "Chapter 17: Comparison",
    "section": "Confounding",
    "text": "Confounding\nWhen levels of one variable are associated with levels of another the variables are said to be confounded.\nIn our example, perhaps we run a course Sedona, AZ where belief in ESP is high and people are likely to take the whole course. If the other was run in Phoenix, AZ this would not be the case. The belief in ESP in the location is confounded with taking subsequent courses."
  },
  {
    "objectID": "slides/lect_16.html#example-1",
    "href": "slides/lect_16.html#example-1",
    "title": "Chapter 17: Comparison",
    "section": "Example 1",
    "text": "Example 1\nWhich of the following appear safe from confounding and which appear to be contaminated?\n\nA comparison of two promotional displays using average daily sales in one store with one type of display and another store with a different type.\nA comparison of two promotional diplays using average daily sales in one store with one type of display on Monday and the other display on Friday.\nA comparison of two landscaping offers sent at random to potential customers in the same zip code."
  },
  {
    "objectID": "slides/lect_16.html#example-1---solns",
    "href": "slides/lect_16.html#example-1---solns",
    "title": "Chapter 17: Comparison",
    "section": "Example 1 - solns",
    "text": "Example 1 - solns\n\nConfounded by differences between the store, such as location or sales volume\nConfounded by differences in shopping patterns during the week.\nFree of confounding, though may not generalize to other zip codes"
  },
  {
    "objectID": "slides/lect_16.html#assumptions",
    "href": "slides/lect_16.html#assumptions",
    "title": "Chapter 17: Comparison",
    "section": "Assumptions",
    "text": "Assumptions\n\nNo obvious lurking variable or confounders\nSRS condition, or independent random samples from two populations\nWe need to check \\(\\begin{eqnarray*} n_1\\cdot \\hat{p}_1 \\geq 10 \\\\ n_1\\cdot(1-\\hat{p}_1) \\geq 10\\\\ n_2\\cdot \\hat{p}_2 \\geq 10\\\\ n_2\\cdot(1-\\hat{p}_2) \\geq 10 \\end{eqnarray*}\\)"
  },
  {
    "objectID": "slides/lect_16.html#hypothesis-test-for-a-difference-in-proportions",
    "href": "slides/lect_16.html#hypothesis-test-for-a-difference-in-proportions",
    "title": "Chapter 17: Comparison",
    "section": "Hypothesis test for a difference in proportions",
    "text": "Hypothesis test for a difference in proportions\n\\[ z = \\frac{\\hat{p}_1 - \\hat{p}_2 - D_0}{se(\\hat{p}_1 - \\hat{p}_2)}\\]"
  },
  {
    "objectID": "slides/lect_16.html#example-2",
    "href": "slides/lect_16.html#example-2",
    "title": "Chapter 17: Comparison",
    "section": "Example 2",
    "text": "Example 2\nIn the ESP example, spiritual groups decided to randomly assign members to either the somatic (\\(n_s = 809\\)) or eye contact group (\\(n_i = 646\\)). From those in the somatic group \\(280\\) re-enrolled, subsequent eye contact groups had \\(197\\). Perform a two sample \\(z\\)-test for proportions to determine if the enrollment in the somatic course was 2% more, on average, than that in the eye contact course."
  },
  {
    "objectID": "slides/lect_16.html#steps-for-a-hypothesis-test",
    "href": "slides/lect_16.html#steps-for-a-hypothesis-test",
    "title": "Chapter 17: Comparison",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState hypotheses\nDetermine the level of significance\nCheck conditions\nCalculate test statistic\nCompute p-value\nGeneric conclusion\nInterpret in context"
  },
  {
    "objectID": "slides/lect_16.html#example-2---solns",
    "href": "slides/lect_16.html#example-2---solns",
    "title": "Chapter 17: Comparison",
    "section": "Example 2 - solns",
    "text": "Example 2 - solns\n\n\n\\(H_0: p_s - p_i \\leq 0.02\\) and \\(H_A: p_s - p_i > 0.02\\)\n\\(\\alpha = 0.05\\)\nYes, 280/809*809 and (1-280/809)*809 both > 10 Yes, 197/646*646 and (1-197/646)*646 both > 10\n\\(\\hat{p_i} = \\frac{x_i}{n_i} = \\frac{197}{646} = 0.305\\) \\(\\hat{p_s} = \\frac{x_s}{n_s} = \\frac{280}{809} = 0.346\\)"
  },
  {
    "objectID": "slides/lect_16.html#example-2---solns-1",
    "href": "slides/lect_16.html#example-2---solns-1",
    "title": "Chapter 17: Comparison",
    "section": "Example 2 - solns",
    "text": "Example 2 - solns\n\n\n\\(\\begin{aligned} se(\\hat{p}_s - \\hat{p}_i) &= \\sqrt{\\frac{\\hat{p}_s(1-\\hat{p}_s)}{n_s}+\\frac{\\hat{p}_i(1-\\hat{p}_i)}{n_i}} \\\\ &= \\sqrt{\\frac{0.305(1-0.305)}{646}+\\frac{0.346(1-0.346)}{809}} \\\\ &= \\sqrt{0.0003281 + 0.0002797} \\approx 0.02465 \\end{aligned}\\) \\(\\begin{aligned} z_0 &= \\frac{\\hat{p_s} - \\hat{p_i} - D_0} {se(\\hat{p_s} - \\hat{p_i})} \\\\ &= \\frac{0.346 - 0.305 - 0.02} {0.02465} \\\\ &\\approx 0.851927 \\end{aligned}\\)\n\n1 - pnorm(0.851927) or \\(\\approx 0.197\\)\n\nSince \\(0.197 > \\alpha = 0.05\\) this is not significant.\nWe fail to reject \\(H_0\\). The reenrollment in the somatic course is not significantly more than the reenrollment in the eye contact course."
  },
  {
    "objectID": "slides/lect_16.html#math---two-sample-ci-for-props",
    "href": "slides/lect_16.html#math---two-sample-ci-for-props",
    "title": "Chapter 17: Comparison",
    "section": "Math - two sample CI for props",
    "text": "Math - two sample CI for props\n\\[ \\hat{p}_1 - \\hat{p}_2 - z_{\\alpha/2} se(\\hat{p}_1 - \\hat{p}_2) \\text{  to  }\\\\ \\hat{p}_1 - \\hat{p}_2 + z_{\\alpha/2} se(\\hat{p}_1 - \\hat{p}_2)\\]"
  },
  {
    "objectID": "slides/lect_16.html#assumptions-1",
    "href": "slides/lect_16.html#assumptions-1",
    "title": "Chapter 17: Comparison",
    "section": "Assumptions",
    "text": "Assumptions\n\nNo obvious lurking variables or confounders\nSRS condition\nSample size condition"
  },
  {
    "objectID": "slides/lect_16.html#example-3",
    "href": "slides/lect_16.html#example-3",
    "title": "Chapter 17: Comparison",
    "section": "Example 3",
    "text": "Example 3\nIn the ESP example, spiritual groups decided to randomly assign members to either the somatic (\\(n_s = 809\\)) or eye contact group (\\(n_i = 646\\)). From those in the somatic contact group \\(280\\) re-enrolled, subsequent eye contact groups had \\(197\\). Find the 95% confidence interval for the difference between the proportions who take subsequent courses on the somatic and eye contact group."
  },
  {
    "objectID": "slides/lect_16.html#example-3---solns",
    "href": "slides/lect_16.html#example-3---solns",
    "title": "Chapter 17: Comparison",
    "section": "Example 3 - solns",
    "text": "Example 3 - solns\n\n\n\\(\\begin{aligned} \\text{lower bound} &= \\hat{p}_s - \\hat{p}_i - z_{\\alpha/2} se(\\hat{p}_s - \\hat{p}_i) \\\\ &= 0.346 - 0.305 - 1.96 \\cdot 0.02465 \\\\ &= 0.041 - 0.0483 \\approx -0.0073 \\end{aligned}\\)\n\\(\\begin{aligned} \\text{upper bound} &= \\hat{p}_s - \\hat{p}_i + z_{\\alpha/2} se(\\hat{p}_s - \\hat{p}_i) \\\\ &= 0.346 - 0.305 + 1.96 \\cdot 0.02465 \\\\ &= 0.041 + 0.0483 \\approx 0.0893 \\end{aligned}\\)"
  },
  {
    "objectID": "slides/lect_16.html#interpretation",
    "href": "slides/lect_16.html#interpretation",
    "title": "Chapter 17: Comparison",
    "section": "Interpretation",
    "text": "Interpretation\nSince \\(0 \\text{ is in } [-0.0073, 0.0893]\\) the difference is not statistically signficant at the \\(95\\%\\) significance level. It is possible that the reenrollment rates for eye contact and the somatic course come from populations with the same proportion. We do not know which is higher, either could be.\nIf \\(0\\) is not in the \\(95\\%\\) confidence interval, then the difference is significant and we can be \\(95\\%\\) confident that the difference is between the lower and upper bounds. Any value in the region could plausibly be the difference in proportions between the two populations."
  },
  {
    "objectID": "slides/lect_16.html#assumptions-2",
    "href": "slides/lect_16.html#assumptions-2",
    "title": "Chapter 17: Comparison",
    "section": "Assumptions",
    "text": "Assumptions\n\nNo lurking variables\nSRS condition\nSimilar variances\nEach sample must exceed \\(10|K_4|\\)"
  },
  {
    "objectID": "slides/lect_16.html#in-r",
    "href": "slides/lect_16.html#in-r",
    "title": "Chapter 17: Comparison",
    "section": "In R",
    "text": "In R\nThis computation is long and complicated, so it’s best done in R: t.test()\nSince we only have summary data for the ESP example, we’ll show with the diamonds dataset. In this situation, we’ll ask if there is a relationship between carat (weight of the diamond) and color (D is best and J is worst). Which color has on average the largest diamonds?\n\\[ H_0: \\mu_D - \\mu_j \\leq D_0\\]"
  },
  {
    "objectID": "slides/lect_16.html#in-r-1",
    "href": "slides/lect_16.html#in-r-1",
    "title": "Chapter 17: Comparison",
    "section": "In R",
    "text": "In R\n\n## install packages\nlibrary(tidyverse)\n\nd.color <- diamonds %>% \n  filter(color == \"D\") %>% \n  select(carat)\n  \nj.color <- diamonds %>% \n  filter(color == \"J\") %>% \n  select(carat)\n\n## 2 - sided test\n## Alternative hypothesis: x != y\nt.test(x = d.color, y = j.color, alternative = \"two.sided\")\n\n## Alternative hypothesis: x < y by 0.1\nt.test(x = d.color, y = j.color, alternative  = \"less\", mu = .1)"
  },
  {
    "objectID": "slides/lect_16.html#in-r-2",
    "href": "slides/lect_16.html#in-r-2",
    "title": "Chapter 17: Comparison",
    "section": "In R",
    "text": "In R\n\n\n\n    Welch Two Sample t-test\n\ndata:  d.color and j.color\nt = -41.811, df = 3683.7, p-value < 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.5279915 -0.4806923\nsample estimates:\nmean of x mean of y \n0.6577948 1.1621368 \n\n\n\n    Welch Two Sample t-test\n\ndata:  d.color and j.color\nt = -50.101, df = 3683.7, p-value < 2.2e-16\nalternative hypothesis: true difference in means is less than 0.1\n95 percent confidence interval:\n       -Inf -0.4844961\nsample estimates:\nmean of x mean of y \n0.6577948 1.1621368"
  },
  {
    "objectID": "slides/lect_16.html#interpretation-1",
    "href": "slides/lect_16.html#interpretation-1",
    "title": "Chapter 17: Comparison",
    "section": "Interpretation",
    "text": "Interpretation\nIf the p-value is less than \\(\\alpha\\) there is evidence against \\(H_0\\) and we can reject \\(H_0\\) in favor of the alternative.\n“If the p-value is low then the null must go.”\n2 - sided\nThere is extremely strong evidence that the mean carat for diamonds with the best color (D) is not the same as that for diamonds with the worst color (J).\nalternative = “less”\nThere is extremely strong evidence that the mean carat for diamonds with the best color (D) is smaller by at least 0.1 then diamonds with the worst color (J).\nBut what is the magnitude of the difference?"
  },
  {
    "objectID": "slides/lect_16.html#in-r-3",
    "href": "slides/lect_16.html#in-r-3",
    "title": "Chapter 17: Comparison",
    "section": "In R",
    "text": "In R\n\nt.test(x = d.color, y = j.color, conf.level = 0.95)$conf.int\n\n[1] -0.5279915 -0.4806923\nattr(,\"conf.level\")\n[1] 0.95"
  },
  {
    "objectID": "slides/lect_16.html#another-example",
    "href": "slides/lect_16.html#another-example",
    "title": "Chapter 17: Comparison",
    "section": "Another example",
    "text": "Another example\nCertain people refused to get vacinated from COVID-19. To compare COVID infection rates it’s best to pair people who are vaccinated and not vaccinated but who also have similar education levels, incomes, and risk of infection. This hapenned last year in a UK government report."
  },
  {
    "objectID": "slides/lect_16.html#math",
    "href": "slides/lect_16.html#math",
    "title": "Chapter 17: Comparison",
    "section": "Math",
    "text": "Math\nGiven the paired data we find the differences (\\(d_i = x_i – y_i\\))\nThe \\(100(1 - \\alpha)%\\) confidence paired t- interval is\n\\[\\bar{d} \\pm  t_{\\alpha/2, n-1} \\frac{s_d}{\\sqrt{n}}\\]\nChecklist: No obvious lurking variables. SRS condition. Sample size condition."
  },
  {
    "objectID": "slides/lect_16.html#in-r-4",
    "href": "slides/lect_16.html#in-r-4",
    "title": "Chapter 17: Comparison",
    "section": "In R",
    "text": "In R\n\n# Weight of mice before treatment\nbefore <-c(200.1, 190.9, 192.7, 213, 241.4, 196.9, 172.2, 185.5, 205.2, 193.7)\n# Weight of mice after treatment\nafter <-c(392.9, 393.2, 345.1, 393, 434, 427.9, 422, 383.9, 392.3, 352.2)\n\n# A tibble\nmice <- tibble(\n  group = rep(c(\"before\", \"after\"), each = 10),\n  weight = c(before, after)\n  )\n\nt.test(weight ~ group, data = mice, paired = TRUE)"
  },
  {
    "objectID": "slides/lect_16.html#in-r-5",
    "href": "slides/lect_16.html#in-r-5",
    "title": "Chapter 17: Comparison",
    "section": "In R",
    "text": "In R\n\n\n\n    Paired t-test\n\ndata:  weight by group\nt = 20.883, df = 9, p-value = 6.2e-09\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 173.4219 215.5581\nsample estimates:\nmean difference \n         194.49"
  },
  {
    "objectID": "slides/lect_16.html#plot",
    "href": "slides/lect_16.html#plot",
    "title": "Chapter 17: Comparison",
    "section": "Plot",
    "text": "Plot\n\nggplot(data = mice) +\n  geom_boxplot(aes(x = group, y = weight))"
  },
  {
    "objectID": "slides/lect_16.html#interpretation-2",
    "href": "slides/lect_16.html#interpretation-2",
    "title": "Chapter 17: Comparison",
    "section": "Interpretation",
    "text": "Interpretation\nThere is very strong evidence that the underlying population means of the mice before and after treatment are not the same. On average, the mice are much heavier after treatment.\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_17.html#revision",
    "href": "slides/lect_17.html#revision",
    "title": "Chapter 18: Inference for counts",
    "section": "Revision",
    "text": "Revision\nWe have discussed this before and now we will formalize this work. Like walking up a lighthouse."
  },
  {
    "objectID": "slides/lect_17.html#test-of-independence",
    "href": "slides/lect_17.html#test-of-independence",
    "title": "Chapter 18: Inference for counts",
    "section": "Test of independence",
    "text": "Test of independence\n\\[H_0: \\text{Qualitative variable 1 and Qualitative variable 2 are independent}\\]\n\\[H_A: \\text{Qualitative variable 1 and Qualitative variable 2 are not independent}\\]"
  },
  {
    "objectID": "slides/lect_17.html#example-1",
    "href": "slides/lect_17.html#example-1",
    "title": "Chapter 18: Inference for counts",
    "section": "Example 1",
    "text": "Example 1\nA manufacturing firm is considering a shift from a 5-day workweek (8 hours per day) to a 4-day workweek (10 hours per day). Samples of the preferences of 188 employees in two divisions produced the following contingency table:\nObserved counts\n\n\n\n\n\nDivisions\n\n\n\n\n\n\n\n\nClerical\nProduction\nTotal\n\n\nPreferences\n5-day\n17\n46\n63\n\n\n\n4-day\n28\n38\n66\n\n\n\nTotal\n45\n84\n129\n\n\n\na. What would it mean if the preference of employees is independent of division?\nb. State \\(H_0\\) for the \\(\\chi^2\\) test of independence in terms of the parameters of two segments of the population of employees."
  },
  {
    "objectID": "slides/lect_17.html#example-1---solns",
    "href": "slides/lect_17.html#example-1---solns",
    "title": "Chapter 18: Inference for counts",
    "section": "Example 1 - solns",
    "text": "Example 1 - solns\n\nIndependence means that all the percent of people who prefer a 5-day work week is the same in all divisions. Lack of independence implies different percentages across divisions\n\\(H_0: p_{clerical} = p_{production}\\) \\(H_A: \\text{at least one of these differs}\\)"
  },
  {
    "objectID": "slides/lect_17.html#calculating-chi2",
    "href": "slides/lect_17.html#calculating-chi2",
    "title": "Chapter 18: Inference for counts",
    "section": "Calculating \\(\\chi^2\\)",
    "text": "Calculating \\(\\chi^2\\)\nIf one variable is independent of the other, then the variable should have the same proportion in each level as the totals have in each level.\nExpected counts\n\n\n\n\n\n\n\n\n\n\n\n\nDivisions\n\n\n\n\n\n\n\n\nClerical\nProduction\nTotal\n\n\nPreferences\n5-day\n\\(45/129\\cdot63 \\approx 22\\)\n\\(84/129\\cdot63 \\approx 41\\)\n63\n\n\n\n4-day\n\\(45/129\\cdot66 \\approx 23\\)\n\\(84/129\\cdot66 \\approx 43\\)\n66\n\n\n\nTotal\n45\n84\n129"
  },
  {
    "objectID": "slides/lect_17.html#calculating-chi2-1",
    "href": "slides/lect_17.html#calculating-chi2-1",
    "title": "Chapter 18: Inference for counts",
    "section": "Calculating \\(\\chi^2\\)",
    "text": "Calculating \\(\\chi^2\\)\n\\[ \\chi^2 = sum\\frac{(observed - expected)^2}{expected}\\]\nWe want to know how much this varies from the expected that is why the expected is the denominator."
  },
  {
    "objectID": "slides/lect_17.html#example-2",
    "href": "slides/lect_17.html#example-2",
    "title": "Chapter 18: Inference for counts",
    "section": "Example 2",
    "text": "Example 2\nFind the expected counts for the following observed variables\n\n\n\n\n \n  \n    gender \n    happy \n    meh \n    sad \n  \n \n\n  \n    female \n    100 \n    30 \n    110 \n  \n  \n    male \n    70 \n    32 \n    120"
  },
  {
    "objectID": "slides/lect_17.html#example-2---solns",
    "href": "slides/lect_17.html#example-2---solns",
    "title": "Chapter 18: Inference for counts",
    "section": "Example 2 - solns",
    "text": "Example 2 - solns\n\n\n\n\n \n  \n    happy \n    meh \n    sad \n  \n \n\n  \n    88.31169 \n    32.20779 \n    119.4805 \n  \n  \n    81.68831 \n    29.79221 \n    110.5195"
  },
  {
    "objectID": "slides/lect_17.html#plot",
    "href": "slides/lect_17.html#plot",
    "title": "Chapter 18: Inference for counts",
    "section": "Plot",
    "text": "Plot\n\n\n\ngender <- c(rep(\"male\", 222), \n            rep(\"female\", 240))\nmood <- c(rep(\"happy\", 70), rep(\"meh\",32),\n          rep(\"sad\", 120), rep(\"happy\", 100),\n          rep(\"meh\", 30), rep(\"sad\", 110))\nd <- tibble(gender, mood)\n \n## draw the plot\nggplot(data = d) +\n  geom_bar(aes(x = mood, fill = gender),\n           position = \"fill\")"
  },
  {
    "objectID": "slides/lect_17.html#reading-plots",
    "href": "slides/lect_17.html#reading-plots",
    "title": "Chapter 18: Inference for counts",
    "section": "Reading plots",
    "text": "Reading plots\nIf the color change in the bars are approximately at the same height in every level of the variable on the \\(x\\) axis, this is evidence against rejecting \\(H_0\\). We might be more inclined to think that \\(H_0\\) is true."
  },
  {
    "objectID": "slides/lect_17.html#assumptions",
    "href": "slides/lect_17.html#assumptions",
    "title": "Chapter 18: Inference for counts",
    "section": "Assumptions",
    "text": "Assumptions\n\nNo lurking variables\nData is a random sample from the population\nCategories must be mutually exclusive\nEach cell count must be at least 5 or 10 (more here)"
  },
  {
    "objectID": "slides/lect_17.html#degrees-of-freedom",
    "href": "slides/lect_17.html#degrees-of-freedom",
    "title": "Chapter 18: Inference for counts",
    "section": "degrees of freedom",
    "text": "degrees of freedom\n\\[df \\text{ for a } \\chi^2 \\text{ test of independence} = (r-1)(c-1)\\]\nwhere \\(r= \\text{number of rows}\\) and \\(c= \\text{number of columns}\\)\nAssumptions:\n\nEach cell count ideally 10, or 5 if the test has 4 or more degrees of freedom."
  },
  {
    "objectID": "slides/lect_17.html#in-r",
    "href": "slides/lect_17.html#in-r",
    "title": "Chapter 18: Inference for counts",
    "section": "In R",
    "text": "In R\n\n\nFind the totals\nCompute the expected counts\nCalculate \\(\\chi^2 = sum\\frac{(observed - expected)^2}{expected}\\)\nFind the df \\((r-1)(c-1)\\)\nSolve for the p-value 1 - pchisq(chi-square, df)"
  },
  {
    "objectID": "slides/lect_17.html#example-3",
    "href": "slides/lect_17.html#example-3",
    "title": "Chapter 18: Inference for counts",
    "section": "Example 3",
    "text": "Example 3\nIn example 2, perform a hypothesis test and find the \\(\\chi^2\\) value and the p-value. Are gender and mood independent?"
  },
  {
    "objectID": "slides/lect_17.html#steps-for-a-hypothesis-test",
    "href": "slides/lect_17.html#steps-for-a-hypothesis-test",
    "title": "Chapter 18: Inference for counts",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState hypotheses\nDetermine the level of significance\nCheck conditions\nCalculate test statistic\nCompute p-value\nGeneric conclusion\nInterpret in context"
  },
  {
    "objectID": "slides/lect_17.html#example-3---solns",
    "href": "slides/lect_17.html#example-3---solns",
    "title": "Chapter 18: Inference for counts",
    "section": "Example 3 - solns",
    "text": "Example 3 - solns\n\n\n\\(H_0: p_h = p_m = p_s\\) and \\(H_A: \\text{at least one differs}\\)\n\\(\\alpha = 0.05\\)\nYes.\n\\(\\begin{aligned} \\chi^2 &= sum\\frac{(observed - expected)^2}{expected} \\\\ &= \\frac{(100-88.3)^2}{88.3} + \\frac{(70-81.7)^2}{81.7} + ... + \\frac{(120-119.5)^2}{119.5}\\\\ &\\approx 5.0999\\end{aligned}\\) \\(df = (3-1)\\cdot(2-1)\\)"
  },
  {
    "objectID": "slides/lect_17.html#example-3---solns-1",
    "href": "slides/lect_17.html#example-3---solns-1",
    "title": "Chapter 18: Inference for counts",
    "section": "Example 3 - solns",
    "text": "Example 3 - solns\n\n\n1 - pchisq(5.099, df = 2)\\(\\approx 0.078\\)\nWe fail to reject \\(H_0\\)\nWe do not have evidence that gender and mood are associated, the data suggests they are independent."
  },
  {
    "objectID": "slides/lect_17.html#example-3---solns-2",
    "href": "slides/lect_17.html#example-3---solns-2",
    "title": "Chapter 18: Inference for counts",
    "section": "Example 3 - solns",
    "text": "Example 3 - solns\n\nd %>% \n  count(mood, gender) %>% \n  pivot_wider(names_from = mood, values_from = n) %>% \n  select(-gender) %>% \n  chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  .\nX-squared = 5.0999, df = 2, p-value = 0.07809"
  },
  {
    "objectID": "slides/lect_17.html#test-for-goodness-of-fit",
    "href": "slides/lect_17.html#test-for-goodness-of-fit",
    "title": "Chapter 18: Inference for counts",
    "section": "Test for goodness of fit",
    "text": "Test for goodness of fit\nWhen an outcome is either Binomial or Poisson one way to check that predictions are correct is to perform a \\(\\chi^2\\) test on the actual and predicted.\n\n\nA small p-value to indicates that these values are not independent."
  },
  {
    "objectID": "slides/lect_15.html#does-esp-exist-1",
    "href": "slides/lect_15.html#does-esp-exist-1",
    "title": "Chapter 16: Statistical tests",
    "section": "Does ESP exist?",
    "text": "Does ESP exist?\nSince there are 5 cards, it would be possible to guess the correct card at random \\(p=1/5\\) times, or 20% of the time.\nA person with ESP should be able to guess the correct card more often than 20%. But how much more often do they need to get it right for us to believe that ESP exists?"
  },
  {
    "objectID": "slides/lect_15.html#statistical-test",
    "href": "slides/lect_15.html#statistical-test",
    "title": "Chapter 16: Statistical tests",
    "section": "Statistical test",
    "text": "Statistical test\nOne way to determine something like this is to use a statistical test. A statistical test is a procedure to determine if the results from the sample are convincing enough to allow us to conclude something about the population."
  },
  {
    "objectID": "slides/lect_15.html#hypotheses",
    "href": "slides/lect_15.html#hypotheses",
    "title": "Chapter 16: Statistical tests",
    "section": "Hypotheses",
    "text": "Hypotheses\nWhen we perform a statistical test, we set out our hypotheses before we begin. There are two hypotheses,\nnull hypothesis \\(H_0\\), a statement about there being no effect, or no difference.\nalternative hypothesis \\(H_A\\), the thing that we secretly hope will turn out to be true."
  },
  {
    "objectID": "slides/lect_15.html#esp-hypotheses",
    "href": "slides/lect_15.html#esp-hypotheses",
    "title": "Chapter 16: Statistical tests",
    "section": "ESP hypotheses",
    "text": "ESP hypotheses\nThinking about the ESP experiment, we could use words to state our hypotheses\n\\(\\begin{eqnarray*} &H_0:& \\text{ ESP does not exist} \\\\ &H_A:& \\text{ESP exists} \\end{eqnarray*}\\)\nWe could also write the hypotheses in terms of parameters,\n\\(\\begin{eqnarray*} H_0: p \\leq 1/5 \\\\ H_A: p > 1/5 \\end{eqnarray*}\\)"
  },
  {
    "objectID": "slides/lect_15.html#hypotheses-1",
    "href": "slides/lect_15.html#hypotheses-1",
    "title": "Chapter 16: Statistical tests",
    "section": "Hypotheses",
    "text": "Hypotheses\n\n\nHypotheses are always written about the population parameter (\\(\\mu\\), \\(p\\), \\(\\mu_1-\\mu_2\\), \\(p_1-p_2\\)), never about the sample statistics (\\(\\bar{x}\\), \\(\\hat{p}\\), \\(\\bar{x}_1-\\bar{x}_2\\), \\(\\hat{p}_1-\\hat{p}_2\\)).\nThe null hypothesis is the boring thing that we’re trying to gather evidence against\nThe alternative hypothesis is the exciting thing that would make headlines"
  },
  {
    "objectID": "slides/lect_15.html#one-and-two-sided-hypotheses",
    "href": "slides/lect_15.html#one-and-two-sided-hypotheses",
    "title": "Chapter 16: Statistical tests",
    "section": "One and two sided hypotheses",
    "text": "One and two sided hypotheses\n\n\n\\(H_A\\) has a \\(>\\) sign: upper tail, or “one-sided”\n\\(H_A\\) has a \\(<\\) sign: lower tail, or “one-sided”\n\\(H_A\\) has a \\(\\neq\\) sign: both sides, or “two-sided”"
  },
  {
    "objectID": "slides/lect_15.html#example-1",
    "href": "slides/lect_15.html#example-1",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 1",
    "text": "Example 1\nWhat are the null and alternate hypothesis for these decisions?\n\n\nA person interviews for a job opening. The company has to decide whether to hire the person\nAn inventor proposes a new way to wrap packages that they say will speed up the manufacturing process. Should they adopt the new method?\nA sales representative submits receipts from a recent business trip. Staff must determine whether the claims are legitimate."
  },
  {
    "objectID": "slides/lect_15.html#example-1-solns",
    "href": "slides/lect_15.html#example-1-solns",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 1 solns",
    "text": "Example 1 solns\n\n\n$H_0 = $ Person is not hired\n$H_0 = $ Retain the current method\n$H_0 = $ Treat claims as legitimate. The employee is innocent until evidence to the contrary is found."
  },
  {
    "objectID": "slides/lect_15.html#past-tests",
    "href": "slides/lect_15.html#past-tests",
    "title": "Chapter 16: Statistical tests",
    "section": "Past tests",
    "text": "Past tests\n\n\nVisual assocation tests\nqqplots\n\\(\\chi^2\\) tests"
  },
  {
    "objectID": "slides/lect_15.html#example-2",
    "href": "slides/lect_15.html#example-2",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 2",
    "text": "Example 2\nA snack-food chain runs a promotion in which shoppers are told that 1 in 4 kids’ meals includes a prize. A father buys two kids’ meals, and neither has a prize. He concludes that because neither has a prize, the chain is being deceptive.\n\nWhat is the null and alternative hypothesis?\nDescribe a Type I error?\nDescribe a Type II error?\nWhat is the probability that the father has made a Type I error?"
  },
  {
    "objectID": "slides/lect_15.html#example-2---solns",
    "href": "slides/lect_15.html#example-2---solns",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 2 - solns",
    "text": "Example 2 - solns\n\n\\(H_0\\) = chain is being honest; \\(H_A\\) = chain is not being honest\nFalsely accusing the chain of being deceptive\nFailting to realize that the chain is being deceptive\nFather rejects if both are missing a prize. \\(P(neither has a prize) = (1 - 1/4)^2 \\approx 0.56\\)"
  },
  {
    "objectID": "slides/lect_15.html#test-statistic",
    "href": "slides/lect_15.html#test-statistic",
    "title": "Chapter 16: Statistical tests",
    "section": "Test statistic",
    "text": "Test statistic\nIn the previous example, we used probability to determine how likely it is to get two meals neither of which contain a prize. This process involves computing a test statistic (\\(0.56\\))."
  },
  {
    "objectID": "slides/lect_15.html#testing-a-proportion---contd",
    "href": "slides/lect_15.html#testing-a-proportion---contd",
    "title": "Chapter 16: Statistical tests",
    "section": "Testing a proportion - contd",
    "text": "Testing a proportion - contd\nUnder \\(H_0\\), we find\n\\[z_0 = \\frac{\\hat{p} - p_0} {\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\]"
  },
  {
    "objectID": "slides/lect_15.html#assumptions",
    "href": "slides/lect_15.html#assumptions",
    "title": "Chapter 16: Statistical tests",
    "section": "Assumptions",
    "text": "Assumptions\n\n\nSRS and sample must be < \\(10\\%\\) of population\nBoth \\(np_0\\) and \\(n(1-p_0)\\) are larger than 10"
  },
  {
    "objectID": "slides/lect_15.html#example-3",
    "href": "slides/lect_15.html#example-3",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 3",
    "text": "Example 3\nIn the ESP example, we know that the population average for guessing ESP cards is 9 out of 24 cards. An interested participant took a training course to enhance their ESP. In the followup exam, they guessed 17 out of 36 cards. Did the course improve their ESP abilities?"
  },
  {
    "objectID": "slides/lect_15.html#steps-for-a-hypothesis-test",
    "href": "slides/lect_15.html#steps-for-a-hypothesis-test",
    "title": "Chapter 16: Statistical tests",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState hypotheses\nDetermine the level of significance\nCheck conditions\nCalculate test statistic\nCompute p-value\nGeneric conclusion\nInterpret in context"
  },
  {
    "objectID": "slides/lect_15.html#example-3---solns",
    "href": "slides/lect_15.html#example-3---solns",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 3 - solns",
    "text": "Example 3 - solns\n\n\n\\(H_0: p \\leq 9/24\\) and \\(H_A: p > 9/24\\)\n\\(\\alpha = 0.05\\)\nYes 9/24*36 and (1-9/24)*36 both > 10\n\\(\\hat{p} = \\frac{x}{n} = \\frac{17}{36} =0.472\\)\n\\(\\begin{aligned} z_0 &= \\frac{\\hat{p} - p_0} {\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\\\ &= \\frac{0.472 - 0.375} {\\sqrt{\\frac{0.375(1-0.375)}{36}}} \\\\ &= \\frac{0.0972}{0.0807} \\approx 1.2 \\end{aligned}\\)"
  },
  {
    "objectID": "slides/lect_15.html#example-3---solns-1",
    "href": "slides/lect_15.html#example-3---solns-1",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 3 - solns",
    "text": "Example 3 - solns\n\n\n1 -pnorm(1.2) or 1- pnorm((17/36- 9/24)/sqrt((0.375*(1-0.375))/36)) \\(\\approx 0.115\\)\nSince \\(0.115 > \\alpha = 0.05\\) this is not significant.\nWe fail to reject \\(H_0\\). The score does not provide evidence that the intervention improved ESP."
  },
  {
    "objectID": "slides/lect_15.html#testing-a-mean---contd",
    "href": "slides/lect_15.html#testing-a-mean---contd",
    "title": "Chapter 16: Statistical tests",
    "section": "Testing a mean - contd",
    "text": "Testing a mean - contd\nUnder \\(H_0\\), we find\n\\[t = \\frac{\\bar{X} - \\mu_0} {s/\\sqrt{{n}}} \\]"
  },
  {
    "objectID": "slides/lect_15.html#assumptions-1",
    "href": "slides/lect_15.html#assumptions-1",
    "title": "Chapter 16: Statistical tests",
    "section": "Assumptions",
    "text": "Assumptions\n\n\nSRS and sample must be < \\(10\\%\\) of population\nIf we do not know if the population is normal, \\(n > 10|K_4|\\)"
  },
  {
    "objectID": "slides/lect_15.html#example-4",
    "href": "slides/lect_15.html#example-4",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 4",
    "text": "Example 4\nLet \\(\\bar{x} = 3281\\), \\(s = 529\\), and \\(n = 59\\). Perform a hypothesis test that the sample comes from a distribution where the population mean is less than \\(\\mu_0 = 4000\\)"
  },
  {
    "objectID": "slides/lect_15.html#steps-for-a-hypothesis-test-1",
    "href": "slides/lect_15.html#steps-for-a-hypothesis-test-1",
    "title": "Chapter 16: Statistical tests",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState hypotheses\nDetermine the level of significance\nCheck conditions\nCalculate test statistic\nCompute p-value\nGeneric conclusion\nInterpret in context"
  },
  {
    "objectID": "slides/lect_15.html#example-4---solns",
    "href": "slides/lect_15.html#example-4---solns",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 4 - solns",
    "text": "Example 4 - solns\n\n\n\\(H_0: p \\geq 4000\\) and \\(H_A: p < 4000\\)\n\\(\\alpha = 0.05\\)\nYes\n\\(\\bar{x} = 3281\\)\n\\(\\begin{aligned} t &= \\frac{\\bar{X} - \\mu_0} {s/\\sqrt{{n}}}\\\\ &= \\frac{3281-4000}{529/\\sqrt{59}} \\\\ &= \\frac{-719}{68.87} \\approx -10.44 \\end{aligned}\\)"
  },
  {
    "objectID": "slides/lect_15.html#example-4---solns-1",
    "href": "slides/lect_15.html#example-4---solns-1",
    "title": "Chapter 16: Statistical tests",
    "section": "Example 4 - solns",
    "text": "Example 4 - solns\n\n\npt(-10.44, df = 58) or pt((3281-4000)/(529/sqrt(59)), df = 58) \\(\\approx 3.07e-15\\)\nSince \\(3.07e-15 < \\alpha = 0.05\\) this is significant.\nWe reject \\(H_0\\). There is very strong evidence that the mean value is less than 4000."
  },
  {
    "objectID": "slides/lect_15.html#errors",
    "href": "slides/lect_15.html#errors",
    "title": "Chapter 16: Statistical tests",
    "section": "Errors",
    "text": "Errors\nThere are two types of errors defined in hypothesis testing:\n\nType I error, rejecting a true null\nType II error, not rejecting a false null"
  },
  {
    "objectID": "slides/lect_15.html#law-analogy",
    "href": "slides/lect_15.html#law-analogy",
    "title": "Chapter 16: Statistical tests",
    "section": "Law analogy",
    "text": "Law analogy\nIn the US, a person is innocent until proven guilty, and evidence of guilt must be beyond “the shadow of a doubt.” We can make two types of mistakes:\n\nConvict an innocent person (type I error)\nRelease a guilty person (type II error)"
  },
  {
    "objectID": "slides/lect_15.html#extremists-and-black-and-white",
    "href": "slides/lect_15.html#extremists-and-black-and-white",
    "title": "Chapter 16: Statistical tests",
    "section": "Extremists and black and white",
    "text": "Extremists and black and white\nTwo options:\n\nthe original study (p-value 0.01) made a Type I error, and the \\(H_0\\) was really true\nthe second study (p-value 0.59) made a Type II error, and \\(H_A\\) is really true\n\nor…\n\nmaybe there were no errors made, just different studies found different things"
  },
  {
    "objectID": "slides/lect_15.html#multiple-testing",
    "href": "slides/lect_15.html#multiple-testing",
    "title": "Chapter 16: Statistical tests",
    "section": "Multiple testing",
    "text": "Multiple testing\nBecause the probability of a Type I error is \\(\\alpha\\), if you do many tests you will find significance in \\(\\alpha\\) of them just by chance.\nIf you do 100 tests, you should expect to find 5 of them to be significant, just by chance.\nThis is the problem of multiple testing."
  },
  {
    "objectID": "slides/lect_15.html#multiple-testing-publication-bias",
    "href": "slides/lect_15.html#multiple-testing-publication-bias",
    "title": "Chapter 16: Statistical tests",
    "section": "Multiple testing + publication bias",
    "text": "Multiple testing + publication bias\nOkay, so \\(\\alpha\\) of all tests show significance, just by random chance.\nAnd things that look significant get published…\nThat means that a fair number of things that are published are actually false! This is pretty scary."
  },
  {
    "objectID": "slides/lect_15.html#how-to-fix-the-problem",
    "href": "slides/lect_15.html#how-to-fix-the-problem",
    "title": "Chapter 16: Statistical tests",
    "section": "How to fix the problem",
    "text": "How to fix the problem\nAs a researcher:\n\nmake sure your results can be replicated (like Motyl tried to do with the politics and grey study)\npublish code and data so others can study your work\n\nAs someone who reads about statistics:\n\nbe skeptical about claims that are just one of many tests\nlook for replication and reproducibility!"
  },
  {
    "objectID": "slides/lect_15.html#reducing-the-probability-of-type-ii-error",
    "href": "slides/lect_15.html#reducing-the-probability-of-type-ii-error",
    "title": "Chapter 16: Statistical tests",
    "section": "Reducing the probability of Type II error",
    "text": "Reducing the probability of Type II error\nIn order to reduce the probability of making a Type II error, we can either\n\nincrease the significance level\nincrease the sample size"
  },
  {
    "objectID": "slides/lect_14.html#revision",
    "href": "slides/lect_14.html#revision",
    "title": "Chapter 15: Confidence intervals",
    "section": "Revision",
    "text": "Revision"
  },
  {
    "objectID": "slides/lect_14.html#variability",
    "href": "slides/lect_14.html#variability",
    "title": "Chapter 15: Confidence intervals",
    "section": "Variability",
    "text": "Variability\n\nask them what they population mean should be\nwe also need to think about the variability\n\n\n\ndependent on \\(p\\) - fatter in middle, skinnier near 0 and 1\ndependent on \\(n\\), number of samples, bigger sample, less variability"
  },
  {
    "objectID": "slides/lect_14.html#variability---math",
    "href": "slides/lect_14.html#variability---math",
    "title": "Chapter 15: Confidence intervals",
    "section": "Variability - math",
    "text": "Variability - math\n\\[ \\hat{p} \\sim N(\\mu = p, \\sigma^2 = \\frac{p(1-p)}{n}) \\]\n\n\nnumerator of the variance is similar to that of a Binomial distribution\nas sample size increases, variance decreases"
  },
  {
    "objectID": "slides/lect_14.html#ci---math",
    "href": "slides/lect_14.html#ci---math",
    "title": "Chapter 15: Confidence intervals",
    "section": "CI - math",
    "text": "CI - math\n\\[\\hat{p} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\hat{p}(1-\\hat{p})/n} \\] For \\(95\\%\\) CI, \\(z_{\\alpha/2} = 1.96\\)\nAs confidence level increases, interval widens\nIn R: qnorm(0.025)"
  },
  {
    "objectID": "slides/lect_14.html#assumptions",
    "href": "slides/lect_14.html#assumptions",
    "title": "Chapter 15: Confidence intervals",
    "section": "Assumptions",
    "text": "Assumptions\n\n\nSRS condition The observed sample is SRS from the appropriate population. If population is finite, less than 10% of total population\nSample size condition (for proportion) both \\(n\\hat{p}\\) and \\(n(1-\\hat{p})\\) are larger than 10."
  },
  {
    "objectID": "slides/lect_14.html#example-1",
    "href": "slides/lect_14.html#example-1",
    "title": "Chapter 15: Confidence intervals",
    "section": "Example 1",
    "text": "Example 1\n\n\nLet \\(\\hat{p}= 0.14\\) and \\(n = 350\\), find a \\(95\\%\\) CI for the proportion\n\\(\\begin{aligned} se(\\hat{p}) &= \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} &= \\sqrt{\\frac{0.14(1-0.14)}{350}}\\end{aligned} \\approx 0.0185\\)\nlower value: \\(\\hat{p} - 1.96 \\cdot 0.0185 \\approx 0.10374\\)\nupper value: \\(\\hat{p} + 1.96 \\cdot 0.0185 \\approx 0.17626\\)"
  },
  {
    "objectID": "slides/lect_14.html#example-2",
    "href": "slides/lect_14.html#example-2",
    "title": "Chapter 15: Confidence intervals",
    "section": "Example 2",
    "text": "Example 2\nAn auditor checks a sample of 225 randomly chosen transactions from among the thousands processed in an office. Thirty-five contains errors in crediting or debiting the appropriate account\na. Does this situation meet the conditions required for a \\(z\\)-interval for the proportion?\nb. Find the \\(95\\%\\) confidence interval for \\(p\\), the proportion of all transactions processed in the this office that have these errors.\nc. Managers claim that the proportion of errors is about \\(10\\%\\). Does that seem reasonable?"
  },
  {
    "objectID": "slides/lect_14.html#example-2---solns",
    "href": "slides/lect_14.html#example-2---solns",
    "title": "Chapter 15: Confidence intervals",
    "section": "Example 2 - solns",
    "text": "Example 2 - solns\n\n\nyes, \\(\\hat{p} = 35/225 \\approx 0.156\\) so \\(n\\hat{p}, n(1-\\hat{p})> 10\\) and we assume sampled \\(<10\\%\\)\n\\(\\begin{aligned} \\hat{p} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\hat{p}(1-\\hat{p})/n} &= 0.156 \\pm 1.96 \\sqrt{0.156(1-0.156)/225}\\\\ &= 0.156 \\pm 1.96 \\cdot 0.0242 \\\\ &= 0.156 \\pm 0.047\\\\ & [0.109, 0.203]\\end{aligned}\\)\nNo \\(10\\%\\) is too low, with \\(95\\%\\) confidence it is higher"
  },
  {
    "objectID": "slides/lect_14.html#variability-1",
    "href": "slides/lect_14.html#variability-1",
    "title": "Chapter 15: Confidence intervals",
    "section": "Variability",
    "text": "Variability\n\n\nto account for smaller sample size we use a different distribution\n\n\n\n\nstandard deviation of distribution\n\nhigher sd -> wider CI\n\nsample size\n\nsmaller sample size -> wider CI"
  },
  {
    "objectID": "slides/lect_14.html#section-3",
    "href": "slides/lect_14.html#section-3",
    "title": "Chapter 15: Confidence intervals",
    "section": "",
    "text": "t distribution more density in tails"
  },
  {
    "objectID": "slides/lect_14.html#ci---mean",
    "href": "slides/lect_14.html#ci---mean",
    "title": "Chapter 15: Confidence intervals",
    "section": "CI - mean",
    "text": "CI - mean\n\\[\\bar{x} \\pm t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} \\]"
  },
  {
    "objectID": "slides/lect_14.html#t---distribution",
    "href": "slides/lect_14.html#t---distribution",
    "title": "Chapter 15: Confidence intervals",
    "section": "T - distribution",
    "text": "T - distribution\n\n\ndon’t know sigma so use s in it’s place\nas df get bigger (a proxy for n) S approaches sigma\n\n\n\n\n\\(Z = \\frac{X-\\mu_X}{\\sigma_X}\\)\n\\(\\bar{X} \\sim N(\\mu = \\mu\\_X, \\sigma^2 = \\frac{\\sigma_X^2}{n})\\)\n\\(T_{n-1} = \\frac{\\bar{X}-\\mu_X}{S/\\sqrt{n}}\\)\n\\(t\\) distribution has more density in the tails to account for smaller sample sizes"
  },
  {
    "objectID": "slides/lect_14.html#variability-2",
    "href": "slides/lect_14.html#variability-2",
    "title": "Chapter 15: Confidence intervals",
    "section": "Variability",
    "text": "Variability\n\n\ndependent on \\(confidence \\text{ }level\\) - as confidence level increases so does the width of the interval\ndependent on \\(n\\), number of samples, bigger sample, less variability"
  },
  {
    "objectID": "slides/lect_14.html#assumptions-1",
    "href": "slides/lect_14.html#assumptions-1",
    "title": "Chapter 15: Confidence intervals",
    "section": "Assumptions",
    "text": "Assumptions\n\n\nSRS condition The observed sample is SRS from the appropriate population. If population is finite, less than 10% of total population\nSample size condition the sample size is larger than 10 times the absolute value of the kurtosis, \\(n>10|K_4|\\)."
  },
  {
    "objectID": "slides/lect_14.html#example-1-1",
    "href": "slides/lect_14.html#example-1-1",
    "title": "Chapter 15: Confidence intervals",
    "section": "Example 1",
    "text": "Example 1\n\n\nLet \\(\\bar{x}= \\$3285\\), \\(n = 150\\), and \\(s = \\$238\\) find a \\(95\\%\\) CI for the mean\n\\(\\begin{aligned} se(\\bar{x}) &= s/\\sqrt{n} &= 238/\\sqrt{150}\\end{aligned} \\approx 19.43262\\)\nqt(.025, df = 149) \\(\\approx -1.976\\)\nlower value: \\(3285 - 1.976 \\cdot 19.43262 \\approx \\$3,320\\)\nupper value: \\(3285 + 1.976 \\cdot 19.43262 \\approx \\$3,247\\)\n3285 + qt(.025, df = 149)* 238/sqrt(150)"
  },
  {
    "objectID": "slides/lect_14.html#example-2-1",
    "href": "slides/lect_14.html#example-2-1",
    "title": "Chapter 15: Confidence intervals",
    "section": "Example 2",
    "text": "Example 2\nOffice administrators claim that the average amount on a purchase order is $6,000. A SRS of 49 purchase orders averages \\(\\bar{x} = \\$4,200\\) with \\(s = \\$3,500\\).\n\nWhat is the relevant sampling distribution?\nFind the 95% confidence interval for \\(\\mu\\), the mean of purchase orders handled by this office during the sampling period.\nDo you think the administrators claim is reasonable?"
  },
  {
    "objectID": "slides/lect_14.html#example-2---solns-1",
    "href": "slides/lect_14.html#example-2---solns-1",
    "title": "Chapter 15: Confidence intervals",
    "section": "Example 2 - solns",
    "text": "Example 2 - solns\n\n\n\\(N(\\mu, \\sigma^2/49)\\)\n\\[\\begin{aligned} 4200 \\pm 2.01 \\cdot 3500/\\sqrt{49} &= 4200 \\pm 2.01 \\cdot 500 \\\\ &= 4200 \\pm -1005.317 \\\\ &\\approx [3195, 5205]\\end{aligned}\\]\nNo \\(\\$6,00\\) is way above the \\(95\\%\\) confidence interval"
  },
  {
    "objectID": "slides/lect_14.html#example-2---solns-2",
    "href": "slides/lect_14.html#example-2---solns-2",
    "title": "Chapter 15: Confidence intervals",
    "section": "Example 2 - solns",
    "text": "Example 2 - solns\n\\(10 \\cdot [3195, 5205] = [31950, 52050]\\)"
  },
  {
    "objectID": "slides/lect_14.html#sample-size---mean",
    "href": "slides/lect_14.html#sample-size---mean",
    "title": "Chapter 15: Confidence intervals",
    "section": "Sample size - mean",
    "text": "Sample size - mean\n\\[n = \\frac{4s^2}{\\text{(Margin of error)}^2} \\]\n\n\nFor \\(p\\) use \\(p = 0.5\\) for biggest variance"
  },
  {
    "objectID": "supplemental/poisson.html",
    "href": "supplemental/poisson.html",
    "title": "Limits of the binomial distribution is the poisson",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr. James Tanton. They are provided for students who want to dive deeper into the mathematics behind the Poisson distribution. Additional supplemental notes will be added throughout the semester.\nI don’t know statistics! I’ve only ever taken one—very basic—introductory course on the subject from which I feel I learned very little. The rest of my understanding of the subject has been from personal reading and from teaching my own course on the subject! But I’ve secretly been longing for understanding the history and theoretical underpinnings of the topic for a very long time: Why is the central limit theorem true – mathematically and intuitively? How does one actually figure out the chi-squared distribution? Why, really, do you divide by \\(n-1\\) in the formula for standard deviation? And so on. (I figured out one answer to that last question here).\nI was reminded of my lack of knowledge of statistics last week at a university reception. An astronomer was chatting with his graduate student and said “Everything is the Poisson distribution” to then look at me, the mathematician, to say “Right?”\nIt might be shocking to learn that I don’t know what the Poisson distribution is! Well, I didn’t at that moment.\nI have a maxim: It is okay not to know. But it is not okay not to want to find out.\nSo I decided this month to find out about the Poisson distribution and think about its mathematical meaning.In looking up the formula one retrieves:\n\\[P(X=k)=\\frac{\\lambda^k}{k!} e^{-\\lambda}\\] for \\(k\\in\\{0,1, 2,3,\\ldots\\}.\\)\nThis reads: Some random variable \\(X\\) can take on non-negative integer values and the chances that you’ll actually see it adopt a particular value \\(k\\) is given by a crazy formula that depends on some constant parameter \\(\\lambda\\).\nGot it? Is it now clear that everything is Poisson?\nStatisticians and mathematicians do not come up with formulas out of the air. What is the story behind this bizarreness?"
  },
  {
    "objectID": "supplemental/poisson.html#perhaps-everything-is-binomial",
    "href": "supplemental/poisson.html#perhaps-everything-is-binomial",
    "title": "Limits of the binomial distribution is the poisson",
    "section": "Perhaps Everything is Binomial?",
    "text": "Perhaps Everything is Binomial?\nIf I roll a die three times, what are the chances I’ll get exactly two sixes?\nMaybe I’ll first roll a non-six and then two sixes:\n\\[N \\ 6 \\ 6\\] The chances of seeing this are \\(\\frac{5}{6}\\times \\frac{1}{6}\\times\\frac{1}{6}\\). Or, following the implied notation, I could roll \\(6\\ N\\ 6\\) or \\(6\\ 6\\ N\\) with probabilities\n\\(\\frac{1}{6}\\times \\frac{5}{6}\\times\\frac{1}{6}\\) and \\(\\frac{1}{6}\\times \\frac{1}{6}\\times\\frac{5}{6}\\), respectively.\nSo we see that there are \\(3\\) ways I could see two sixes and one non-six in a roll of three, each with the same probability. The chances of me seeing exactly two sixes is thus\n\\[ 3\\left(\\frac{1}{6}\\right)^2\\left(\\frac{5}{6}\\right) \\]\nIn general, if in an experiment I have a probability \\(p\\) of seeing a success, and hence a probability \\(1-p\\) of seeing a failure, and I run the experiment \\(n\\) times in a row, the probability that I will see exactly \\(k\\) successes is \\[\\binom{n}{k}p^k(1-p)^{n-k}\\]\nHere \\(\\binom{n}{k}=\\frac{n!}{k!(n-k)!}\\)is “\\(n\\) choose \\(k\\) ,” the number of ways \\(k\\) successes can be arranged among a string \\(n\\) units long. For example, the chances of seeing exactly two sixes after rolling a die three times is \\[\\frac{3!}{2!1!}\\left(\\frac{1}{6}\\right)^2\\left(1-\\frac{1}{6}\\right)=3\\left(\\frac{1}{6}\\right)^2\\left(\\frac{5}{6}\\right) \\] as we saw.\nWe have here a binomial distribution. In general, for each success probability \\(p\\) and run length \\(n\\) we have the distribution \\[\\mathbb{P}(X=k) = \\binom{n}{k}p^k(1-p)^{n-k}\\] for \\(k\\in\\{0,1, 2,\\ldots,n \\}.\\) Here \\(X\\) is the random variable given as the number of times I see a success in running an experiment \\(n\\) times in a row.”\nIn the 1700s scholars became interested in questions about runs of events that seem to occur in an ongoing fashion and counting the number of occurrences of the event you might expect to see in any selected time period. French mathematicians Siméon Denis Poisson and Abraham de Moivre were the first to develop the mathematics for this.\nI’ve been sitting on my porch for many hours of my life, counting the number of cars that pass by each hour. After many hours of observation I can say that the flow of cars is more or less regular (there is no difference in traffic flow in the day versus the night) and that, on average, \\(12\\) cars pass my house each hour.\nI am about to go sit out on my porch for an hour. What is the probability I will see \\(15\\) cars?\nOne possible start to this question is to treat it as a run of an experiment, not over an hour but, instead, one experiment per minute for \\(60\\) minutes. If I know the chances \\(p\\) of seeing a car in a given minute, then the chances of seeing \\(15\\) cars over a course of \\(60\\) minutes would be \\[\\binom{60}{15} p^{15}(1-p)^{45}.\\] How might I estimate \\(p\\)?\nWell, I expect to see an average of \\(12\\) cars over the course an hour. So, on average, I expect to see one car in any five-minute period. So chances of me selecting a minute with the appearance of a car in it should be \\(p=\\frac{1}{5}\\) That’s it. We have a formula for the chances of seeing \\(15\\) cars over the course of an hour. \\[ \\binom{60}{15}0.2^{15}0.8^{45}\\approx 0.076.\\] There is a problem with our work here: we’ve assumed that cars are spaced apart so that I’ll never see two cars within the same minute. To obviate this objection, let’s work instead with the \\(3600\\) seconds in an hour: I’ve never seen two cars go by within the same second.\nNow, on average, over the \\(3600\\) seconds of an hour, \\(12\\) of them will have a car “in them,” and so the chances of me seeing a car in any particular second is \\(p=\\frac{12}{3600}\\)\nThis now gives \\[\\binom{3600}{15}\\left(\\frac{12}{3600}\\right)^{15} \\left(1-\\frac{12}{3600}\\right)^{3555}\\approx0.080\\] for the chances of me seeing exactly \\(15\\) cars.\nWell, actually, I realise now that I think I have seen two cars go by within the same second: two cars going in opposite directions passed each other in front of my house.\nSo maybe I should repeat this analysis not over every minute or every second, but instead over every nanosecond or every picosecond. I need a very short length of time I can be sure will never have two cars appearing in it.\nLet’s break the hour into \\(n\\), almost instantaneous, units of time. The chances of me seeing a car within any one of those units is \\(p=\\frac{12}{n}\\) and so the probability of me seeing \\(15\\) cars over a run of \\(n\\) of these units of time is \\[\\binom{n}{15}\\left(\\frac{12}{n}\\right)^{15}\\left(1-\\frac{12}{n}\\right)^{n-15}.\\] Ideally, we should compute this for larger and larger values of \\(n\\). That is, we should take the limit as \\(n\\) grows infinitely large."
  },
  {
    "objectID": "supplemental/poisson.html#taking-the-limit",
    "href": "supplemental/poisson.html#taking-the-limit",
    "title": "Limits of the binomial distribution is the poisson",
    "section": "Taking the Limit",
    "text": "Taking the Limit\nThe formula we have reads \\[\\frac{n(n-1)(n-14)}{15!}\\cdot\\frac{12^{15}}{n^{15}}\\cdot\\left(1-\\frac{12}{n}\\right)^n\\cdot\\frac{1}{\\left(1-\\frac{12}{n}\\right)^{15}}.\\] I can see how parts of this formula change as \\(n\\) grows larger and larger.\nFor instance \\[ \\frac{1}{\\left(1-\\frac{12}{n}\\right)^{15}}\\to\\frac{1}{(1-0)^{15}}=1\\] as \\(n\\) grows.\nAlso, \\[ \\frac{n(n-1)\\cdots(n-14)}{n^{15}}=\\left(1-\\frac{1}{n}\\right)\\left(1-\\frac{2}{n}\\right)\\cdots\\left(1-\\frac{14}{n}\\right)\\to1\\cdot\\cdots 1 = 1\\] as \\(n\\) grows.\nAnd the formula \\(\\left(1-\\frac{12}{n}\\right)^{n}\\) is reminiscent of the famous compound-interest formula \\[ \\lim_{n\\to\\infty}\\left(1+\\frac{1}{n}\\right)^n=e\\] or more generally, \\[ \\lim_{n\\to\\infty}\\left(1+\\frac{x}{n}\\right)^n=e^x\\] So we have that \\[ \\left(1-\\frac{12}{n}\\right)^n\\to e^{-12}\\] as \\(n\\) grows.\nSo we see that our formula, \\[\n\\left(\\begin{array}{c}\nn \\\\\n15\n\\end{array}\\right)\\left(\\frac{12}{n}\\right)^{15}\\left(1-\\frac{12}{n}\\right)^{n-15}\n\\] in the absolute ideal of looking at finer and finer intervals over the hour, becomes the formula \\[\n1 \\cdot \\frac{12^{15}}{15 !} \\cdot e^{-12} \\cdot 1=\\frac{12^{15}}{15 !} e^{-12}.\n\\] This has value \\(\\approx 0.072\\). There is about a \\(7\\)% chance I will see \\(15\\) cars over any given hour.\nMost important, this work has led us to the Poisson probability distribution formula!\nIf you have a phenomenon that seems to occur at a more-or-less steady rate, with the number occurrences during any set time length seeming to be more-or-less the same over all periods of that length, and no two events can occur at exactly the same instant, then, if you have good reason to believe that, for a given period length, on average \\(\\lambda\\) events occur, the probability that you will see \\(k\\) events during any particular time period of that length is \\[\\frac{\\lambda^k}{k !} e^{-\\lambda}.\\]\nThis is the Poisson distribution.\nI am guessing that many astronomical phenomena occur at more-or-less steady rates, on average—meteor strikes to the Earth, appearance of Sun spots—and so maybe close to everything in astronomy is indeed Poisson?\nAside: From \\(\\lim_{n\\to\\infty}\\left(1+\\frac{1}{n}\\right)^n=e\\) we see that \\[\n\\left(1+\\frac{x}{n}\\right)^n=\\left(\\left(1+\\frac{1}{n / x}\\right)^{n / x}\\right)^x \\rightarrow(e)^x\n\\]\nif \\(x\\) is positive (since \\(n/x\\) grows large and positive if \\(n\\) does). We also establish \\[\\lim _{n \\rightarrow \\infty}\\left(1-\\frac{1}{n}\\right)^n=e^{-1}\\]\nby observing that \\[\\begin{aligned}\\left(1-\\frac{1}{n}\\right)^n &=\\left(\\frac{n-1}{n}\\right)^n=\\frac{1}{\\left(\\frac{n}{n-1}\\right)^n} \\\\ &=\\frac{1}{\\left(1+\\frac{1}{n-1}\\right)^{n-1} \\cdot\\left(1+\\frac{1}{n-1}\\right)} \\\\ & \\rightarrow \\frac{1}{e \\cdot(1+0)}=\\frac{1}{e} \\end{aligned}\\]\nas \\(n\\) grows.\nFollowing similar algebra, we see that for negative \\(x\\), setting \\(y=-x\\), \\[ \\left(1+\\frac{x}{n}\\right)^n=\\left(1-\\frac{y}{n}\\right)^n=\\left(\\left(1-\\frac{1}{n/y}\\right)^{n/y}\\right)^y\\to e^{-y}=e^{x}.\\] Therefore \\[\n\\lim_{n\\to\\infty}\\left(1+\\frac{x}{n}\\right)^n=e^x\n\\] even if \\(x\\) is negative.\n© 2017 James Tanton tanton.math@gmail.com"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html",
    "href": "supplemental/exam-2-studyguide.html",
    "title": "Study list for exam 2",
    "section": "",
    "text": "The R functions we have discussed in these weeks:"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#addition-rules",
    "href": "supplemental/exam-2-studyguide.html#addition-rules",
    "title": "Study list for exam 2",
    "section": "Addition rules",
    "text": "Addition rules\n-\\(E(X \\pm c) = E(X) \\pm c\\)\n-\\(SD(X \\pm c) = SD(X)\\)\n-\\(Var(X \\pm c) = Var(X)\\)"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#multiplication-rules",
    "href": "supplemental/exam-2-studyguide.html#multiplication-rules",
    "title": "Study list for exam 2",
    "section": "Multiplication rules",
    "text": "Multiplication rules\n-\\(E(cX) = cE(X)\\)\n-\\(SD(cX) = |c|SD(X)\\)\n-\\(Var(cX) = c^2Var(X)\\)\n-\\(E(cX \\pm a)=cE(X) \\pm a\\)\n- \\(Var(cX \\pm a)=c^2Var(X)\\)"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#which-variable-on-which-axis-and-what-are-the-names-for-each-variable",
    "href": "supplemental/exam-2-studyguide.html#which-variable-on-which-axis-and-what-are-the-names-for-each-variable",
    "title": "Study list for exam 2",
    "section": "Which variable on which axis and what are the names for each variable?",
    "text": "Which variable on which axis and what are the names for each variable?"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#describing-scatter-plots",
    "href": "supplemental/exam-2-studyguide.html#describing-scatter-plots",
    "title": "Study list for exam 2",
    "section": "Describing scatter plots",
    "text": "Describing scatter plots\n\nHomo and heteroskedastic"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#covariance-look-at-a-plot-and-know-if-positive-or-negative",
    "href": "supplemental/exam-2-studyguide.html#covariance-look-at-a-plot-and-know-if-positive-or-negative",
    "title": "Study list for exam 2",
    "section": "Covariance look at a plot and know if positive or negative",
    "text": "Covariance look at a plot and know if positive or negative\n\\(cov(x, y) = \\frac{(x_1 - \\bar{x})(y_1 - \\bar{y}) + (x_2 - \\bar{x})(y_2 - \\bar{y}) + \\ldots + (x_n - \\bar{x})(y_n - \\bar{y})}{n-1}\\)"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#correlation---look-at-a-plot-and-approximate",
    "href": "supplemental/exam-2-studyguide.html#correlation---look-at-a-plot-and-approximate",
    "title": "Study list for exam 2",
    "section": "Correlation - look at a plot and approximate",
    "text": "Correlation - look at a plot and approximate\n\\[corr(x, y) = \\frac{cov(x, y)}{s_x \\cdot s_y}\\]\n\nReferred to as \\(r\\)\nStrength of linear association\n\\(r\\) is always between \\(-1\\) and \\(+1\\), \\(-1 \\leq r \\leq 1\\).\n\\(r\\) does not have units"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#fitting-a-line",
    "href": "supplemental/exam-2-studyguide.html#fitting-a-line",
    "title": "Study list for exam 2",
    "section": "Fitting a line",
    "text": "Fitting a line\n\\(m = \\frac{r \\cdot s_y}{s_x}\\)\n\\(b = \\bar{y} - m \\bar{x}\\)"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#predicting",
    "href": "supplemental/exam-2-studyguide.html#predicting",
    "title": "Study list for exam 2",
    "section": "Predicting",
    "text": "Predicting\n\nlibrary(tidymodels)\n\n## Assign the least\n## squares line\nleast_squares_fit <- \n  linear_reg() %>% \n  set_engine(\"lm\") %>% \n  fit(price ~ carat, data = diamonds) \n## NOTE: outcome first, predictor second\n\n## Find the prediction\npredict(least_squares_fit, tibble(carat = c(1, 2, 2.5, 4)))\n\n# A tibble: 4 × 1\n   .pred\n   <dbl>\n1  5500.\n2 13256.\n3 17135.\n4 28769."
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#spurious-correlations",
    "href": "supplemental/exam-2-studyguide.html#spurious-correlations",
    "title": "Study list for exam 2",
    "section": "Spurious correlations",
    "text": "Spurious correlations\nbirth order associated with increased risk of downs syndrome, etc…"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#the-sharpe-ratio",
    "href": "supplemental/exam-2-studyguide.html#the-sharpe-ratio",
    "title": "Study list for exam 2",
    "section": "The Sharpe ratio",
    "text": "The Sharpe ratio\n\\(S(X) = \\frac{\\mu_X - r_f}{\\sigma_X}\\) - higher better - how to compute with a calculator from a pdf and also with just \\(\\mu\\) and \\(\\sigma\\) - computing in R"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#joint-pdfs",
    "href": "supplemental/exam-2-studyguide.html#joint-pdfs",
    "title": "Study list for exam 2",
    "section": "Joint pdfs",
    "text": "Joint pdfs\nFind probability given values Are they independent or not? What do increasing and decreasing joint pdfs look like?\n\\(E(X+Y) = E(X) + E(Y)\\) regardless of independence"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#rules-of-independence",
    "href": "supplemental/exam-2-studyguide.html#rules-of-independence",
    "title": "Study list for exam 2",
    "section": "3 Rules of independence",
    "text": "3 Rules of independence"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#covariance-of-rv",
    "href": "supplemental/exam-2-studyguide.html#covariance-of-rv",
    "title": "Study list for exam 2",
    "section": "Covariance of RV",
    "text": "Covariance of RV\n\\(Cov(X, Y) = E((X - \\mu_X)(Y - \\mu_Y))\\) \\(Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y)\\) If \\(X\\),\\(Y\\) are independent, then \\(Cov(X, Y) = 0\\), opposite not true If \\(X\\), \\(Y\\) are independent, \\(Cov(X, Y) = 0\\), so \\(Var(X+ Y) = Var(X) + Var(Y)\\)"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#correlation",
    "href": "supplemental/exam-2-studyguide.html#correlation",
    "title": "Study list for exam 2",
    "section": "Correlation",
    "text": "Correlation\n\\(corr(x, y) = \\frac{cov(x, y)}{s_x \\cdot s_y}\\) \\[\\rho = Corr(X, Y) = \\frac{Cov(X, Y)}{\\sigma_X \\cdot \\sigma_Y}\\] ## IID variables \\(E(aX + bY + c) = aE(X) + bE(Y) + c\\) \\(Var(aX + bY + c) = a^2Var(X) + b^2Var(Y) + 2abCov(X, Y)\\)"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#bernoulli-trial",
    "href": "supplemental/exam-2-studyguide.html#bernoulli-trial",
    "title": "Study list for exam 2",
    "section": "Bernoulli trial",
    "text": "Bernoulli trial\nexpectation and variance"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#binomial",
    "href": "supplemental/exam-2-studyguide.html#binomial",
    "title": "Study list for exam 2",
    "section": "Binomial",
    "text": "Binomial\n\\(Y = B_1 + B_2 + ... + B_n\\), where \\(B_1, B_2, ..., B_n\\) Bernoulli trials FIST expectation and variance binomial pdf limiting of \\(p\\) approaches Poisson distribution use R to find these probabilities"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#poisson",
    "href": "supplemental/exam-2-studyguide.html#poisson",
    "title": "Study list for exam 2",
    "section": "Poisson",
    "text": "Poisson\nRIPS expectation and variance use R to find these probabilities"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#shifts-and-scales-of-normal-distribution",
    "href": "supplemental/exam-2-studyguide.html#shifts-and-scales-of-normal-distribution",
    "title": "Study list for exam 2",
    "section": "Shifts and scales of normal distribution",
    "text": "Shifts and scales of normal distribution\nZ score and standardization Use symmetry to find probabilities, finding them in R Percentiles to Z values, finding them in R"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#rule",
    "href": "supplemental/exam-2-studyguide.html#rule",
    "title": "Study list for exam 2",
    "section": "68 - 95 - 99.7 rule",
    "text": "68 - 95 - 99.7 rule"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#normality-tests-and-qqplots",
    "href": "supplemental/exam-2-studyguide.html#normality-tests-and-qqplots",
    "title": "Study list for exam 2",
    "section": "Normality tests and qqplots",
    "text": "Normality tests and qqplots"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#skewness-and-kurtosis",
    "href": "supplemental/exam-2-studyguide.html#skewness-and-kurtosis",
    "title": "Study list for exam 2",
    "section": "Skewness and Kurtosis",
    "text": "Skewness and Kurtosis"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#vocabulary-related-to-sampling",
    "href": "supplemental/exam-2-studyguide.html#vocabulary-related-to-sampling",
    "title": "Study list for exam 2",
    "section": "Vocabulary related to sampling",
    "text": "Vocabulary related to sampling\nsample, population, bias, representative, random, inference, cluster, strata, sampling frame, nonresponse rate, interviewer affects, survivor bias, …"
  },
  {
    "objectID": "supplemental/exam-2-studyguide.html#sampling-methods",
    "href": "supplemental/exam-2-studyguide.html#sampling-methods",
    "title": "Study list for exam 2",
    "section": "Sampling methods",
    "text": "Sampling methods\nSRS, stratified, cluster, census, voluntary response, convenience benefits and drawbacks of all and where to apply each"
  },
  {
    "objectID": "repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "R is a great language",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\nOur project will demonstrate that the praise package is by far the best R package."
  }
]