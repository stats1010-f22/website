---
title: "Chapter 18: Inference for counts"
subtitle: "STAT 1010 - Fall 2022"
footer:  "[stat1010-f22.github.io/website](https://stats1010-f22.github.io/website/)"
format: 
  revealjs: 
    theme: slides.scss
    transition: fade
    slide-number: true
editor: visual
execute:
  freeze: auto
---

```{r include = FALSE}
library(countdown)
library(pdftools)
library(tidyverse)
library(kableExtra)
```

# Learning outcomes

::: incremental
-   Test for independence in a contigency table using a chi-squared test
-   Check for a goodness of fit of a probability model using a chi-square test
-   Find the appropriate degrees of freedom for a chi-squared test.
-   Explain the similarities and differences between chi-squared tests and methods that compare two proportions
-   Determine the statistical significance of a chi-squared statistic from `R`
:::

## Revision

We have [discussed](https://stats1010-f22.github.io/website/supplemental/chi-squared.html) [this](https://stats1010-f22.github.io/website/ae/ae-2-exploring-categorical-vars.html#chi-squared-test) [before](https://stats1010-f22.github.io/website/hw/hw-1.html) and now we will formalize this work. Like walking up a lighthouse.

## Test of independence

$$H_0: \text{Qualitative variable 1 and Qualitative variable 2 are independent}$$

$$H_A: \text{Qualitative variable 1 and Qualitative variable 2 are not independent}$$

## Example 1 {.smaller}

A manufacturing firm is considering a shift from a 5-day workweek (8 hours per day) to a 4-day workweek (10 hours per day). Samples of the preferences of 188 employees in four divisions produced the following contingency table:

Observed counts

|             |       | Divisions |            |       |
|-------------|-------|-----------|------------|-------|
|             |       | Clerical  | Production | Total |
| Preferences | 5-day | 17        | 46         | 63    |
|             | 4-day | 28        | 38         | 66    |
|             | Total | 45        | 84         | 129   |

a\. What would it mean if the preference of employees is independent of division?

b\. State $H_0$ for the $\chi^2$ test of independence in terms of the parameters of four segments of the population of employees.

## Example 1 - solns

a.  Independence means that all the percent of people who prefer a 5-day work week is the same in all divisions. Lack of independence implies different percentages across divisions
b.  $H_0: p_{clerical} = p_{production}$ 
$H_A: \text{at least one of these differs}$

## Calculating $\chi^2$

If one variable is independent of the other, then the variable should have the same proportion in each level as the totals have in each level.

Expected counts

|             |       | Divisions                  |                            |       |
|---------------|---------------|-----------------------------|---------------------------------|--------------|
|             |       | Clerical                   | Production                 | Total |
| Preferences | 5-day | $45/129\cdot63 \approx 22$ | $84/129\cdot63 \approx 41$ | 63    |
|             | 4-day | $45/129\cdot66 \approx 23$ | $45/129\cdot66 \approx 43$ | 66    |
|             | Total | 45                         | 84                         | 129   |


## Calculating $\chi^2$

$$ \chi^2 = sum\frac{(observed - expected)^2}{expected}$$
## Example 2

Find the expected counts for the following observed variables

```{r expected-counts}
#| echo: false
#| eval: true

## Input data
gender <- c(rep("male", 222), 
            rep("female", 240))
mood <- c(rep("happy", 70), rep("meh",32),
          rep("sad", 120), rep("happy", 100),
          rep("meh", 30), rep("sad", 110))
d <- tibble(gender, mood)

## contingency table
d %>% 
  count(gender, mood) %>% 
  group_by(gender) %>% 
  mutate(sum_gender = sum(n)) %>% 
  ungroup() %>% 
  group_by(mood) %>% 
  mutate(sum_mood = sum(n)) %>% 
  kbl() %>%
  kable_styling()
```


## Plot

::: columns
::: {.column width="50%"}
```{r plot-show}
#| echo: true
#| eval: false

gender <- c(rep("male", 222), 
            rep("female", 240))
mood <- c(rep("happy", 70), rep("meh",32),
          rep("sad", 120), rep("happy", 100),
          rep("meh", 30), rep("sad", 110))
d <- tibble(gender, mood)
 
## draw the plot
ggplot(data = d) +
  geom_bar(aes(x = mood, fill = gender),
           position = "fill")
```
:::

::: {.column width="50%"}
```{r plot-draw}
#| echo: false
#| eval: true

gender <- c(rep("male", 222), 
            rep("female", 240))
mood <- c(rep("happy", 70), rep("meh",32),
          rep("sad", 120), rep("happy", 100),
          rep("meh", 30), rep("sad", 110))
d <- tibble(gender, mood)
 
## draw the plot
ggplot(data = d) +
  geom_bar(aes(x = mood, fill = gender),
           position = "fill")
```
:::
:::
## Reading plots

If the color change in the bars are approximately at the same height in every level of the variable on the $x$ axis, this is evidence against rejecting $H_0$. We might be more inclined to think that $H_0$ is true. 

## Assumptions

1. No lurking variables
2. Data is a random sample from the population
3. Categories must be mutually exclusive
4. Each cell count must be at least 5 or 10 (more here)


#  {background-iframe="https://nzgwynn.shinyapps.io/chi-squared/"}

## degrees of freedom

$$df \text{for a } \chi^2 \text{ test of independence} = (r-1)(c-1)$$

where $r= \text{number of rows}$ and $c= \text{number of columns}$

Assumption:
4. Each cell count ideally 10, or 5 if the test has 4 or more degrees of freedom. 

# General vs Specific Hypothesis


# Tests of goodness of fit