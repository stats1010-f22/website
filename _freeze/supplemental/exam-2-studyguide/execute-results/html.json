{
  "hash": "41fb6a59b1f5fb32277c01a11d4c9389",
  "result": {
    "markdown": "---\ntitle: \"Study list for exam 2\"\nexecute: \n  echo: false\n---\n\n\nThe R functions we have discussed in these weeks:\n\n|                |\n|----------------|\n| functions      |\n| qnorm()        |\n| pnorm()        |\n| cov()          |\n| cor()          |\n| mutate()       |\n| View()         |\n| tibble()       |\n| slice()        |\n| exp()          |\n| lfactorial()   |\n| dbinom()       |\n| dpois()        |\n| slice_sample() |\n| c()            |\n\n# Lecture 7\n\n$\\mu = E(X)$ $= x_1p(x_1) + x_2p(x_2) + ... + x_np(x_n)$\n\nHow to define a pdf!\n\n## Addition rules\n\n\\-$E(X \\pm c) = E(X) \\pm c$\n\n\\-$SD(X \\pm c) = SD(X)$\n\n\\-$Var(X \\pm c) = Var(X)$\n\n## Multiplication rules\n\n\\-$E(cX) = cE(X)$\n\n\\-$SD(cX) = |c|SD(X)$\n\n\\-$Var(cX) = c^2Var(X)$\n\n\\-$E(cX \\pm a)=cE(X) \\pm a$\n\n\\- $Var(cX \\pm a)=c^2Var(X)$\n\n# Lecture 8\n\n## Which variable on which axis and what are the names for each variable?\n\n## Describing scatter plots\n\n-   Homo and heteroskedastic\n\n## Covariance look at a plot and know if positive or negative\n\n$cov(x, y) = \\frac{(x_1 - \\bar{x})(y_1 - \\bar{y}) + (x_2 - \\bar{x})(y_2 - \\bar{y}) + \\ldots + (x_n - \\bar{x})(y_n - \\bar{y})}{n-1}$\n\n## Correlation - look at a plot and approximate\n\n$$corr(x, y) = \\frac{cov(x, y)}{s_x \\cdot s_y}$$\n\n1.  Referred to as $r$\n2.  Strength of linear association\n3.  $r$ is always between $-1$ and $+1$, $-1 \\leq r \\leq 1$.\n4.  $r$ does not have units\n\n## Fitting a line\n\n$m = \\frac{r \\cdot s_y}{s_x}$\n\n$b = \\bar{y} - m \\bar{x}$\n\n## Predicting\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n\n## Assign the least\n## squares line\nleast_squares_fit <- \n  linear_reg() %>% \n  set_engine(\"lm\") %>% \n  fit(price ~ carat, data = diamonds) \n## NOTE: outcome first, predictor second\n\n## Find the prediction\npredict(least_squares_fit, tibble(carat = c(1, 2, 2.5, 4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 Ã— 1\n   .pred\n   <dbl>\n1  5500.\n2 13256.\n3 17135.\n4 28769.\n```\n:::\n:::\n\n\n## Spurious correlations\n\nbirth order associated with increased risk of downs syndrome, etc...\n\n# Lecture 9\n\n## The Sharpe ratio\n\n$S(X) = \\frac{\\mu_X - r_f}{\\sigma_X}$ - higher better - how to compute with a calculator from a pdf and also with just $\\mu$ and $\\sigma$ - computing in `R`\n\n## Joint pdfs\n\nFind probability given values Are they independent or not? What do increasing and decreasing joint pdfs look like?\n\n$E(X+Y) = E(X) + E(Y)$ regardless of independence\n\n## 3 Rules of independence\n\n## Covariance of RV\n\n$Cov(X, Y) = E((X - \\mu_X)(Y - \\mu_Y))$ $Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y)$ If $X$,$Y$ are independent, then $Cov(X, Y) = 0$, opposite not true If $X$, $Y$ are independent, $Cov(X, Y) = 0$, so $Var(X+ Y) = Var(X) + Var(Y)$\n\n## Correlation\n\n$corr(x, y) = \\frac{cov(x, y)}{s_x \\cdot s_y}$ $$\\rho = Corr(X, Y) = \\frac{Cov(X, Y)}{\\sigma_X \\cdot \\sigma_Y}$$ \\## IID variables $E(aX + bY + c) = aE(X) + bE(Y) + c$ $Var(aX + bY + c) = a^2Var(X) + b^2Var(Y) + 2abCov(X, Y)$\n\n# Lecture 10\n\n## Bernoulli trial\n\nexpectation and variance\n\n## Binomial\n\n$Y = B_1 + B_2 + ... + B_n$, where $B_1, B_2, ..., B_n$ Bernoulli trials FIST expectation and variance binomial pdf limiting of $p$ approaches Poisson distribution use `R` to find these probabilities\n\n## Poisson\n\nRIPS expectation and variance use `R` to find these probabilities\n\n# Lecture 11\n\nAs $n$ increases binomial approaches normal distribution\n\n## Shifts and scales of normal distribution\n\nZ score and standardization Use symmetry to find probabilities, finding them in R Percentiles to Z values, finding them in R\n\n## 68 - 95 - 99.7 rule\n\n## Normality tests and qqplots\n\n## Skewness and Kurtosis\n\n# Lecture 12\n\n## Vocabulary related to sampling\n\nsample, population, bias, representative, random, inference, cluster, strata, sampling frame, nonresponse rate, interviewer affects, survivor bias, ...\n\n## Sampling methods\n\nSRS, stratified, cluster, census, voluntary response, convenience benefits and drawbacks of all and where to apply each\n\n# Lecture 13\n\ndistribution of the sample mean, standard error, control limits and types of errors, error rates with repeated testing, control charts for variation\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}