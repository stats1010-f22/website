{
  "hash": "e0dd8b3773d2adbf7ffc0cb451ba0cf6",
  "result": {
    "markdown": "---\ntitle: \"Chapter 17: Comparison\"\nsubtitle: \"STAT 1010 - Fall 2022\"\nfooter:  \"[stat1010-f22.github.io/website](https://stats1010-f22.github.io/website/)\"\nformat: \n  revealjs: \n    theme: slides.scss\n    transition: fade\n    slide-number: true\neditor: visual\nexecute:\n  freeze: auto\n---\n\n\n\n\n# Learning outcomes\n\n::: incremental\n-   Recognize confounding\n-   Formulate hypotheses for comparing two proportions\n-   Perform a z-test for the difference between two proportions\n-   Perform a t-test for the difference between two means\n-   Distinguish between paired and independent samples\n-   Use a CI for difference to compare two proportions or two means\n:::\n\n## Different types of comparisons {.smaller}\n\nFrom our last lecture, there are two courses that participants can take to improve their ESP abilities. One series of courses focuses on somatic training of the participant and the other on eye contact between the sender and receiver. For the purposes of this exercise, we let S be the event that a person took the first somatic course, and I be the event that a person took the first eye training course. This lesson will teach us how to assess these two courses. We will answer these questions:\n\n::: incremental\n1.  Does a higher proportion of people sign up for subsequent eye contact or somatic courses?\n2.  Are the earning for the somatic group higher than those of the eye contact group?\n:::\n\n# Data {.smaller}\n\nLet $p_i = \\text{the proportion of students who continue the series of eye contact training courses}$ and $p_s = \\text{the proportion of students who continue the series of somatic training courses}$. To demonstrate that somatic course is better than the eye contact, we want 2% more students to reenroll. The null hypothesis is $$H_0: p_s - p_i \\leq 0.02$$ means that enrollment in subsequent somatic courses does not meet this criteria. If the data rejects $H_0$ in favor of $H_A: p_s - p_i > 0.02$, this suggests the eye contact course is better.\n\n## Data - cont'd\n\nThere are a few ways that we can get data to explore these hypotheses:\n\n::: incremental\n1.  Experiment: random sample, assigns treatment, compares between treatments.\n2.  Obtain random samples from two populations.\n3.  Compare two sets of observations: can be problematic\n:::\n\n## Confounding\n\nWhen levels of one variable are associated with levels of another the variables are said to be *confounded.*\n\nIn our example, perhaps we run a course Sedona, AZ where belief in ESP is high and people are likely to take the whole course. If the other was run in Phoenix, AZ this would not be the case. The belief in ESP in the location is confounded with taking subsequent courses.\n\n## Example 1\n\nWhich of the following appear safe from confounding and which appear to be contaminated?\n\n1.  A comparison of two promotional displays using average daily sales in one store with one type of display and another store with a different type.\n2.  A comparison of two promotional diplays using average daily sales in one store with one type of display on Monday and the other display on Friday.\n3.  A comparison of two landscaping offers sent at random to potential customers in the same zip code.\n\n## Example 1 - solns\n\n1.  Confounded by differences between the store, such as location or sales volume\n2.  Confounded by differences in shopping patterns during the week.\n3.  Free of confounding, though may not generalize to other zip codes\n\n# Two-sample $z$-test for proportions\n\n$$ H_0: p_1 - p_2 \\leq D_0 $$\n\nThe formula for standard error for $\\hat{p}_1-\\hat{p}_2$ is\n\n$se(\\hat{p}_1 - \\hat{p}_2) = \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1}+\\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}$\n\n## Assumptions\n\n1.  No obvious lurking variable or confounders\n2.  SRS condition, or independent random samples from two populations\n3.  We need to check $\\begin{eqnarray*} n_1\\cdot \\hat{p}_1 \\geq 10 \\\\ n_1\\cdot(1-\\hat{p}_1) \\geq 10\\\\ n_2\\cdot \\hat{p}_2 \\geq 10\\\\ n_2\\cdot(1-\\hat{p}_2) \\geq 10 \\end{eqnarray*}$\n\n## Hypothesis test for a difference in proportions\n\n$$ z = \\frac{\\hat{p}_1 - \\hat{p}_2 - D_0}{se(\\hat{p}_1 - \\hat{p}_2)}$$\n\n## Example 2\n\nIn the ESP example, spiritual groups decided to randomly assign members to either the somatic ($n_s = 809$) or eye contact group ($n_i = 646$). From those in the somatic group $280$ re-enrolled, subsequent eye contact groups had $197$. Perform a two sample $z$-test for proportions to determine if the enrollment in the somatic course was 2% more, on average, than that in the eye contact course.\n\n## Steps for a hypothesis test\n\n1.  State hypotheses\n2.  Determine the level of significance\n3.  Check conditions\n4.  Calculate test statistic\n5.  Compute p-value\n6.  Generic conclusion\n7.  Interpret in context\n\n## Example 2 - solns\n\n::: incremental\n1.  $H_0: p_s - p_i \\leq 0.02$ and $H_A: p_s - p_i > 0.02$\n2.  $\\alpha = 0.05$\n3.  Yes, `280/809*809` and `(1-280/809)*809` both \\> 10 Yes, `197/646*646` and `(1-197/646)*646` both \\> 10\n4.  $\\hat{p_i} = \\frac{x_i}{n_i} = \\frac{197}{646} = 0.305$ $\\hat{p_s} = \\frac{x_s}{n_s} = \\frac{280}{809} = 0.346$\n:::\n\n## Example 2 - solns {.smaller}\n\n::: incremental\n5.  $\\begin{aligned} se(\\hat{p}_s - \\hat{p}_i) &= \\sqrt{\\frac{\\hat{p}_s(1-\\hat{p}_s)}{n_s}+\\frac{\\hat{p}_i(1-\\hat{p}_i)}{n_i}} \\\\ &= \\sqrt{\\frac{0.305(1-0.305)}{646}+\\frac{0.346(1-0.346)}{809}} \\\\ &= \\sqrt{0.0003281 + 0.0002797} \\approx 0.02465 \\end{aligned}$ $\\begin{aligned} z_0 &= \\frac{\\hat{p_s} - \\hat{p_i} - D_0} {se(\\hat{p_s} - \\hat{p_i})} \\\\ &= \\frac{0.346 - 0.305 - 0.02} {0.02465} \\\\ &\\approx 0.851927 \\end{aligned}$\n\n`1 - pnorm(0.851927)` or $\\approx 0.197$\n\n6.  Since $0.197 > \\alpha = 0.05$ this is not significant.\n7.  We *fail to reject* $H_0$. The reenrollment in the somatic course is not significantly more than the reenrollment in the eye contact course.\n:::\n\n# Two-sample confidence interval for proportions {.smaller}\n\nSometimes we only want to estimate the difference, not determine if they is a statistically significant difference. We may not know which value of $D_0$ to use.\n\n::: incremental\n1.  We can build 2 CIs (like we did [here](https://stats1010-f22.github.io/website/slides/lect_14.html#/ci---math)) to see if they overlap.\n2.  We can build a CI for the difference between the two proportions\n:::\n\n## Math - two sample CI for props\n\n$$ \\hat{p}_1 - \\hat{p}_2 - z_{\\alpha/2} se(\\hat{p}_1 - \\hat{p}_2) \\text{  to  }\\\\ \\hat{p}_1 - \\hat{p}_2 + z_{\\alpha/2} se(\\hat{p}_1 - \\hat{p}_2)$$\n\n## Assumptions\n\n1.  No obvious lurking variables or confounders\n2.  SRS condition\n3.  Sample size condition\n\n## Example 3\n\nIn the ESP example, spiritual groups decided to randomly assign members to either the somatic ($n_s = 809$) or eye contact group ($n_i = 646$). From those in the somatic contact group $280$ re-enrolled, subsequent eye contact groups had $197$. Find the 95% confidence interval for the difference between the proportions who take subsequent courses on the somatic and eye contact group.\n\n## Example 3 - solns\n\n::: incremental\n1.  $\\begin{aligned} \\text{lower bound} &= \\hat{p}_s - \\hat{p}_i - z_{\\alpha/2} se(\\hat{p}_s - \\hat{p}_i) \\\\ &= 0.346 - 0.305 - 1.96 \\cdot 0.02465 \\\\ &= 0.041 - 0.0483 \\approx -0.0073 \\end{aligned}$\n2.  $\\begin{aligned} \\text{upper bound} &= \\hat{p}_s - \\hat{p}_i + z_{\\alpha/2} se(\\hat{p}_s - \\hat{p}_i) \\\\ &= 0.346 - 0.305 + 1.96 \\cdot 0.02465 \\\\ &= 0.041 + 0.0483 \\approx 0.0893 \\end{aligned}$\n:::\n\n## Interpretation {.smaller}\n\nSince $0 \\text{ is in } [-0.0073, 0.0893]$ the difference is not statistically signficant at the $95\\%$ significance level. It is possible that the reenrollment rates for eye contact and the somatic course come from populations with the same proportion. We do not know which is higher, either could be.\n\nIf $0$ is not in the $95\\%$ confidence interval, then the difference is significant and we can be $95\\%$ confident that the difference is between the lower and upper bounds. Any value in the region could plausibly be the difference in proportions between the two populations.\n\n# Two sample t-test\n\nInstead of reenrollment levels, perhaps we're interested in the differences in earnings from the two ESP course. In that case, we'll need to use a *two sample t-test*:\n\n$$ t = \\frac{(\\bar{X}_1 - \\bar{X}_2) - D_0}{se(\\bar{X}_1 - \\bar{X}_2)} $$\n\n## Assumptions\n\n1.  No lurking variables\n2.  SRS condition\n3.  Similar variances\n4.  Each sample must exceed $10|K_4|$\n\n## In `R`\n\nThis computation is long and complicated, so it's best done in `R`: `t.test()`\n\nSince we only have summary data for the ESP example, we'll show with the diamonds dataset. In this situation, we'll ask if there is a relationship between carat (weight of the diamond) and color (D is best and J is worst). Which color has on average the largest diamonds?\n\n$$ H_0: \\mu_D - \\mu_j \\leq D_0$$\n\n## In `R`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## install packages\nlibrary(tidyverse)\n\nd.color <- diamonds %>% \n  filter(color == \"D\") %>% \n  select(carat)\n  \nj.color <- diamonds %>% \n  filter(color == \"J\") %>% \n  select(carat)\n\n## 2 - sided test\n## Alternative hypothesis: x != y\nt.test(x = d.color, y = j.color, alternative = \"two.sided\")\n\n## Alternative hypothesis: x < y by 0.1\nt.test(x = d.color, y = j.color, alternative  = \"less\", mu = .1)\n```\n:::\n\n\n\n## In `R`\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  d.color and j.color\nt = -41.811, df = 3683.7, p-value < 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.5279915 -0.4806923\nsample estimates:\nmean of x mean of y \n0.6577948 1.1621368 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  d.color and j.color\nt = -50.101, df = 3683.7, p-value < 2.2e-16\nalternative hypothesis: true difference in means is less than 0.1\n95 percent confidence interval:\n       -Inf -0.4844961\nsample estimates:\nmean of x mean of y \n0.6577948 1.1621368 \n```\n:::\n:::\n\n\n\n## Interpretation {.smaller}\n\nIf the p-value is less than $\\alpha$ there is evidence against $H_0$ and we can reject $H_0$ in favor of the alternative.\n\n\"If the p-value is low then the null must go.\"\n\n### 2 - sided\n\nThere is extremely strong evidence that the mean carat for diamonds with the best color (D) is not the same as that for diamonds with the worst color (J).\n\n### alternative = \"less\"\n\nThere is extremely strong evidence that the mean carat for diamonds with the best color (D) is smaller by at least 0.1 then diamonds with the worst color (J).\n\nBut what is the magnitude of the difference?\n\n# CI for the difference between two means\n\n$$ \\bar{X}_1 - \\bar{X}_2 - t_{\\alpha/2} se(\\bar{X}_1 - \\bar{X}_2) \\text{  to  }\\\\ \\bar{X}_1 - \\bar{X}_2 + t_{\\alpha/2} se(\\bar{X}_1 - \\bar{X}_2)$$ \n\nWe use `R` to calculate. The assumptions are the same as those of the [2 sample t-test](https://stats1010-f22.github.io/website/slides/lect_16.html#/assumptions-2)\n\n$se(\\bar{X}_1 - \\bar{X}_2) = \\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}$\n\n## In `R`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(x = d.color, y = j.color, conf.level = 0.95)$conf.int\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.5279915 -0.4806923\nattr(,\"conf.level\")\n[1] 0.95\n```\n:::\n:::\n\n\n# Paired comparisons {.smaller}\n\nWe'll circle back to this [ESP example](https://stats1010-f22.github.io/website/slides/lect_15.html#/example-3), but without the editing subsequent to class: \n\nIn the ESP example, an interested participant initially guessed 9 out of 24 cards and then took a training course to enhance their ESP. In the followup exam, they guessed 17 out of 36 cards. Did the course improve their ESP abilities?\n\nWhat is the difference between these questions and why will a *paired comparison* give us more accurate solutions?\n\n## Another example\n\nCertain people refused to get vacinated from COVID-19. To compare COVID infection rates it's best to *pair* people who are vaccinated and not vaccinated but who also have similar education levels, incomes, and risk of infection. This hapenned last year in a [UK government report](https://healthfeedback.org/claimreview/article-by-the-expose-failed-to-account-for-caveats-listed-in-u-k-vaccine-surveillance-reports-falsely-claims-fully-vaccinated-people-have-weakened-immunity/).\n\n## Math\nGiven the paired data we find the differences ($d_i = x_i â€“ y_i$)\n\nThe $100(1 - \\alpha)%$ confidence paired t- interval is\n\n$$\\bar{d} \\pm  t_{\\alpha/2, n-1} \\frac{s_d}{\\sqrt{n}}$$\n\nChecklist:\tNo obvious lurking variables.\n\t\t\tSRS condition.\n\t\t\tSample size condition.\n\t\t\t\n\t\t\t\n## In `R`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Weight of mice before treatment\nbefore <-c(200.1, 190.9, 192.7, 213, 241.4, 196.9, 172.2, 185.5, 205.2, 193.7)\n# Weight of mice after treatment\nafter <-c(392.9, 393.2, 345.1, 393, 434, 427.9, 422, 383.9, 392.3, 352.2)\n\n# A tibble\nmice <- tibble(\n  group = rep(c(\"before\", \"after\"), each = 10),\n  weight = c(before, after)\n  )\n\nt.test(weight ~ group, data = mice, paired = TRUE)\n```\n:::\n\n\n\n## In `R`\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  weight by group\nt = 20.883, df = 9, p-value = 6.2e-09\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 173.4219 215.5581\nsample estimates:\nmean difference \n         194.49 \n```\n:::\n:::\n\n\n\n\n## Plot\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = mice) +\n  geom_boxplot(aes(x = group, y = weight))\n```\n\n::: {.cell-output-display}\n![](lect_16_files/figure-revealjs/plot-1.png){width=960}\n:::\n:::\n\n\n## Interpretation\n\nThere is very strong evidence that the underlying population means of the mice before and after treatment are not the same. On average, the mice are much heavier after treatment. \n\n\n\n\n\n",
    "supporting": [
      "lect_16_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}