{
  "hash": "a40694757dba3b156899c451b9c28ec1",
  "result": {
    "markdown": "---\ntitle: \"Chapter 16: Statistical tests\"\nsubtitle: \"STAT 1010 - Fall 2022\"\nfooter:  \"[stat1010-f22.github.io/website](https://stats1010-f22.github.io/website/)\"\nformat: \n  revealjs: \n    theme: slides.scss\n    transition: fade\n    slide-number: true\neditor: visual\nexecute:\n  freeze: auto\n---\n\n\n\n\n# Learning outcomes\n\n::: incremental\n-   Vocabulary: alternative hypothesis, null hupothesis, one-sided, two-sided hypotheses, and test statistic\n-   Understand the differences between a statistical test for proportions and for means.\n-   Recognize the different types of errors Type I and Type II when designing a test\n-   Distinguish between statistical and substantive significance\n-   Relate confidence intervals to two-sided tests\n:::\n\n# Does ESP exist?\n\nSome people believe in the presence of Extrasensory Perception, or ESP. How could we prove whether it does or doesn't exist?\n\nOne test for ESP is with Zener cards.\n\n![](lect_15-things/zener-cards.jpg){width=\"369\"}\n\n## Does ESP exist?\n\nSince there are 5 cards, it would be possible to guess the correct card at random $p=1/5$ times, or 20% of the time.\n\nA person with ESP should be able to guess the correct card more often than 20%. But how much more often do they need to get it right for us to believe that ESP exists?\n\n## Statistical test\n\nOne way to determine something like this is to use a **statistical test**. A statistical test is a procedure to determine if the results from the sample are convincing enough to allow us to conclude something about the population.\n\n## Hypotheses\n\nWhen we perform a statistical test, we set out our **hypotheses** before we begin. There are two hypotheses,\n\n**null hypothesis** $H_0$, a statement about there being no effect, or no difference.\n\n**alternative hypothesis** $H_A$, the thing that we secretly hope will turn out to be true.\n\n## ESP hypotheses\n\nThinking about the ESP experiment, we could use words to state our hypotheses\n\n$\\begin{eqnarray*} &H_0:& \\text{ ESP does not exist} \\\\ &H_A:& \\text{ESP exists} \\end{eqnarray*}$\n\nWe could also write the hypotheses in terms of parameters,\n\n$\\begin{eqnarray*} H_0: p \\leq 1/5 \\\\ H_A: p > 1/5 \\end{eqnarray*}$\n\n## Hypotheses\n\n::: incremental\n-   Hypotheses are always written about the population parameter ($\\mu$, $p$, $\\mu_1-\\mu_2$, $p_1-p_2$), never about the sample statistics ($\\bar{x}$, $\\hat{p}$, $\\bar{x}_1-\\bar{x}_2$, $\\hat{p}_1-\\hat{p}_2$).\n-   The null hypothesis is the boring thing that we're trying to gather evidence against\n-   The alternative hypothesis is the exciting thing that would make headlines\n:::\n\n## One and two sided hypotheses\n\n::: incremental\n-   $H_A$ has a $>$ sign: upper tail, or \"one-sided\"\n-   $H_A$ has a $<$ sign: lower tail, or \"one-sided\"\n-   $H_A$ has a $\\neq$ sign: both sides, or \"two-sided\"\n:::\n\n## Example 1\n\nWhat are the null and alternate hypothesis for these decisions?\n\n::: incremental\n-   A person interviews for a job opening. The company has to decide whether to hire the person\n-   An inventor proposes a new way to wrap packages that they say will speed up the manufacturing process. Should they adopt the new method?\n-   A sales representative submits receipts from a recent business trip. Staff must determine whether the claims are legitimate.\n:::\n\n## Example 1 solns\n\n::: incremental\n-   $H_0 = $ Person is not hired\n-   $H_0 = $ Retain the current method\n-   $H_0 = $ Treat claims as legitimate. The employee is innocent until evidence to the contrary is found.\n:::\n\n## Past tests\n\n::: incremental\n-   [Visual assocation tests](https://stats1010-f22.github.io/website/slides/lect_08.html#/price-vs-carat)\n\n-   [qqplots](https://stats1010-f22.github.io/website/slides/lect_11.html#/plot---normal)\n\n-   [$\\chi^2$ tests](https://stats1010-f22.github.io/website/supplemental/chi-squared.html)\n:::\n\n## Example 2\n\nA snack-food chain runs a promotion in which shoppers are told that 1 in 4 kids' meals includes a prize. A father buys two kids' meals, and neither has a prize. He concludes that because neither has a prize, the chain is being deceptive.\n\na.  What is the null and alternative hypothesis?\nb.  Describe a Type I error?\nc.  Describe a Type II error?\nd.  What is the probability that the father has made a Type I error?\n\n## Example 2 - solns\n\na.  $H_0$ = chain is being honest; $H_A$ = chain is not being honest\nb.  Falsely accusing the chain of being deceptive\nc.  Failting to realize that the chain is being deceptive\nd.  Father rejects if both are missing a prize. $P(neither has a prize) = (1 - 1/4)^2 \\approx 0.56$\n\n## Test statistic\n\nIn the previous example, we used probability to determine how likely it is to get two meals neither of which contain a prize. This process involves computing a *test statistic* ($0.56$).\n\n# Testing a proportion\n\nTo test a proportion, $\\hat{p}$, we must have a distribution with which to compare it. The distribution that we use is the distribution assumed in $H_0$ we use $p_0$ to denote this.\n\n$$p_0 \\sim N(p_0,  \\frac{{p_0}(1-{p_0})}{n}) $$\n\n## Testing a proportion - contd\n\nUnder $H_0$, we find\n\n$$z_0 = \\frac{\\hat{p} - p_0} {\\sqrt{\\frac{p_0(1-p_0)}{n}}} $$ \n\n## Assumptions\n\n::: incremental\n-   *SRS* and sample must be < $10\\%$ of population\n-   Both $np_0$ and $n(1-p_0)$ are larger than 10\n:::\n\n## Example 3\n\nIn the ESP example, we know that the population average for  guessing ESP cards is 9 out of 24 cards. An interested participant  took a training course to enhance their ESP. In the followup exam, they guessed 17 out of 36 cards. Did the course improve their ESP abilities?\n\n## Steps for a hypothesis test\n\n1.  State hypotheses\n2.  Determine the level of significance\n3.  Check conditions\n4.  Calculate test statistic\n5.  Compute p-value\n6.  Generic conclusion\n7.  Interpret in context\n\n## Example 3 - solns\n\n::: incremental\n1.  $H_0: p \\leq 9/24$ and $H_A: p > 9/24$\n2.  $\\alpha = 0.05$\n3.  Yes `9/24*36` and `(1-9/24)*36` both > 10\n4.  $\\hat{p} = \\frac{x}{n} = \\frac{17}{36} =0.472$\n5.  $\\begin{aligned} z_0 &= \\frac{\\hat{p} - p_0} {\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\\\ &= \\frac{0.472 - 0.375} {\\sqrt{\\frac{0.375(1-0.375)}{36}}} \\\\ &= \\frac{0.0972}{0.0807} \\approx 1.2 \\end{aligned}$\n:::\n\n## Example 3 - solns\n\n::: incremental\n5.  `1 -pnorm(1.2)` or `1- pnorm((17/36- 9/24)/sqrt((0.375*(1-0.375))/36))` $\\approx 0.115$\n6.  Since $0.115 > \\alpha = 0.05$ this is not significant.\n7. We *fail to reject* $H_0$.  The score does not provide evidence that the intervention improved ESP.\n:::\n\n\n\n# Testing a mean\n\nTo test a mean, $\\bar{x}$, we must have a distribution with which to compare it. The distribution that we use is the distribution assumed in $H_0$ we use $\\mu_0$ to denote this. Because we don't know $\\sigma$ we will once again use $s$ from the sample\n\n## Testing a mean - contd\n\nUnder $H_0$, we find\n\n$$t = \\frac{\\bar{X} - \\mu_0} {s/\\sqrt{{n}}} $$ \n\n## Assumptions\n\n::: incremental\n-   *SRS* and sample must be < $10\\%$ of population\n-   If we do not know if the population is normal, $n > 10|K_4|$\n:::\n\n## Example 4\n\nLet $\\bar{x} = 3281$, $s = 529$, and $n = 59$. Perform a hypothesis test that the sample comes from a distribution where the population mean is less than $\\mu_0 = 4000$\n\n\n## Steps for a hypothesis test\n\n1.  State hypotheses\n2.  Determine the level of significance\n3.  Check conditions\n4.  Calculate test statistic\n5.  Compute p-value\n6.  Generic conclusion\n7.  Interpret in context\n\n## Example 4 - solns\n\n::: incremental\n1.  $H_0: p \\geq 4000$ and $H_A: p < 4000$\n2.  $\\alpha = 0.05$\n3.  Yes\n4.  $\\bar{x} = 3281$\n5.  $\\begin{aligned} t &= \\frac{\\bar{X} - \\mu_0} {s/\\sqrt{{n}}}\\\\ &= \\frac{3281-4000}{529/\\sqrt{59}} \\\\ &= \\frac{-719}{68.87} \\approx -10.44 \\end{aligned}$\n:::\n\n## Example 4 - solns\n\n::: incremental\n5.  `pt(-10.44, df = 58)` or \n`pt((3281-4000)/(529/sqrt(59)), df = 58)` $\\approx 3.07e-15$\n6.  Since  $3.07e-15 < \\alpha = 0.05$ this is significant.\n7. We *reject* $H_0$.  There is *very strong* evidence that the mean value is less than 4000.\n:::\n\n\n# Do extremists see the world in black and white?\n\nResearcher Matt Motyl ran a study in 2010 with 2,000 participants. He wanted to determine if political moderates were able to perceive shades of grey more accurately than people on the far left or the far right. The p-value from the study was 0.01. Reject the null! Evidence in support of the idea that moderates can see grey better.\n\nBut then... he re-ran the study. This time, the p-value was 0.59. Not even close to significant.\n\nWhat happened?!\n\nVia Regina Nuzzo's Nature article, [Scientific method: Statistical Errors](https://www.nature.com/news/scientific-method-statistical-errors-1.14700#)\n\n## Errors\n\nThere are two types of errors defined in hypothesis testing:\n\n-   Type I error, rejecting a true null\n-   Type II error, not rejecting a false null\n\n#  {background-iframe=\"https://shiny.rit.albany.edu/stat/betaprob/\"}\n\n## Law analogy\n\nIn the US, a person is innocent until proven guilty, and evidence of guilt must be beyond \"the shadow of a doubt.\" We can make two types of mistakes:\n\n-   Convict an innocent person (type I error)\n-   Release a guilty person (type II error)\n\n## Extremists and black and white\n\nTwo options:\n\n-   the original study (p-value 0.01) made a Type I error, and the $H_0$ was really true\n-   the second study (p-value 0.59) made a Type II error, and $H_A$ is really true\n\nor...\n\n-   maybe there were no errors made, just different studies found different things\n\n## Multiple testing\n\nBecause the probability of a Type I error is $\\alpha$, if you do many tests you will find significance in $\\alpha$ of them **just by chance**.\n\nIf you do 100 tests, you should expect to find 5 of them to be significant, just by chance.\n\nThis is the problem of **multiple testing.**\n\n## Multiple testing + publication bias\n\nOkay, so $\\alpha$ of all tests show significance, just by random chance.\n\nAnd things that look significant get published...\n\nThat means that a fair number of things that are published are actually false! This is pretty scary.\n\n## How to fix the problem\n\nAs a researcher:\n\n-   make sure your results can be replicated (like Motyl tried to do with the politics and grey study)\n-   publish code and data so others can study your work\n\nAs someone who reads about statistics:\n\n-   be skeptical about claims that are just one of many tests\n-   look for replication and reproducibility!\n\n## Reducing the probability of Type II error\n\nIn order to reduce the probability of making a Type II error, we can either\n\n-   increase the significance level\n-   increase the sample size\n\n# Statistical versus practical significance\n\nSometimes, you find something that is very statistically significant, but not practically significant.\n\nFor example, a revision program might increase final exam grades with $p-value < 0.00001$, but it may only increase final exam grades by $1\\%$. This is statistically significant but not practically significant.\n\nContext is important!\n\n# Confidence interval or test\n\nThese two are mostly interchangeable. However, tests only provide negative statements and does not give us much information about parameter values.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}