[
  {
    "objectID": "supplemental/exam-2-studyguide.html",
    "href": "supplemental/exam-2-studyguide.html",
    "title": "Study list for exam 2",
    "section": "",
    "text": "functions\noperators\npipes\n\n\nfilter()\n%/%\n%>%\n\n\ndistinct()\n%%\n“+”\n\n\ncount()\n!=\n\n\n\nselect()\nrowSums()\n\n\n\nmutate()\ncolSums()\n\n\n\nView()\n\n\n\n\nglimpse()\n\n\n\n\npivot_wider()\n\n\n\n\ngroup_by()\n\n\n\n\nchisq.test()\n\n\n\n\nggplot()\n\n\n\n\ngeom_hist()\n\n\n\n\ngeom_bar()\n\n\n\n\ngeom_point()\n\n\n\n\nlabs()\n\n\n\n\nfacet_wrap()\n\n\n\n\n\nBenefits and downsides of these visualization methods: histogram and boxplot.\nConditional probability tables - which variable is it conditioned on.\nMean, median, mode and which is best in skewed distributions. Identify in a plot\nMeasures of spread: standard deviation, variance, quartiles, percentiles, interquartile range.\nChi-squared expected counts given a contingency table of counts.\nIndependent events\nDisjoint events\nVenn diagrams\nCompliment\nThe three laws of probability - Kolomogorov’s axioms\nClassification of variables"
  },
  {
    "objectID": "supplemental/poisson.html",
    "href": "supplemental/poisson.html",
    "title": "Limits of the binomial distribution is the poisson",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr. James Tanton. They are provided for students who want to dive deeper into the mathematics behind the Poisson distribution. Additional supplemental notes will be added throughout the semester.\nI don’t know statistics! I’ve only ever taken one—very basic—introductory course on the subject from which I feel I learned very little. The rest of my understanding of the subject has been from personal reading and from teaching my own course on the subject! But I’ve secretly been longing for understanding the history and theoretical underpinnings of the topic for a very long time: Why is the central limit theorem true – mathematically and intuitively? How does one actually figure out the chi-squared distribution? Why, really, do you divide by \\(n-1\\) in the formula for standard deviation? And so on. (I figured out one answer to that last question here).\nI was reminded of my lack of knowledge of statistics last week at a university reception. An astronomer was chatting with his graduate student and said “Everything is the Poisson distribution” to then look at me, the mathematician, to say “Right?”\nIt might be shocking to learn that I don’t know what the Poisson distribution is! Well, I didn’t at that moment.\nI have a maxim: It is okay not to know. But it is not okay not to want to find out.\nSo I decided this month to find out about the Poisson distribution and think about its mathematical meaning.In looking up the formula one retrieves:\n\\[P(X=k)=\\frac{\\lambda^k}{k!} e^{-\\lambda}\\] for \\(k\\in\\{0,1, 2,3,\\ldots\\}.\\)\nThis reads: Some random variable \\(X\\) can take on non-negative integer values and the chances that you’ll actually see it adopt a particular value \\(k\\) is given by a crazy formula that depends on some constant parameter \\(\\lambda\\).\nGot it? Is it now clear that everything is Poisson?\nStatisticians and mathematicians do not come up with formulas out of the air. What is the story behind this bizarreness?"
  },
  {
    "objectID": "supplemental/poisson.html#perhaps-everything-is-binomial",
    "href": "supplemental/poisson.html#perhaps-everything-is-binomial",
    "title": "Limits of the binomial distribution is the poisson",
    "section": "Perhaps Everything is Binomial?",
    "text": "Perhaps Everything is Binomial?\nIf I roll a die three times, what are the chances I’ll get exactly two sixes?\nMaybe I’ll first roll a non-six and then two sixes:\n\\[N \\ 6 \\ 6\\] The chances of seeing this are \\(\\frac{5}{6}\\times \\frac{1}{6}\\times\\frac{1}{6}\\). Or, following the implied notation, I could roll \\(6\\ N\\ 6\\) or \\(6\\ 6\\ N\\) with probabilities\n\\(\\frac{1}{6}\\times \\frac{5}{6}\\times\\frac{1}{6}\\) and \\(\\frac{1}{6}\\times \\frac{1}{6}\\times\\frac{5}{6}\\), respectively.\nSo we see that there are \\(3\\) ways I could see two sixes and one non-six in a roll of three, each with the same probability. The chances of me seeing exactly two sixes is thus\n\\[ 3\\left(\\frac{1}{6}\\right)^2\\left(\\frac{5}{6}\\right) \\]\nIn general, if in an experiment I have a probability \\(p\\) of seeing a success, and hence a probability \\(1-p\\) of seeing a failure, and I run the experiment \\(n\\) times in a row, the probability that I will see exactly \\(k\\) successes is \\[\\binom{n}{k}p^k(1-p)^{n-k}\\]\nHere \\(\\binom{n}{k}=\\frac{n!}{k!(n-k)!}\\)is “\\(n\\) choose \\(k\\) ,” the number of ways \\(k\\) successes can be arranged among a string \\(n\\) units long. For example, the chances of seeing exactly two sixes after rolling a die three times is \\[\\frac{3!}{2!1!}\\left(\\frac{1}{6}\\right)^2\\left(1-\\frac{1}{6}\\right)=3\\left(\\frac{1}{6}\\right)^2\\left(\\frac{5}{6}\\right) \\] as we saw.\nWe have here a binomial distribution. In general, for each success probability \\(p\\) and run length \\(n\\) we have the distribution \\[\\mathbb{P}(X=k) = \\binom{n}{k}p^k(1-p)^{n-k}\\] for \\(k\\in\\{0,1, 2,\\ldots,n \\}.\\) Here \\(X\\) is the random variable given as the number of times I see a success in running an experiment \\(n\\) times in a row.”\nIn the 1700s scholars became interested in questions about runs of events that seem to occur in an ongoing fashion and counting the number of occurrences of the event you might expect to see in any selected time period. French mathematicians Siméon Denis Poisson and Abraham de Moivre were the first to develop the mathematics for this.\nI’ve been sitting on my porch for many hours of my life, counting the number of cars that pass by each hour. After many hours of observation I can say that the flow of cars is more or less regular (there is no difference in traffic flow in the day versus the night) and that, on average, \\(12\\) cars pass my house each hour.\nI am about to go sit out on my porch for an hour. What is the probability I will see \\(15\\) cars?\nOne possible start to this question is to treat it as a run of an experiment, not over an hour but, instead, one experiment per minute for \\(60\\) minutes. If I know the chances \\(p\\) of seeing a car in a given minute, then the chances of seeing \\(15\\) cars over a course of \\(60\\) minutes would be \\[\\binom{60}{15} p^{15}(1-p)^{45}.\\] How might I estimate \\(p\\)?\nWell, I expect to see an average of \\(12\\) cars over the course an hour. So, on average, I expect to see one car in any five-minute period. So chances of me selecting a minute with the appearance of a car in it should be \\(p=\\frac{1}{5}\\) That’s it. We have a formula for the chances of seeing \\(15\\) cars over the course of an hour. \\[ \\binom{60}{15}0.2^{15}0.8^{45}\\approx 0.076.\\] There is a problem with our work here: we’ve assumed that cars are spaced apart so that I’ll never see two cars within the same minute. To obviate this objection, let’s work instead with the \\(3600\\) seconds in an hour: I’ve never seen two cars go by within the same second.\nNow, on average, over the \\(3600\\) seconds of an hour, \\(12\\) of them will have a car “in them,” and so the chances of me seeing a car in any particular second is \\(p=\\frac{12}{3600}\\)\nThis now gives \\[\\binom{3600}{15}\\left(\\frac{12}{3600}\\right)^{15} \\left(1-\\frac{12}{3600}\\right)^{3555}\\approx0.080\\] for the chances of me seeing exactly \\(15\\) cars.\nWell, actually, I realise now that I think I have seen two cars go by within the same second: two cars going in opposite directions passed each other in front of my house.\nSo maybe I should repeat this analysis not over every minute or every second, but instead over every nanosecond or every picosecond. I need a very short length of time I can be sure will never have two cars appearing in it.\nLet’s break the hour into \\(n\\), almost instantaneous, units of time. The chances of me seeing a car within any one of those units is \\(p=\\frac{12}{n}\\) and so the probability of me seeing \\(15\\) cars over a run of \\(n\\) of these units of time is \\[\\binom{n}{15}\\left(\\frac{12}{n}\\right)^{15}\\left(1-\\frac{12}{n}\\right)^{n-15}.\\] Ideally, we should compute this for larger and larger values of \\(n\\). That is, we should take the limit as \\(n\\) grows infinitely large."
  },
  {
    "objectID": "supplemental/poisson.html#taking-the-limit",
    "href": "supplemental/poisson.html#taking-the-limit",
    "title": "Limits of the binomial distribution is the poisson",
    "section": "Taking the Limit",
    "text": "Taking the Limit\nThe formula we have reads \\[\\frac{n(n-1)(n-14)}{15!}\\cdot\\frac{12^{15}}{n^{15}}\\cdot\\left(1-\\frac{12}{n}\\right)^n\\cdot\\frac{1}{\\left(1-\\frac{12}{n}\\right)^{15}}.\\] I can see how parts of this formula change as \\(n\\) grows larger and larger.\nFor instance \\[ \\frac{1}{\\left(1-\\frac{12}{n}\\right)^{15}}\\to\\frac{1}{(1-0)^{15}}=1\\] as \\(n\\) grows.\nAlso, \\[ \\frac{n(n-1)\\cdots(n-14)}{n^{15}}=\\left(1-\\frac{1}{n}\\right)\\left(1-\\frac{2}{n}\\right)\\cdots\\left(1-\\frac{14}{n}\\right)\\to1\\cdot\\cdots 1 = 1\\] as \\(n\\) grows.\nAnd the formula \\(\\left(1-\\frac{12}{n}\\right)^{n}\\) is reminiscent of the famous compound-interest formula \\[ \\lim_{n\\to\\infty}\\left(1+\\frac{1}{n}\\right)^n=e\\] or more generally, \\[ \\lim_{n\\to\\infty}\\left(1+\\frac{x}{n}\\right)^n=e^x\\] So we have that \\[ \\left(1-\\frac{12}{n}\\right)^n\\to e^{-12}\\] as \\(n\\) grows.\nSo we see that our formula, \\[\n\\left(\\begin{array}{c}\nn \\\\\n15\n\\end{array}\\right)\\left(\\frac{12}{n}\\right)^{15}\\left(1-\\frac{12}{n}\\right)^{n-15}\n\\] in the absolute ideal of looking at finer and finer intervals over the hour, becomes the formula \\[\n1 \\cdot \\frac{12^{15}}{15 !} \\cdot e^{-12} \\cdot 1=\\frac{12^{15}}{15 !} e^{-12}.\n\\] This has value \\(\\approx 0.072\\). There is about a \\(7\\)% chance I will see \\(15\\) cars over any given hour.\nMost important, this work has led us to the Poisson probability distribution formula!\nIf you have a phenomenon that seems to occur at a more-or-less steady rate, with the number occurrences during any set time length seeming to be more-or-less the same over all periods of that length, and no two events can occur at exactly the same instant, then, if you have good reason to believe that, for a given period length, on average \\(\\lambda\\) events occur, the probability that you will see \\(k\\) events during any particular time period of that length is \\[\\frac{\\lambda^k}{k !} e^{-\\lambda}.\\]\nThis is the Poisson distribution.\nI am guessing that many astronomical phenomena occur at more-or-less steady rates, on average—meteor strikes to the Earth, appearance of Sun spots—and so maybe close to everything in astronomy is indeed Poisson?\nAside: From \\(\\lim_{n\\to\\infty}\\left(1+\\frac{1}{n}\\right)^n=e\\) we see that \\[\n\\left(1+\\frac{x}{n}\\right)^n=\\left(\\left(1+\\frac{1}{n / x}\\right)^{n / x}\\right)^x \\rightarrow(e)^x\n\\]\nif \\(x\\) is positive (since \\(n/x\\) grows large and positive if \\(n\\) does). We also establish \\[\\lim _{n \\rightarrow \\infty}\\left(1-\\frac{1}{n}\\right)^n=e^{-1}\\]\nby observing that \\[\\begin{aligned}\\left(1-\\frac{1}{n}\\right)^n &=\\left(\\frac{n-1}{n}\\right)^n=\\frac{1}{\\left(\\frac{n}{n-1}\\right)^n} \\\\ &=\\frac{1}{\\left(1+\\frac{1}{n-1}\\right)^{n-1} \\cdot\\left(1+\\frac{1}{n-1}\\right)} \\\\ & \\rightarrow \\frac{1}{e \\cdot(1+0)}=\\frac{1}{e} \\end{aligned}\\]\nas \\(n\\) grows.\nFollowing similar algebra, we see that for negative \\(x\\), setting \\(y=-x\\), \\[ \\left(1+\\frac{x}{n}\\right)^n=\\left(1-\\frac{y}{n}\\right)^n=\\left(\\left(1-\\frac{1}{n/y}\\right)^{n/y}\\right)^y\\to e^{-y}=e^{x}.\\] Therefore \\[\n\\lim_{n\\to\\infty}\\left(1+\\frac{x}{n}\\right)^n=e^x\n\\] even if \\(x\\) is negative.\n© 2017 James Tanton tanton.math@gmail.com"
  },
  {
    "objectID": "supplemental/exam-1-studyguide.html",
    "href": "supplemental/exam-1-studyguide.html",
    "title": "Study list for exam 1",
    "section": "",
    "text": "functions\noperators\npipes\n\n\nfilter()\n%/%\n%>%\n\n\ndistinct()\n%%\n“+”\n\n\ncount()\n!=\n\n\n\nselect()\nrowSums()\n\n\n\nmutate()\ncolSums()\n\n\n\nView()\n\n\n\n\nglimpse()\n\n\n\n\npivot_wider()\n\n\n\n\ngroup_by()\n\n\n\n\nchisq.test()\n\n\n\n\nggplot()\n\n\n\n\ngeom_hist()\n\n\n\n\ngeom_bar()\n\n\n\n\ngeom_point()\n\n\n\n\nlabs()\n\n\n\n\nfacet_wrap()\n\n\n\n\n\nBenefits and downsides of these visualization methods: histogram and boxplot.\nConditional probability tables - which variable is it conditioned on.\nMean, median, mode and which is best in skewed distributions. Identify in a plot\nMeasures of spread: standard deviation, variance, quartiles, percentiles, interquartile range.\nChi-squared expected counts given a contingency table of counts.\nIndependent events\nDisjoint events\nVenn diagrams\nCompliment\nThe three laws of probability - Kolomogorov’s axioms\nClassification of variables"
  },
  {
    "objectID": "supplemental/slr-derivations.html",
    "href": "supplemental/slr-derivations.html",
    "title": "Deriving the Least-Squares Estimates for Simple Linear Regression",
    "section": "",
    "text": "This document contains the mathematical details for deriving the least-squares estimates for slope (\\(\\beta_1\\)) and intercept (\\(\\beta_0\\)). We obtain the estimates, \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) by finding the values that minimize the sum of squared residuals, as shown in Equation 1.\n\\[\nSSR = \\sum\\limits_{i=1}^{n}[y_i - \\hat{y}_i]^2 = [y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i)]^2 = [y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i]^2\n\\tag{1}\\]\nRecall that we can find the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize /eq-ssr by taking the partial derivatives of Equation 1 and setting them to 0. Thus, the values of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\) that minimize the respective partial derivative also minimize the sum of squared residuals. The partial derivatives are shown in Equation 2.\n\\[\n\\begin{aligned}\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} &= -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)  \\\\\n\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)\n\\end{aligned}\n\\tag{2}\\]\nThe derivation of deriving \\(\\hat{\\beta}_0\\) is shown in Equation 3.\n\\[\n\\begin{aligned}\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_0} &= -2 \\sum\\limits_{i=1}^{n}(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}(y_i + \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i) = 0 \\\\&\\Rightarrow - \\sum\\limits_{i=1}^{n}y_i + n\\hat{\\beta}_0 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i = 0 \\\\&\\Rightarrow n\\hat{\\beta}_0  = \\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i \\\\&\\Rightarrow \\hat{\\beta}_0  = \\frac{1}{n}\\Big(\\sum\\limits_{i=1}^{n}y_i - \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i\\Big)\\\\&\\Rightarrow \\hat{\\beta}_0  = \\bar{y} - \\hat{\\beta}_1 \\bar{x} \\\\\\end{aligned}\n\\tag{3}\\]\nThe derivation of \\(\\hat{\\beta}_1\\) using the \\(\\hat{\\beta}_0\\) we just derived is shown in Equation 4.\n\\[\n\\begin{aligned}&\\frac{\\partial \\text{SSR}}{\\partial \\hat{\\beta}_1} = -2 \\sum\\limits_{i=1}^{n}x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0  \\\\&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + \\hat{\\beta}_0\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\\\text{(Fill in }\\hat{\\beta}_0\\text{)}&\\Rightarrow -\\sum\\limits_{i=1}^{n}x_iy_i + (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = 0 \\\\&\\Rightarrow  (\\bar{y} - \\hat{\\beta}_1\\bar{x})\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\bar{y}\\sum\\limits_{i=1}^{n}x_i - \\hat{\\beta}_1\\bar{x}\\sum\\limits_{i=1}^{n}x_i + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow n\\bar{y}\\bar{x} - \\hat{\\beta}_1n\\bar{x}^2 + \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 = \\sum\\limits_{i=1}^{n}x_iy_i \\\\&\\Rightarrow \\hat{\\beta}_1\\sum\\limits_{i=1}^{n}x_i^2 - \\hat{\\beta}_1n\\bar{x}^2  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\&\\Rightarrow \\hat{\\beta}_1\\Big(\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2\\Big)  = \\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} \\\\ &\\hat{\\beta}_1 = \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2}\\end{aligned}\n\\tag{4}\\]\nTo write \\(\\hat{\\beta}_1\\) in a form that’s more recognizable, we will use the following:\n\\[\n\\sum x_iy_i - n\\bar{y}\\bar{x} = \\sum(x - \\bar{x})(y - \\bar{y}) = (n-1)\\text{Cov}(x,y)\n\\tag{5}\\]\n\\[\n\\sum x_i^2 - n\\bar{x}^2 - \\sum(x - \\bar{x})^2 = (n-1)s_x^2\n\\tag{6}\\]\nwhere \\(\\text{Cov}(x,y)\\) is the covariance of \\(x\\) and \\(y\\), and \\(s_x^2\\) is the sample variance of \\(x\\) (\\(s_x\\) is the sample standard deviation).\nThus, applying Equation 5 and Equation 6, we have\n\\[\n\\begin{aligned}\\hat{\\beta}_1 &= \\frac{\\sum\\limits_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}}{\\sum\\limits_{i=1}^{n}x_i^2 -n\\bar{x}^2} \\\\&= \\frac{\\sum\\limits_{i=1}^{n}(x-\\bar{x})(y-\\bar{y})}{\\sum\\limits_{i=1}^{n}(x-\\bar{x})^2}\\\\&= \\frac{(n-1)\\text{Cov}(x,y)}{(n-1)s_x^2}\\\\&= \\frac{\\text{Cov}(x,y)}{s_x^2}\\end{aligned}\n\\tag{7}\\]\nThe correlation between \\(x\\) and \\(y\\) is \\(r = \\frac{\\text{Cov}(x,y)}{s_x s_y}\\). Thus, \\(\\text{Cov}(x,y) = r s_xs_y\\). Plugging this into Equation 7, we have\n\\[\n\\hat{\\beta}_1 = \\frac{\\text{Cov}(x,y)}{s_x^2} = r\\frac{s_ys_x}{s_x^2} = r\\frac{s_y}{s_x}\n\\tag{8}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html",
    "href": "supplemental/model-diagnostics-matrix.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr. Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of the model diagnostics - leverage, standardized residuals, and Cook’s distance. We assume the reader knowledge of the matrix form for multiple linear regression. Please see Matrix Form of Linear Regression for a review."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#introduction",
    "href": "supplemental/model-diagnostics-matrix.html#introduction",
    "title": "Model Diagnostics",
    "section": "Introduction",
    "text": "Introduction\nSuppose we have \\(n\\) observations. Let the \\(i^{th}\\) be \\((x_{i1}, \\ldots, x_{ip}, y_i)\\), such that \\(x_{i1}, \\ldots, x_{ip}\\) are the explanatory variables (predictors) and \\(y_i\\) is the response variable. We assume the data can be modeled using the least-squares regression model, such that the mean response for a given combination of explanatory variables follows the form in Equation 1.\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{1}\\]\nWe can write the response for the \\(i^{th}\\) observation as shown in Equation 2.\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip} + \\epsilon_i\n\\tag{2}\\]\nsuch that \\(\\epsilon_i\\) is the amount \\(y_i\\) deviates from \\(\\mu\\{y|x_{i1}, \\ldots, x_{ip}\\}\\), the mean response for a given combination of explanatory variables. We assume each \\(\\epsilon_i \\sim N(0,\\sigma^2)\\), where \\(\\sigma^2\\) is a constant variance for the distribution of the response \\(y\\) for any combination of explanatory variables \\(x_1, \\ldots, x_p\\)."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "href": "supplemental/model-diagnostics-matrix.html#matrix-form-for-the-regression-model",
    "title": "Model Diagnostics",
    "section": "Matrix Form for the Regression Model",
    "text": "Matrix Form for the Regression Model\nWe can represent the Equation 1 and Equation 2 using matrix notation. Let\n\\[\n\\mathbf{Y} = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\y_n\\end{bmatrix}\n\\hspace{15mm}\n\\mathbf{X} = \\begin{bmatrix}x_{11} & x_{12} & \\dots & x_{1p} \\\\\nx_{21} & x_{22} & \\dots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\dots & x_{np} \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\beta}= \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\n\\hspace{15mm}\n\\boldsymbol{\\epsilon}= \\begin{bmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\n\\tag{3}\\]\nThus,\n\\[\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\\]\nTherefore the estimated response for a given combination of explanatory variables and the associated residuals can be written as\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\hspace{10mm} \\mathbf{e} = \\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\tag{4}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "href": "supplemental/model-diagnostics-matrix.html#hat-matrix-leverage",
    "title": "Model Diagnostics",
    "section": "Hat Matrix & Leverage",
    "text": "Hat Matrix & Leverage\nRecall from the notes Matrix Form of Linear Regression that \\(\\hat{\\boldsymbol{\\beta}}\\) can be written as the following:\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\n\\tag{5}\\]\nCombining Equation 4 and Equation 5, we can write \\(\\hat{\\mathbf{Y}}\\) as the following:\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{Y}} &= \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[10pt]\n&= \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\\\\n\\end{aligned}\n\\tag{6}\\]\nWe define the hat matrix as an \\(n \\times n\\) matrix of the form \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\). Thus Equation 6 becomes\n\\[\n\\hat{\\mathbf{Y}} = \\mathbf{H}\\mathbf{Y}\n\\tag{7}\\]\nThe diagonal elements of the hat matrix are a measure of how far the predictor variables of each observation are from the means of the predictor variables. For example, \\(h_{ii}\\) is a measure of how far the values of the predictor variables for the \\(i^{th}\\) observation, \\(x_{i1}, x_{i2}, \\ldots, x_{ip}\\), are from the mean values of the predictor variables, \\(\\bar{x}_1, \\bar{x}_2, \\ldots, \\bar{x}_p\\). In the case of simple linear regression, the \\(i^{th}\\) diagonal, \\(h_{ii}\\), can be written as\n\\[\nh_{ii} =  \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j=1}^{n}(x_j-\\bar{x})^2}\n\\]\nWe call these diagonal elements, the leverage of each observation.\nThe diagonal elements of the hat matrix have the following properties:\n\n\\(0 \\leq h_ii \\leq 1\\)\n\\(\\sum\\limits_{i=1}^{n} h_{ii} = p+1\\), where \\(p\\) is the number of predictor variables in the model.\nThe mean hat value is \\(\\bar{h} = \\frac{\\sum\\limits_{i=1}^{n} h_{ii}}{n} = \\frac{p+1}{n}\\).\n\nUsing these properties, we consider a point to have high leverage if it has a leverage value that is more than 2 times the average. In other words, observations with leverage greater than \\(\\frac{2(p+1)}{n}\\) are considered to be high leverage points, i.e. outliers in the predictor variables. We are interested in flagging high leverage points, because they may have an influence on the regression coefficients.\nWhen there are high leverage points in the data, the regression line will tend towards those points; therefore, one property of high leverage points is that they tend to have small residuals. We will show this by rewriting the residuals from Equation 4 using Equation 7.\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{Y} - \\hat{\\mathbf{Y}} \\\\[10pt]\n& = \\mathbf{Y} - \\mathbf{H}\\mathbf{Y} \\\\[10pt]\n&= (1-\\mathbf{H})\\mathbf{Y}\n\\end{aligned}\n\\tag{8}\\]\nNote that the identity matrix and hat matrix are idempotent, i.e. \\(\\mathbf{I}\\mathbf{I} = \\mathbf{I}\\), \\(\\mathbf{H}\\mathbf{H} = \\mathbf{H}\\). Thus, \\((\\mathbf{I} - \\mathbf{H})\\) is also idempotent. These matrices are also symmetric. Using these properties and Equation 8, we have that the variance-covariance matrix of the residuals \\(\\boldsymbol{e}\\), is\n\\[\n\\begin{aligned}\nVar(\\mathbf{e}) &= \\mathbf{e}\\mathbf{e}^T \\\\[10pt]\n&=  (1-\\mathbf{H})Var(\\mathbf{Y})^T(1-\\mathbf{H})^T \\\\[10pt]\n&= (1-\\mathbf{H})\\hat{\\sigma}^2(1-\\mathbf{H})^T  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})(1-\\mathbf{H})  \\\\[10pt]\n&= \\hat{\\sigma}^2(1-\\mathbf{H})\n\\end{aligned}\n\\tag{9}\\]\nwhere \\(\\hat{\\sigma}^2 = \\frac{\\sum_{i=1}^{n}e_i^2}{n-p-1}\\) is the estimated regression variance. Thus, the variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\hat{\\sigma}^2(1-h_{ii})\\). Therefore, the higher the leverage, the smaller the variance of the residual. Because the expected value of the residuals is 0, we conclude that points with high leverage tend to have smaller residuals than points with lower leverage."
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "href": "supplemental/model-diagnostics-matrix.html#standardized-residuals",
    "title": "Model Diagnostics",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nIn general, we standardize a value by shifting by the expected value and rescaling by the standard deviation (or standard error). Thus, the \\(i^{th}\\) standardized residual takes the form\n\\[\nstd.res_i = \\frac{e_i - E(e_i)}{SE(e_i)}\n\\]\nThe expected value of the residuals is 0, i.e. \\(E(e_i) = 0\\). From Equation 9), the standard error of the residual is \\(SE(e_i) = \\hat{\\sigma}\\sqrt{1-h_{ii}}\\). Therefore,\n\\[\nstd.res_i = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_{ii}}}\n\\tag{10}\\]"
  },
  {
    "objectID": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "href": "supplemental/model-diagnostics-matrix.html#cooks-distance",
    "title": "Model Diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s distance is a measure of how much each observation influences the model coefficients, and thus the predicted values. The Cook’s distance for the \\(i^{th}\\) observation can be written as\n\\[\nD_i = \\frac{(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})^T(\\hat{\\mathbf{Y}} -\\hat{\\mathbf{Y}}_{(i)})}{(p+1)\\hat{\\sigma}}\n\\tag{11}\\]\nwhere \\(\\hat{\\mathbf{Y}}_{(i)}\\) is the vector of predicted values from the model fitted when the \\(i^{th}\\) observation is deleted. Cook’s Distance can be calculated without deleting observations one at a time, since Equation 12 below is mathematically equivalent to Equation 11.\n\\[\nD_i = \\frac{1}{p+1}std.res_i^2\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg] = \\frac{e_i^2}{(p+1)\\hat{\\sigma}^2(1-h_{ii})}\\Bigg[\\frac{h_{ii}}{(1-h_{ii})}\\Bigg]\n\\tag{12}\\]"
  },
  {
    "objectID": "supplemental/model-selection-criteria.html",
    "href": "supplemental/model-selection-criteria.html",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "",
    "text": "Note\n\n\n\nThe following supplemental notes were created by Dr. Maria Tackett for STA 210. They are provided for students who want to dive deeper into the mathematics behind regression and reflect some of the material covered in STA 211: Mathematics of Regression. Additional supplemental notes will be added throughout the semester.\nThis document discusses some of the mathematical details of Akaike’s Information Criterion (AIC) and Schwarz’s Bayesian Information Criterion (BIC). We assume the reader knowledge of the matrix form for multiple linear regression.Please see Matrix Notation for Multiple Linear Regression for a review."
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "href": "supplemental/model-selection-criteria.html#maximum-likelihood-estimation-of-boldsymbolbeta-and-sigma",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)",
    "text": "Maximum Likelihood Estimation of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma\\)\nTo understand the formulas for AIC and BIC, we will first briefly explain the likelihood function and maximum likelihood estimates for regression.\nLet \\(\\mathbf{Y}\\) be \\(n \\times 1\\) matrix of responses, \\(\\mathbf{X}\\), the \\(n \\times (p+1)\\) matrix of predictors, and \\(\\boldsymbol{\\beta}\\), \\((p+1) \\times 1\\) matrix of coefficients. If the multiple linear regression model is correct then,\n\\[\n\\mathbf{Y} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2)\n\\tag{1}\\]\nWhen we do linear regression, our goal is to estimate the unknown parameters \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) from Equation 1. In Matrix Notation for Multiple Linear Regression, we showed a way to estimate these parameters using matrix alegbra. Another approach for estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is using maximum likelihood estimation.\nA likelihood function is used to summarise the evidence from the data in support of each possible value of a model parameter. Using Equation 1, we will write the likelihood function for linear regression as\n\\[\nL(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) = \\prod\\limits_{i=1}^n (2\\pi \\sigma^2)^{-\\frac{1}{2}} \\exp\\bigg\\{-\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})\\bigg\\}\n\\tag{2}\\]\nwhere \\(Y_i\\) is the \\(i^{th}\\) response and \\(\\mathbf{X}_i\\) is the vector of predictors for the \\(i^{th}\\) observation. One approach estimating \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) is to find the values of those parameters that maximize the likelihood in Equation 2, i.e. maximum likelhood estimation. To make the calculations more manageable, instead of maximizing the likelihood function, we will instead maximize its logarithm, i.e. the log-likelihood function. The values of the parameters that maximize the log-likelihood function are those that maximize the likelihood function. The log-likelihood function we will maximize is\n\\[\n\\begin{aligned}\n\\log L(\\mathbf{X}, \\mathbf{Y}|\\boldsymbol{\\beta}, \\sigma^2) &= \\sum\\limits_{i=1}^n -\\frac{1}{2}\\log(2\\pi\\sigma^2) -\\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta})^T(Y_i - \\mathbf{X}_i \\boldsymbol{\\beta}) \\\\\n&= -\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\\\\n\\end{aligned}\n\\tag{3}\\]\n\nThe maximum likelihood estimate of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2\\) are \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} \\hspace{10mm} \\hat{\\sigma}^2 = \\frac{1}{n}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta}) = \\frac{1}{n}RSS\n\\tag{4}\\]\nwhere \\(RSS\\) is the residual sum of squares. Note that the maximum likelihood estimate is not exactly equal to the estimate of \\(\\sigma^2\\) we typically use \\(\\frac{RSS}{n-p-1}\\). This is because the maximum likelihood estimate of \\(\\sigma^2\\) in Equation 4 is a biased estimator of \\(\\sigma^2\\). When \\(n\\) is much larger than the number of predictors \\(p\\), then the differences in these two estimates are trivial."
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#aic",
    "href": "supplemental/model-selection-criteria.html#aic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "AIC",
    "text": "AIC\nAkaike’s Information Criterion (AIC) is\n\\[\nAIC = -2 \\log L + 2(p+1)\n\\tag{5}\\]\nwhere \\(\\log L\\) is the log-likelihood. This is the general form of AIC that can be applied to a variety of models, but for now, let’s focus on AIC for mutliple linear regression.\n\\[\n\\begin{aligned}\nAIC &= -2 \\log L + 2(p+1) \\\\\n&= -2\\bigg[-\\frac{n}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^T(\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\\bigg] + 2(p+1) \\\\\n&= n\\log\\big(2\\pi\\frac{RSS}{n}\\big) + \\frac{1}{RSS/n}RSS \\\\\n&= n\\log(2\\pi) + n\\log(RSS) - n\\log(n) + 2(p+1)\n\\end{aligned}\n\\tag{6}\\]"
  },
  {
    "objectID": "supplemental/model-selection-criteria.html#bic",
    "href": "supplemental/model-selection-criteria.html#bic",
    "title": "Model Selection Criteria: AIC & BIC",
    "section": "BIC",
    "text": "BIC\n[To be added.]"
  },
  {
    "objectID": "supplemental/chi-squared.html",
    "href": "supplemental/chi-squared.html",
    "title": "Chi-squared test expected values",
    "section": "",
    "text": "Information about the Chi-Squared test can be found here. We have two hypotheses:\n\\(H_0\\) = the variables are independent, there is no relationship between the two categorical variables.\n\\(H_A\\) = Knowing the value of one variable helps to predict the value of the other variable.\nUnder the null hypothesis, the distribution of one variable is independent to the distribution of the other. This means that the expected count for one cell, can be found using the column total times the row total divided by the total number of observations."
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Teaching Assistant\n\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\n\nPatrick Chao\nMon & Wed\n4pm - 5pm\nZoom"
  },
  {
    "objectID": "weeks/week-02.html",
    "href": "weeks/week-02.html",
    "title": "Week 2",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-02.html#participate",
    "href": "weeks/week-02.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 2"
  },
  {
    "objectID": "weeks/week-02.html#practice",
    "href": "weeks/week-02.html#practice",
    "title": "Week 2",
    "section": "Practice",
    "text": "Practice\n📋 diamonds"
  },
  {
    "objectID": "weeks/week-02.html#perform",
    "href": "weeks/week-02.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-07.html",
    "href": "weeks/week-07.html",
    "title": "Week 7",
    "section": "",
    "text": "📖 Read Chpts 6 & 10 from Stine and Foster\n📖 Read FGLI: Chpts 6 & 10 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-07.html#participate",
    "href": "weeks/week-07.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 8\n🖥️ Lecture 9"
  },
  {
    "objectID": "weeks/week-07.html#practice",
    "href": "weeks/week-07.html#practice",
    "title": "Week 7",
    "section": "Practice",
    "text": "Practice\n📋 AE 9"
  },
  {
    "objectID": "weeks/week-07.html#perform",
    "href": "weeks/week-07.html#perform",
    "title": "Week 7",
    "section": "Perform",
    "text": "Perform\n✍️ HW 2 - Titanic\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-05.html",
    "href": "weeks/week-05.html",
    "title": "Week 5",
    "section": "",
    "text": "📖 Read Solutions to AEs\n📖 Read Solutions to HW-1"
  },
  {
    "objectID": "weeks/week-05.html#practice",
    "href": "weeks/week-05.html#practice",
    "title": "Week 5",
    "section": "Practice",
    "text": "Practice\n📋 Revision 1 for exam 1\n📋 Revision 2 for exam 1"
  },
  {
    "objectID": "weeks/week-05.html#perform",
    "href": "weeks/week-05.html#perform",
    "title": "Week 5",
    "section": "Perform",
    "text": "Perform\n⌨️ Course evaluation\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-06.html",
    "href": "weeks/week-06.html",
    "title": "Week 6",
    "section": "",
    "text": "📖 Read Chpt 9 from Stine and Foster\n📖 Read FGLI: Chpt 9 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-06.html#participate",
    "href": "weeks/week-06.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 7"
  },
  {
    "objectID": "weeks/week-06.html#practice",
    "href": "weeks/week-06.html#practice",
    "title": "Week 6",
    "section": "Practice",
    "text": "Practice\n📋 Random variables"
  },
  {
    "objectID": "weeks/week-06.html#perform",
    "href": "weeks/week-06.html#perform",
    "title": "Week 6",
    "section": "Perform",
    "text": "Perform\n✅ Exam 1\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-04.html",
    "href": "weeks/week-04.html",
    "title": "Week 4",
    "section": "",
    "text": "📖 Read chapter 14 of Introduction to Data Science\n📖 Read chapter 2 of Probability, Statistics, and Data: A fresh approach using R"
  },
  {
    "objectID": "weeks/week-04.html#participate",
    "href": "weeks/week-04.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 5\n🖥️ Lecture 6"
  },
  {
    "objectID": "weeks/week-04.html#practice",
    "href": "weeks/week-04.html#practice",
    "title": "Week 4",
    "section": "Practice",
    "text": "Practice\n📋 Exploring probabilities\n📋 The birthday simulation"
  },
  {
    "objectID": "weeks/week-04.html#perform",
    "href": "weeks/week-04.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test - week 3\n✍️ HW 1 - Titanic\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-03.html",
    "href": "weeks/week-03.html",
    "title": "Week 3",
    "section": "",
    "text": "📖 Read chapter 4 of Introduction to Modern Statistics\n📖 Read chapter 5 of Introduction to Modern Statistics"
  },
  {
    "objectID": "weeks/week-03.html#participate",
    "href": "weeks/week-03.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 3\n🖥️ Lecture 4"
  },
  {
    "objectID": "weeks/week-03.html#practice",
    "href": "weeks/week-03.html#practice",
    "title": "Week 3",
    "section": "Practice",
    "text": "Practice\n📋 Exploring qualitative variables\n📋 Exploring numeric variables"
  },
  {
    "objectID": "weeks/week-03.html#perform",
    "href": "weeks/week-03.html#perform",
    "title": "Week 3",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test - week 3\n✍️ HW 6 - Statistics Experience\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-08.html",
    "href": "weeks/week-08.html",
    "title": "Week 8",
    "section": "",
    "text": "📖 Read Chpts 11 & 12 from Stine and Foster\n📖 Read FGLI: Chpts 11 & 12 from Stine and Foster"
  },
  {
    "objectID": "weeks/week-08.html#participate",
    "href": "weeks/week-08.html#participate",
    "title": "Week 8",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 10\n🖥️ Lecture 11"
  },
  {
    "objectID": "weeks/week-08.html#practice",
    "href": "weeks/week-08.html#practice",
    "title": "Week 8",
    "section": "Practice",
    "text": "Practice\n📋"
  },
  {
    "objectID": "weeks/week-08.html#perform",
    "href": "weeks/week-08.html#perform",
    "title": "Week 8",
    "section": "Perform",
    "text": "Perform\n✍️ HW 2 - Titanic\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-01.html",
    "href": "weeks/week-01.html",
    "title": "Week 1",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Read the support resources"
  },
  {
    "objectID": "weeks/week-01.html#participate",
    "href": "weeks/week-01.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\n🖥️ Lecture 1 - Download R and plotting your first graph"
  },
  {
    "objectID": "weeks/week-01.html#practice",
    "href": "weeks/week-01.html#practice",
    "title": "Week 1",
    "section": "Practice",
    "text": "Practice\n📋 diamonds"
  },
  {
    "objectID": "weeks/week-01.html#perform",
    "href": "weeks/week-01.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n⌨️ Diagnostic test\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "slides/lect_08.html#price-vs-carat",
    "href": "slides/lect_08.html#price-vs-carat",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Price vs carat",
    "text": "Price vs carat"
  },
  {
    "objectID": "slides/lect_08.html#visual-association-test",
    "href": "slides/lect_08.html#visual-association-test",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Visual association test",
    "text": "Visual association test\n\nAsk them to run the coding in RStudio and see what they get - can connect some of their computers to the big screen\nCan they see a difference between their plots and the real plot? What is the difference?\n\n\n\n\n\n\n\n\n\n\ndiamonds %>% # filtered data\n  slice_sample(n = nrow(.)) %>% # random sample rows\n  pull(carat) %>% # take out the variable carat\n  bind_cols(., diamonds$price) %>% # price in the same order and bound to carat in different order\n  ggplot() + # into ggplot\n  geom_point(aes(y = ...2, x = ...1)) + # using the new names\n  labs(title = \"Simulated association test\", \n       x = \"Weight of diamond in carat\", \n       y = \"Price of diamonds in US$\")"
  },
  {
    "objectID": "slides/lect_08.html#describing-a-scatter-plot",
    "href": "slides/lect_08.html#describing-a-scatter-plot",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Describing a scatter plot",
    "text": "Describing a scatter plot\n\nWhat is the difference between the actual plot and the simulated plots?\nDiscuss each point.\nBig words make you sound smart to people that aren’t that smart.\n\n\n\n\nTrend or direction\n\npositive\nnegative\n\nCurvature\n\nlinear\nnonlinear\n\nexponential\nquadratic\n\n\n\n\n\nVariation\n\nhomoscedasticity (similar variance)\nheteroscedasticity (different variance)\n\nOutliers\n\nany weird points (explore these)\n\nGroupings"
  },
  {
    "objectID": "slides/lect_08.html#describe-these-plots",
    "href": "slides/lect_08.html#describe-these-plots",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Describe these plots",
    "text": "Describe these plots\n\nWhat are the relationships between each plot?\nWhat do the numbers mean?"
  },
  {
    "objectID": "slides/lect_08.html#measuring-association-1",
    "href": "slides/lect_08.html#measuring-association-1",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Measuring association",
    "text": "Measuring association\n\nRemind them of the variance and what we did with the squares. What squares could we use now?"
  },
  {
    "objectID": "slides/lect_08.html#covariance",
    "href": "slides/lect_08.html#covariance",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Covariance",
    "text": "Covariance\n\nIf the product is negative then there it contributes to a negative trend - downhill from left to right.\nSame if positive\nhard to get ones that are negative for this dataset b/c tbere is a really strong positive association"
  },
  {
    "objectID": "slides/lect_08.html#covariance-math",
    "href": "slides/lect_08.html#covariance-math",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Covariance math",
    "text": "Covariance math\n\nThis is a measure of the squares. We’d like a measure that is one dimensional. We want to look at more than just squares.\n\n\\(cov(x, y) = \\frac{(x_1 - \\bar{x})(y_1 - \\bar{y}) + (x_2 - \\bar{x})(y_2 - \\bar{y}) + \\ldots + (x_n - \\bar{x})(y_n - \\bar{y})}{n-1}\\)"
  },
  {
    "objectID": "slides/lect_08.html#correlation-math",
    "href": "slides/lect_08.html#correlation-math",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Correlation math",
    "text": "Correlation math\n\nStandardizes the strength of the association\n\n\\[corr(x, y) = \\frac{cov(x, y)}{s_x \\cdot s_y}\\]"
  },
  {
    "objectID": "slides/lect_08.html#correlation-characteristics",
    "href": "slides/lect_08.html#correlation-characteristics",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Correlation characteristics",
    "text": "Correlation characteristics\n\nStandardizes the strength of the association\n\n\n\nReferred to as \\(r\\)\nStrength of linear association\n\\(r\\) is always between \\(-1\\) and \\(+1\\), \\(-1 \\leq r \\leq 1\\).\n\\(r\\) does not have units"
  },
  {
    "objectID": "slides/lect_08.html#computing-in-r",
    "href": "slides/lect_08.html#computing-in-r",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Computing in R",
    "text": "Computing in R\n\nStandardizes the strength of the association\n\n\n# covariance of price and carat\ncov(diamonds$price, diamonds$carat)\n\n[1] 1742.765\n\n# correlation of price and carat\ncor(diamonds$price, diamonds$carat)\n\n[1] 0.9215913\n\n# coding for the pairs plots\n# library(GGally)\n# diamonds %>% # dataset\n#  select_if(is.numeric) %>% # numeric variables\n#  filter(y < 20, # y less than 20\n#         z < 20, # z less than 20\n#         table < 90) %>% # table less than 90\n#  ggpairs(.) # make the plot"
  },
  {
    "objectID": "slides/lect_08.html#gradient-and-slope",
    "href": "slides/lect_08.html#gradient-and-slope",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Gradient and slope",
    "text": "Gradient and slope\n\nPull out your calculators and work on this\n\n\\[ m = \\frac{r \\cdot s_y}{s_x} \\] \\[ b = \\bar{y} - m \\bar{x} \\]"
  },
  {
    "objectID": "slides/lect_08.html#fitting-by-hand",
    "href": "slides/lect_08.html#fitting-by-hand",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Fitting by hand",
    "text": "Fitting by hand\n\n\n\\(r = 0.9215913\\)\n\\(s_{price} = 3989.44\\)\n\\(s_{carat} = 0.4740112\\)\n\\(m = \\frac{r \\cdot s_{price}}{s_{carat}}\\)\n\\[\\begin{aligned}\n   m &= \\frac{r \\cdot s_{price}}{s_{carat}} \\\\\n&= \\frac{0.9215913 \\cdot 3989.44}{0.4740112} \\\\\n&= 7756.426\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_08.html#fitting-by-hand-1",
    "href": "slides/lect_08.html#fitting-by-hand-1",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Fitting by hand",
    "text": "Fitting by hand\n\n\n\\(b = \\overline{price} - m \\cdot \\overline{carat}\\)\n\\(\\overline{price} = 3932.8\\)\n\\(\\overline{carat} = 0.7979397\\)\n\\(m = 7756.426\\)\n\\[\\begin{aligned}\nb &= \\overline{price} - m \\cdot \\overline{carat} \\\\\n&= 3932.8 - 7756.426 \\cdot 0.7979397\\\\\n&= -2256.36\n\\end{aligned}\\]\nOur model is: \\(\\widehat{\\text{price}} = -2256.36 + 7756.426 \\cdot \\text{carat}\\)"
  },
  {
    "objectID": "slides/lect_08.html#prediction-by-hand",
    "href": "slides/lect_08.html#prediction-by-hand",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Prediction by hand",
    "text": "Prediction by hand\n\nPull out your calculators and work on this\n\nfor carat values \\(2.5\\)\n\n\n\\(\\widehat{\\text{price}} = -2256.36 + 7756.426 \\cdot \\text{carat}\\)\n\\[\\begin{aligned}\n\\widehat{\\text{price}}  &= -2256.36 + 7756.426 \\cdot \\text{carat} \\\\\n&= -2256.36 + 7756.426 \\cdot 2.5 \\\\\n&= \\$17135\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_08.html#fit-predict-in-r",
    "href": "slides/lect_08.html#fit-predict-in-r",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Fit & predict in R",
    "text": "Fit & predict in R\n\nfirst use of tidymodels package\n\n\n# library tidymodels\nlibrary(tidymodels)\n\n## Assign the least\n## squares line\nleast_squares_fit <- \n  linear_reg() %>% \n  set_engine(\"lm\") %>% \n  fit(price ~ carat, data = diamonds) \n## NOTE: outcome first, predictor second\n\n## Find the prediction\npredict(least_squares_fit, tibble(carat = c(1, 2, 2.5, 4)))\n\n# A tibble: 4 × 1\n   .pred\n   <dbl>\n1  5500.\n2 13256.\n3 17135.\n4 28769."
  },
  {
    "objectID": "slides/lect_08.html#warnings",
    "href": "slides/lect_08.html#warnings",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "Warnings",
    "text": "Warnings\n\n\nALWAYS draw plots first\nnumeric variables\nLinear relationship\nCheck for outliers\nLurking variables"
  },
  {
    "objectID": "slides/lect_08.html#more-spurious-correlations",
    "href": "slides/lect_08.html#more-spurious-correlations",
    "title": "Chapter 6: Association between quantitative variables",
    "section": "More spurious correlations",
    "text": "More spurious correlations\n\n\nThese variables are called lurking variables or confounders.\nLurking variables are not considered in the statistical analysis\nConfounders are considered\nThere are both known and unknown confounders, uknown confounders are lurking variables.\n\n\nClick here for more spurious correlations"
  },
  {
    "objectID": "slides/lect_07.html#using-proportions",
    "href": "slides/lect_07.html#using-proportions",
    "title": "Chapter 9: Random variables",
    "section": "Using proportions",
    "text": "Using proportions\n\n\n\n\\(x\\)\n\\(n\\)\n\\(P(X) = x\\)\n\n\n\n\n1.23\n3\n\n\n\n1.29\n5\n\n\n\n1.37\n4\n\n\n\n1.84\n1\n\n\n\n1.18\n6\n\n\n\n1.22\n2\n\n\n\n1.25\n4\n\n\n\nTotal\n25"
  },
  {
    "objectID": "slides/lect_07.html#mean-or-expected-value",
    "href": "slides/lect_07.html#mean-or-expected-value",
    "title": "Chapter 9: Random variables",
    "section": "Mean or expected value",
    "text": "Mean or expected value\nIf we know $P(X) = x$, then we can use this to find the mean or expected value of a random variable. The pdf includes information about both the total and the number of occurrences of \\(x\\), it does the computation for us.\n\\(\\mu = E(X)\\)\n\\(= x_1p(x_1) + x_2p(x_2) + … + x_np(x_n)\\)"
  },
  {
    "objectID": "slides/lect_07.html#price-increase-1",
    "href": "slides/lect_07.html#price-increase-1",
    "title": "Chapter 9: Random variables",
    "section": "Price increase",
    "text": "Price increase\n\n\n\n\\(x\\)\n\\(x + 5\\)\n\\(P(X) = x+5\\)\n\n\n\n\n1.23\n6.23\n0.12\n\n\n1.29\n6.29\n0.20\n\n\n1.37\n6.37\n0.16\n\n\n1.84\n6.84\n0.04\n\n\n1.18\n6.18\n0.24\n\n\n1.22\n6.22\n0.08\n\n\n1.25\n6.25\n0.16"
  },
  {
    "objectID": "slides/lect_07.html#price-increase-2",
    "href": "slides/lect_07.html#price-increase-2",
    "title": "Chapter 9: Random variables",
    "section": "Price increase",
    "text": "Price increase"
  },
  {
    "objectID": "slides/lect_07.html#stock-splits-1",
    "href": "slides/lect_07.html#stock-splits-1",
    "title": "Chapter 9: Random variables",
    "section": "Stock splits",
    "text": "Stock splits\n\n\n\n\\(x\\)\n\\(3x\\)\n\\(P(X) = x\\)\n\n\n\n\n1.23\n3.68\n0.12\n\n\n1.29\n3.87\n0.20\n\n\n1.37\n4.11\n0.16\n\n\n1.84\n5.52\n0.04\n\n\n1.18\n3.54\n0.24\n\n\n1.22\n3.66\n0.08\n\n\n1.25\n3.75\n0.16"
  },
  {
    "objectID": "slides/lect_07.html#stock-splits-2",
    "href": "slides/lect_07.html#stock-splits-2",
    "title": "Chapter 9: Random variables",
    "section": "Stock splits",
    "text": "Stock splits"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-professor",
    "href": "slides/lec-1.html#meet-the-professor",
    "title": "Welcome to STA 210!",
    "section": "Meet the professor",
    "text": "Meet the professor\n\n\n\n\n\nDr. Mine Çetinkaya-Rundel (she/her)\n\n\n\n\nProfessor of the Practice & Director of Undergraduate Studies, Department of Statistical Science\nAffiliated Faculty, Computational Media, Arts & Cultures\nFind out more at mine-cr.com"
  },
  {
    "objectID": "slides/lec-1.html#meet-the-tas",
    "href": "slides/lec-1.html#meet-the-tas",
    "title": "Welcome to STA 210!",
    "section": "Meet the TAs",
    "text": "Meet the TAs\n\nMartha Aboagye (she/her, UG)\nRich Fremgen (he/him, MS)\nEmily Gentles (she/her, MS)\nSara Mehta (she/her, UG)\nRick Presman (he/him, PhD)\nShari Tian (she/her, UG)\nAaditya Warrier (he/him, UG)"
  },
  {
    "objectID": "slides/lec-1.html#check-out-conversations",
    "href": "slides/lec-1.html#check-out-conversations",
    "title": "Welcome to STA 210!",
    "section": "Check out Conversations",
    "text": "Check out Conversations\n\nGo to Conversations 💬\nAnswer the discussion question: How are you doing?"
  },
  {
    "objectID": "slides/lec-1.html#what-is-regression-analysis",
    "href": "slides/lec-1.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis",
    "text": "What is regression analysis\n\n\n“In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or predictors). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or ‘criterion variable’) changes when any one of the independent variables is varied, while the other independent variables are held fixed.”\n\n\nSource: Wikipedia"
  },
  {
    "objectID": "slides/lec-1.html#course-faq",
    "href": "slides/lec-1.html#course-faq",
    "title": "Welcome to STA 210!",
    "section": "Course FAQ",
    "text": "Course FAQ\n\n\nWhat background is assumed for the course? Introductory statistics or probability course.\nWill we be doing computing? Yes. We will use R.\nWill we learn the mathematical theory of regression? Yes and No. The course is primarily focused on application; however, we will discuss some of the mathematics of simple linear regression. The 1-credit course STA 211: Mathematics of Regression you can take simultaneously / after dives into more of the mathematics."
  },
  {
    "objectID": "slides/lec-1.html#course-learning-objectives",
    "href": "slides/lec-1.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\n\nAnalyze real-world data to answer questions about multivariable relationships.\nFit and evaluate linear and logistic regression models.\nAssess whether a proposed model is appropriate and describe its limitations.\nUse Quarto to write reproducible reports and GitHub for version control and collaboration.\nCommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "slides/lec-1.html#examples-of-regression-in-practice",
    "href": "slides/lec-1.html#examples-of-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Examples of regression in practice",
    "text": "Examples of regression in practice\n\n\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\nHow FiveThirtyEight’s 2020 Presidential Forecast Works — And What’s Different Because Of COVID-19\nEffect of Forensic Evidence on Criminal Justice Case Processing\nWhy it’s so freaking hard to make a good COVID-19 model"
  },
  {
    "objectID": "slides/lec-1.html#homepage",
    "href": "slides/lec-1.html#homepage",
    "title": "Welcome to STA 210!",
    "section": "Homepage",
    "text": "Homepage\nsta210-s22.github.io/website\n\nAll course materials\nLinks to Sakai, GitHub, RStudio containers, etc.\nLet’s take a tour!"
  },
  {
    "objectID": "slides/lec-1.html#course-toolkit",
    "href": "slides/lec-1.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta210-s22\nRStudio containers: cmgr.oit.duke.edu/containers\nDiscussion forum: Conversations\nAssignment submission and feedback: Gradescope\n\n\n\n\n\n\n\nImportant\n\n\nReserve an RStudio Container (titled STA 210) before lab on Monday!"
  },
  {
    "objectID": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "href": "slides/lec-1.html#activities-prepare-participate-practice-perform",
    "title": "Welcome to STA 210!",
    "section": "Activities: Prepare, Participate, Practice, Perform",
    "text": "Activities: Prepare, Participate, Practice, Perform\n\nPrepare: Introduce new content and prepare for lectures by completing the readings (and sometimes watching the videos)\nParticipate: Attend and actively participate in lectures and labs, office hours, team meetings\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what you’ve learned to analyze real-world data\n\nLab assignments x 7 (first individual, later team-based)\nHomework assignments x 5 (individual)\nThree take-home exams\nTerm project presented during the final exam period"
  },
  {
    "objectID": "slides/lec-1.html#cadence",
    "href": "slides/lec-1.html#cadence",
    "title": "Welcome to STA 210!",
    "section": "Cadence",
    "text": "Cadence\n\n\nLabs: Start and make large progress on Monday in lab section, finish up by Friday 5pm of that week\nHWs: Posted Friday morning, due following Friday 5pm\nExams: Exam review Thursday in class, exam posted Friday morning, no lab on Monday of following week, due Monday 11:59pm\nProject: Deadlines throughout the semester, with some lab and lecture time dedicated to working on them, and most work done in teams outside of class"
  },
  {
    "objectID": "slides/lec-1.html#teams",
    "href": "slides/lec-1.html#teams",
    "title": "Welcome to STA 210!",
    "section": "Teams",
    "text": "Teams\n\nTeam assignments\n\nAssigned by me\nApplication exercises, labs, and project\nPeer evaluation during teamwork and after completion\n\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/lec-1.html#grading",
    "href": "slides/lec-1.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n3%\n\n\nHomework\n35% (7% x 5)\n\n\nProject\n15%\n\n\nLab\n14% (2% x 7)\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n3%\n\n\n\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/lec-1.html#support",
    "href": "slides/lec-1.html#support",
    "title": "Welcome to STA 210!",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions on the discussion forum\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/lec-1.html#announcements",
    "href": "slides/lec-1.html#announcements",
    "title": "Welcome to STA 210!",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Sakai (Announcements tool) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/lec-1.html#diversity-inclusion",
    "href": "slides/lec-1.html#diversity-inclusion",
    "title": "Welcome to STA 210!",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know!\nPlease let me know your preferred pronouns. You’ll also be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/lec-1.html#accessibility",
    "href": "slides/lec-1.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/lec-1.html#covid-policies",
    "href": "slides/lec-1.html#covid-policies",
    "title": "Welcome to STA 210!",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask at all times!\nRead and follow university guidance"
  },
  {
    "objectID": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "href": "slides/lec-1.html#late-work-waivers-regrades-policy",
    "title": "Welcome to STA 210!",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/lec-1.html#collaboration-policy",
    "href": "slides/lec-1.html#collaboration-policy",
    "title": "Welcome to STA 210!",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/lec-1.html#sharing-reusing-code-policy",
    "href": "slides/lec-1.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 210!",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/lec-1.html#academic-integrity",
    "href": "slides/lec-1.html#academic-integrity",
    "title": "Welcome to STA 210!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/lec-1.html#most-importantly",
    "href": "slides/lec-1.html#most-importantly",
    "title": "Welcome to STA 210!",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "slides/lec-1.html#five-tips-for-success",
    "href": "slides/lec-1.html#five-tips-for-success",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings.\nDo the homework and lab.\nDon’t procrastinate and don’t let a week pass by with lingering questions."
  },
  {
    "objectID": "slides/lec-1.html#learning-during-a-pandemic",
    "href": "slides/lec-1.html#learning-during-a-pandemic",
    "title": "Welcome to STA 210!",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis."
  },
  {
    "objectID": "slides/lec-1.html#this-weeks-tasks",
    "href": "slides/lec-1.html#this-weeks-tasks",
    "title": "Welcome to STA 210!",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nGet a GitHub account if you don’t have one (some advice for choosing a username here)\nComplete the Getting to know you survey if you haven’t yet done so!\nRead the syllabus\nWatch out for next week’s announcement email, in your inbox sometime tomorrow"
  },
  {
    "objectID": "slides/lec-1.html#midori-says",
    "href": "slides/lec-1.html#midori-says",
    "title": "Welcome to STA 210!",
    "section": "Midori says…",
    "text": "Midori says…"
  },
  {
    "objectID": "slides/lect_03.html#definition-of-categorical-variable",
    "href": "slides/lect_03.html#definition-of-categorical-variable",
    "title": "Lec 3 - Exploring categorical data",
    "section": "Definition of categorical variable",
    "text": "Definition of categorical variable\nA categorical or qualitative variable is a variable that can not be measured. They are descriptors or grouping factors."
  },
  {
    "objectID": "slides/lect_03.html#the-purpose-of-exploring-categorical-variables",
    "href": "slides/lect_03.html#the-purpose-of-exploring-categorical-variables",
    "title": "Lec 3 - Exploring categorical data",
    "section": "The purpose of exploring categorical variables",
    "text": "The purpose of exploring categorical variables\n\nExploratory Data Analysis is about learning the structure of a dataset through a series of numerical and graphical techniques.\nWhen you do EDA, you’ll look for both\n\ngeneral trends and\ninteresting outliers in your data.\n\n\ngenerate questions that will help inform subsequent analysis."
  },
  {
    "objectID": "slides/lect_10.html#ebernoulli",
    "href": "slides/lect_10.html#ebernoulli",
    "title": "Chapter 11: Probability models for counts",
    "section": "E(Bernoulli)",
    "text": "E(Bernoulli)\n\n\n\\(E(B) = 0 \\cdot P(B=0) + 1 \\cdot P(B=1)\\)\n\\[\\begin{aligned}\nE(B) &= 0 \\cdot P(B=0) + 1 \\cdot P(B=1)\\\\\n&= 0 \\cdot (1-p) + 1 \\cdot p\\\\\n&= p\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#varbernoulli",
    "href": "slides/lect_10.html#varbernoulli",
    "title": "Chapter 11: Probability models for counts",
    "section": "Var(Bernoulli)",
    "text": "Var(Bernoulli)\n\nWe usually don’t want this information about 1 person, we want it about a whole plane full of people, or a whole town.\nIn that case, we sum together \\(n\\) independent Bernoulli trials.\n\n\n\n\\(Var(B) = (0 - p)^2 \\cdot P(B=0) + (1 - p)^2 \\cdot P(B=1)\\)\n\\[\\begin{aligned}\nVar(B) &= (0 - p)^2 \\cdot P(B=0) + (1 - p)^2 \\cdot P(B=1)\\\\\n&= p^2 \\cdot (1-p) + (1 - p)^2 \\cdot p\\\\\n&= p^2 - p^3 + p(1 - 2p + p^2) \\\\\n&= p^2 - p^3 + p - 2p^2 + p^3\\\\\n&= p(1-p)\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#multiple-bernoulli-trials",
    "href": "slides/lect_10.html#multiple-bernoulli-trials",
    "title": "Chapter 11: Probability models for counts",
    "section": "Multiple Bernoulli trials",
    "text": "Multiple Bernoulli trials\n\nThis happens so often that we have another name for this distribution\n\n\\[Y = B_1 + B_2 + ...  + B_n\\]\n\n\n\\(Y\\) is the sum of independent and identically distributed random variables\nWhat is the mean and variance?"
  },
  {
    "objectID": "slides/lect_10.html#ebinomial",
    "href": "slides/lect_10.html#ebinomial",
    "title": "Chapter 11: Probability models for counts",
    "section": "E(Binomial)",
    "text": "E(Binomial)\n\\[E(Y) = E(B_1 + B_2 + ... + B_n)\\]\n\n\n\\[\\begin{aligned}\nE(Y) &= E(B_1) + E(B_2) + ... + E(B_n) \\\\\n&= p + p + ... + p \\\\\n&= np\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#varbinomial",
    "href": "slides/lect_10.html#varbinomial",
    "title": "Chapter 11: Probability models for counts",
    "section": "Var(Binomial)",
    "text": "Var(Binomial)\n\nthere are multiple ways that we can have 5 successes, so we must also learn to count\n\n\\[Var(Y) = Var(B_1 + B_2 + ... + B_n)\\]\n\n\n\\[\\begin{aligned}\nVar(Y) &= Var(B_1) + Var(B_2) + ... + Var(B_n) \\\\\n&= p(1-p) + p(1-p) + ... + p(1-p) \\\\\n&= np(1-p)\n\\end{aligned}\\]\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#counting-things",
    "href": "slides/lect_10.html#counting-things",
    "title": "Chapter 11: Probability models for counts",
    "section": "Counting things",
    "text": "Counting things\n\nwe just went into groups how many groups are possible?\n\nIn a class of 85 students how many groups of 4 are possible?\n\n\n\\(85 \\cdot 84 \\cdot 83 \\cdot 82\\)\n\\(48,594,840\\) groups\nIf we don’t care about order\n\\(\\frac{85 \\cdot 84 \\cdot 83 \\cdot 82}{4 \\cdot 3 \\cdot 2 \\cdot 1}\\)\n\\(2,024,785\\) groups\nCombination written as \\({}_{n}C_{k}\\) here \\(n = 85\\), \\(k = 4\\) or \\(\\binom{85}{4}\\)\n\n\n\nexp(lfactorial(85))/exp(lfactorial(81))\n\n[1] 48594840\n\nexp(lfactorial(85))/(exp(lfactorial(81))*exp(lfactorial(4)))\n\n[1] 2024785"
  },
  {
    "objectID": "slides/lect_10.html#binomial-pdf",
    "href": "slides/lect_10.html#binomial-pdf",
    "title": "Chapter 11: Probability models for counts",
    "section": "Binomial pdf",
    "text": "Binomial pdf\nIf \\(Y \\sim Bin(n, p)\\) where\n\n$n = $ number of trials\n$p = $ probability of success\n$y = $ number of successes in \\(n\\) Bernoulli trials\n\n\nthen  \\[P(Y = y) = \\binom{n}{y}p^y(1-p)^{n-y}\\]"
  },
  {
    "objectID": "slides/lect_10.html#example",
    "href": "slides/lect_10.html#example",
    "title": "Chapter 11: Probability models for counts",
    "section": "Example",
    "text": "Example\n\n\nLet \\(Y \\sim Bin(n = 5, p = 0.2)\\) find the \\(E(Y)\\) and \\(Var(Y)\\)\n\n\n\n\\(E(Y) = np = 1\\)\n\\(Var(Y) = np(1-p) = 0.8\\)\nWhat is the probability that \\(y = 3\\)? In R: dbinom(size  = 5, prob = 0.2, x = 3) \\(0.0512\\)\n\n\n\n\n\n02:00"
  },
  {
    "objectID": "slides/lect_10.html#warnings",
    "href": "slides/lect_10.html#warnings",
    "title": "Chapter 11: Probability models for counts",
    "section": "Warnings",
    "text": "Warnings\n10% Condition: if trials are selected at random, it is OK to ignore dependence caused by sampling from a finite population if the selected trials make up less than 10% of the population"
  },
  {
    "objectID": "slides/lect_10.html#limit---mins",
    "href": "slides/lect_10.html#limit---mins",
    "title": "Chapter 11: Probability models for counts",
    "section": "Limit - mins",
    "text": "Limit - mins\n\nsome of these cars may come by in the same minute..\n\nI know about 7 cars drive by my house in an hour, what’s the probability 18 cars drive by in the next 60 mins?\n\n\n\\(p = \\frac{7}{60}\\)\n\\(Y \\sim Bin(60, \\frac{7}{60})\\)\n\\(\\binom{60}{18}p^{18}(1-p)^{42}\\)"
  },
  {
    "objectID": "slides/lect_10.html#limit---secs",
    "href": "slides/lect_10.html#limit---secs",
    "title": "Chapter 11: Probability models for counts",
    "section": "Limit - secs",
    "text": "Limit - secs\nI know about 7 cars drive by my house in an hour, what’s the probability 18 cars drive by in the next 3600 secs?\n\n\n\\(p = \\frac{7}{3600}\\)\n\\(Y \\sim Bin(3600, \\frac{7}{3600})\\)\n\\(\\binom{3600}{18}p^{18}(1-p)^{3582}\\)"
  },
  {
    "objectID": "slides/lect_10.html#limit---smallest-interval",
    "href": "slides/lect_10.html#limit---smallest-interval",
    "title": "Chapter 11: Probability models for counts",
    "section": "Limit - smallest interval",
    "text": "Limit - smallest interval\nI know about 7 cars drive by my house in an hour, what’s the probability 18 cars drive by in the next much smaller than a second? Full derivation can be found here.\n\n\n\n\n\\(\\binom{n}{18}(\\frac{7}{n})^{18}(1-\\frac{7}{n})^{n-18}\\)\n\\(\\frac{n\\cdot(n-1)\\ldots(n-17)}{18!}\\cdot \\frac{7^{18}}{n^{18}}\\cdot (1-\\frac{7}{n})^{n} \\cdot \\frac{1}{(1-\\frac{7}{n})^{18}}\\)\n\\(\\frac{n\\cdot(n-1)\\ldots(n-17)}{n^{18}} \\rightarrow 1\\)\n\\(\\frac{1}{(1-\\frac{7}{n})^{18}} \\rightarrow 1\\)\n\n\n\n\n\\(\\frac{7^{18}}{18!}e^{-7}\\)"
  },
  {
    "objectID": "slides/lect_10.html#poisson-distribution---rips",
    "href": "slides/lect_10.html#poisson-distribution---rips",
    "title": "Chapter 11: Probability models for counts",
    "section": "Poisson distribution - RIPS",
    "text": "Poisson distribution - RIPS\n\n\nPoisson - fish - Rips\nR - randomly through space or time\nI - indepedent\nP - proportional to interval size\nS - singly - no multiple occurences in space or time"
  },
  {
    "objectID": "slides/lect_10.html#epois",
    "href": "slides/lect_10.html#epois",
    "title": "Chapter 11: Probability models for counts",
    "section": "E(Pois)",
    "text": "E(Pois)\n\n\\(\\lambda\\)"
  },
  {
    "objectID": "slides/lect_10.html#varpois",
    "href": "slides/lect_10.html#varpois",
    "title": "Chapter 11: Probability models for counts",
    "section": "Var(Pois)",
    "text": "Var(Pois)\n\n\\(\\lambda\\)"
  },
  {
    "objectID": "slides/lect_10.html#example-1",
    "href": "slides/lect_10.html#example-1",
    "title": "Chapter 11: Probability models for counts",
    "section": "Example",
    "text": "Example\n\n\nLet \\(Y \\sim Pois(\\lambda = 5)\\) find the \\(E(Y)\\) and \\(Var(Y)\\)\n\n\n\n\\(E(Y) = 5\\)\n\\(Var(Y) = 5\\)\nWhat is the probability that \\(y = 3\\)? In R: dpois(x = 3, lambda = 5) \\(0.1403739\\)\n\n\n\n\n\n02:00\n\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/01_introduction.html#workspace-image",
    "href": "slides/01_introduction.html#workspace-image",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Workspace image",
    "text": "Workspace image\n\nSaving workspace"
  },
  {
    "objectID": "slides/01_introduction.html#rainbow-parenthesis",
    "href": "slides/01_introduction.html#rainbow-parenthesis",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Rainbow parenthesis",
    "text": "Rainbow parenthesis\n\nParenthesis are important"
  },
  {
    "objectID": "slides/01_introduction.html#code-font",
    "href": "slides/01_introduction.html#code-font",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Code font",
    "text": "Code font\n\nUpdate background and font color of code"
  },
  {
    "objectID": "slides/01_introduction.html#pane-layout",
    "href": "slides/01_introduction.html#pane-layout",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Pane layout",
    "text": "Pane layout\n\nUpdate panes and their layout"
  },
  {
    "objectID": "slides/01_introduction.html#new-directory",
    "href": "slides/01_introduction.html#new-directory",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "New directory",
    "text": "New directory\n\nSelect “New Directory”"
  },
  {
    "objectID": "slides/01_introduction.html#directory-type",
    "href": "slides/01_introduction.html#directory-type",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Directory type",
    "text": "Directory type\n\nThen select “New Project”"
  },
  {
    "objectID": "slides/01_introduction.html#new-folder",
    "href": "slides/01_introduction.html#new-folder",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "New folder",
    "text": "New folder\nHit the “Browse” button, then the “New Folder” button and name it “Stats1010.” All work related to this class will be in this folder, and we will create a new document for each chapter and homework.\n\nthen hit “Create project.”"
  },
  {
    "objectID": "slides/01_introduction.html#name-the-document",
    "href": "slides/01_introduction.html#name-the-document",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Name the document",
    "text": "Name the document\nName the document “lec_01” and hit create\n\nNaming the document"
  },
  {
    "objectID": "slides/01_introduction.html#insert-an-r-code-chuck",
    "href": "slides/01_introduction.html#insert-an-r-code-chuck",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Insert an R code chuck",
    "text": "Insert an R code chuck\nInsert a code chunk\n\nInsert code chunk"
  },
  {
    "objectID": "slides/01_introduction.html#write-your-first-line-of-coding",
    "href": "slides/01_introduction.html#write-your-first-line-of-coding",
    "title": "Lec 1 - Downloading R and plot your first graph",
    "section": "Write your first line of coding",
    "text": "Write your first line of coding\nClick here or the qr code below to write your first line of code\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_09.html#compute-the-sharpe-ratio",
    "href": "slides/lect_09.html#compute-the-sharpe-ratio",
    "title": "Chapter 10: Association between random variables",
    "section": "Compute the Sharpe ratio",
    "text": "Compute the Sharpe ratio\n\nhave them go back to the previous slide and see what they got\n\n\n\n\nCompany\nRandom Variable\nMean per month\nSD\n\n\n\n\nApple\nA\n2.45%\n13.3%\n\n\nMcDonalds\nM\n1.14%\n6.2%\n\n\n\nassume \\(r_f\\) is the risk-free rate of interest is \\(0.1\\%\\)"
  },
  {
    "objectID": "slides/lect_09.html#compute-the-sharpe-ratio-1",
    "href": "slides/lect_09.html#compute-the-sharpe-ratio-1",
    "title": "Chapter 10: Association between random variables",
    "section": "Compute the Sharpe ratio",
    "text": "Compute the Sharpe ratio\n\nwork through it, then what if we don’t know mu and sigma could we find it if we had a pdf?\n\n\n\n\n\n\\[\\begin{aligned}\nS(A) &= \\frac{\\mu_A - r_f}{\\sigma_A}\\\\\n&= \\frac{2.45 - 0.1}{13.3}\\\\\n&=  0.177\n\\end{aligned}\\]\n\\[\\begin{aligned}\nS(M) &= \\frac{\\mu_M - r_f}{\\sigma_M}\\\\\n&= \\frac{1.14 - 0.1}{6.2}\\\\\n&=  0.168\n\\end{aligned}\\]\n\n\n\nWe prefer Apple because it has a higher Sharpe ratio \\(0.177 > 0.168\\)"
  },
  {
    "objectID": "slides/lect_09.html#revision-2",
    "href": "slides/lect_09.html#revision-2",
    "title": "Chapter 10: Association between random variables",
    "section": "Revision 2",
    "text": "Revision 2\n\nfind the mean, stdev, and use them to find the Sharpe ratio\nput microsoft is y on the board and IBM is x\ncopy down the means and st deviation when they get them\n\nInstead of knowing \\(\\mu\\) and \\(\\sigma\\) we have a pdf\n\n\n\n\nIBM stock\nIBM stock\nMicrosoft\nMicrosoft\n\n\n\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(y\\)\n\\(P(Y = y)\\)\n\n\nIncreases\n$5\n0.11\n$4\n0.18\n\n\nNo change\n0\n0.80\n0\n0.67\n\n\nDecreases\n-$5\n0.09\n-$4\n0.15"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-by-hand",
    "href": "slides/lect_09.html#sharpe-ratio-by-hand",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio by hand",
    "text": "Sharpe ratio by hand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIBM\nIBM\nIBM\nIBM\nIBM\nIBM\nIBM\n\n\n\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(\\mu_X\\)\n\\((x-\\mu_X)^2 \\cdot p_X(x)\\)\n\\(Var(X)\\)\n\\(sd(X)\\)\nSharpe ratio\n\n\nIncreases\n$5\n0.11\n\n\n\n\n\n\n\nNo change\n0\n0.80\n\n\n\n\n\n\n\nDecreases\n-$5\n0.09"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-by-hand-1",
    "href": "slides/lect_09.html#sharpe-ratio-by-hand-1",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio by hand",
    "text": "Sharpe ratio by hand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIBM\nIBM\nIBM\nIBM\nIBM\nIBM\nIBM\n\n\n\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(\\mu_X\\)\n\\((x-\\mu_X)^2 \\cdot p_X(x)\\)\n\\(Var(X)\\)\n\\(sd(X)\\)\nSharpe ratio\n\n\nIncreases\n$5\n0.11\n0.1\n2.6411\n4.99\n2.23\n0.03805123\n\n\nNo change\n0\n0.80\n0.1\n0.0080\n4.99\n2.23\n0.03805123\n\n\nDecreases\n-$5\n0.09\n0.1\n2.3409\n4.99\n2.23\n0.03805123"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-by-hand-2",
    "href": "slides/lect_09.html#sharpe-ratio-by-hand-2",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio by hand",
    "text": "Sharpe ratio by hand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\n\n\n\n\n\n\\(y\\)\n\\(P(Y =y)\\)\n\\(\\mu_Y\\)\n\\((y-\\mu_Y)^2 \\cdot p_Y(y)\\)\n\\(Var(Y)\\)\n\\(sd(Y)\\)\nSharpe ratio\n\n\nIncreases\n$4\n0.18\n\n\n\n\n\n\n\nNo change\n0\n0.67\n\n\n\n\n\n\n\nDecreases\n-$4\n0.15"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-by-hand-3",
    "href": "slides/lect_09.html#sharpe-ratio-by-hand-3",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio by hand",
    "text": "Sharpe ratio by hand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\nMCSFT\n\n\n\n\n\n\\(y\\)\n\\(P(Y =y)\\)\n\\(\\mu_Y\\)\n\\((y-\\mu_Y)^2 \\cdot p_Y(y)\\)\n\\(Var(Y)\\)\n\\(sd(Y)\\)\nSharpe ratio\n\n\nIncreases\n$4\n0.18\n0.12\n2.709792\n5.2656\n2.29469\n0.04575782\n\n\nNo change\n0\n0.67\n0.12\n0.009648\n5.2656\n2.29469\n0.04575782\n\n\nDecreases\n-$4\n0.15\n0.12\n2.546160\n5.2656\n2.29469\n0.04575782"
  },
  {
    "objectID": "slides/lect_09.html#the-sharpe-ratio---in-r",
    "href": "slides/lect_09.html#the-sharpe-ratio---in-r",
    "title": "Chapter 10: Association between random variables",
    "section": "The Sharpe ratio - in R",
    "text": "The Sharpe ratio - in R\n\nCan an investor do better by diversifing the investment?\n\n\n# Input the data and the pdf\nstock <- tibble(x = c(5, 0, -5), \n                p_x = c(0.11, 0.8, 0.09), \n                y = c(4, 0, -4), \n                p_y = c(.18, .67, .15))\n\n\nSharpe_ratio <- # name this the Sharpe ratio\n  stock %>% # use the data from above\n  mutate(part_mean_x = x*p_x, # find mean for each part of x \n         part_mean_y = y*p_y, # now for y\n         mean_x = sum(part_mean_x), # find mean x \n         mean_y = sum(part_mean_y),# now for y\n         part_var_x = p_x * (mean_x - x)^2, # find var for each part of x \n         part_var_y = p_y * (mean_y - y)^2,# now for y\n         var_x = sum(part_var_x), # find var of x \n         var_y = sum(part_var_y),# now for y\n         sd_x = sqrt(var_x), # find sd of x \n         sd_y = sqrt(var_y)) %>% # now for y\n  summarise(S_x = (mean_x - 0.015)/sd_x, # find Sharpe ratio of x with rf = 0.015\n            S_y = (mean_y - 0.015)/sd_y) %>% # now for y\n  slice(1)"
  },
  {
    "objectID": "slides/lect_09.html#expected-value-of-x-y",
    "href": "slides/lect_09.html#expected-value-of-x-y",
    "title": "Chapter 10: Association between random variables",
    "section": "Expected value of \\(X + Y\\)",
    "text": "Expected value of \\(X + Y\\)\n\nIf x=-5 then we subtract 5 from all y’s and multiply by \\(p_{x, y}\\) algebraically it all washes out\nWhat about independence? We want to find the standard deviation to compute the Sharpe Ratio\n\n\n\n\n\n\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\n\n\n\n\n\\(x = -5\\)\n\\(x = 0\\)\n\\(x = 5\\)\n\\(p(y)\\)\n\n\n\\(Y\\)\n\\(y=4\\)\n\\(0.00\\)\n\\(0.11\\)\n\\(0.07\\)\n\\(0.18\\)\n\n\n\\(Y\\)\n\\(y=0\\)\n\\(0.03\\)\n\\(0.62\\)\n\\(0.02\\)\n\\(0.67\\)\n\n\n\\(Y\\)\n\\(y=-4\\)\n\\(0.06\\)\n\\(0.07\\)\n\\(0.02\\)\n\\(0.15\\)\n\n\n\n\\(p(x)\\)\n\\(0.09\\)\n\\(0.80\\)\n\\(0.11\\)\n\\(1\\)\n\n\n\n\n\n\\(E(X+Y) = E(X) + E(Y)\\)\n\\(E(X+Y) = E(X) + E(Y) = 0.1 + 0.12 = 0.22\\)"
  },
  {
    "objectID": "slides/lect_09.html#are-x-and-y-independent",
    "href": "slides/lect_09.html#are-x-and-y-independent",
    "title": "Chapter 10: Association between random variables",
    "section": "Are \\(X\\) and \\(Y\\) independent?",
    "text": "Are \\(X\\) and \\(Y\\) independent?\n\nfind any p(x) X p(y) != p(x,y)\nBut we still need to find the stdev in order to find Sharpes ratio\n\n\n\n\n\n\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\n\n\n\n\n\\(x = -5\\)\n\\(x = 0\\)\n\\(x = 5\\)\n\\(p(y)\\)\n\n\n\\(Y\\)\n\\(y=4\\)\n\\(0.00\\)\n\\(0.11\\)\n\\(0.07\\)\n\\(0.18\\)\n\n\n\\(Y\\)\n\\(y=0\\)\n\\(0.03\\)\n\\(0.62\\)\n\\(0.02\\)\n\\(0.67\\)\n\n\n\\(Y\\)\n\\(y=-4\\)\n\\(0.06\\)\n\\(0.07\\)\n\\(0.02\\)\n\\(0.15\\)\n\n\n\n\\(p(x)\\)\n\\(0.09\\)\n\\(0.80\\)\n\\(0.11\\)\n\\(1\\)\n\n\n\n\n\n\\(p_x(-5) \\cdot p_y(4) = 0.18 \\cdot 0.09 \\neq 0.00\\)\n\\(p_x(-5) \\cdot p_y(-4) = 0.09 \\cdot 0.15 = 0.0135 \\neq 0.06\\)\nNO! NO! NO!"
  },
  {
    "objectID": "slides/lect_09.html#covariance-of-sum",
    "href": "slides/lect_09.html#covariance-of-sum",
    "title": "Chapter 10: Association between random variables",
    "section": "Covariance of sum",
    "text": "Covariance of sum\n\nbecause we square things and \\((a + b)^2 = a^2 + b^2 + 2ab\\) we have to add 2 of the covariance\n\n\n\n\\((a+b)^2 = a^2 + 2ab +b^2\\)\nit follows that\n\\(Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y)\\)"
  },
  {
    "objectID": "slides/lect_09.html#correlation",
    "href": "slides/lect_09.html#correlation",
    "title": "Chapter 10: Association between random variables",
    "section": "Correlation",
    "text": "Correlation\n\nwhat about our joint pdf? is it positively or negatively correlated? 3D plot\n\n\n\n\\(corr(x, y) = \\frac{cov(x, y)}{s_x \\cdot s_y}\\)\n\\[\\rho = Corr(X, Y) = \\frac{Cov(X, Y)}{\\sigma_X \\cdot \\sigma_Y}\\]\n\nAs \\(X\\) increases, what happens to \\(Y\\)?\n\n\n\n\n\n\n\n\\(X\\)\n\\(X\\)\n\\(X\\)\n\n\n\n\n\n\n\n\\(x = -5\\)\n\\(x = 0\\)\n\\(x = 5\\)\n\\(p(y)\\)\n\n\n\\(Y\\)\n\\(y=4\\)\n\\(0.00\\)\n\\(0.11\\)\n\\(0.07\\)\n\\(0.18\\)\n\n\n\\(Y\\)\n\\(y=0\\)\n\\(0.03\\)\n\\(0.62\\)\n\\(0.02\\)\n\\(0.67\\)\n\n\n\\(Y\\)\n\\(y=-4\\)\n\\(0.06\\)\n\\(0.07\\)\n\\(0.02\\)\n\\(0.15\\)\n\n\n\n\\(p(x)\\)\n\\(0.09\\)\n\\(0.80\\)\n\\(0.11\\)\n\\(1\\)"
  },
  {
    "objectID": "slides/lect_09.html#independence-cov",
    "href": "slides/lect_09.html#independence-cov",
    "title": "Chapter 10: Association between random variables",
    "section": "Independence & Cov",
    "text": "Independence & Cov\nHow does independence impact upon correlation and covariance?\n\\[ E((X-\\mu_X)(Y-\\mu_Y))\\]\n\n\n\\[\\begin{aligned}\nCov(X,Y) &= E((X-\\mu_X)(Y-\\mu_Y))\\\\\n&= E(X - \\mu_X)E(Y-\\mu_Y)\\\\\n&= 0\n\\end{aligned}\\]\nIf \\(X\\),\\(Y\\) are independent, then \\(Cov(X, Y) = 0\\)\nThe opposite is not true (if \\(Cov(X, Y) = 0\\), then \\(X\\),\\(Y\\) are independent)"
  },
  {
    "objectID": "slides/lect_09.html#independence-var",
    "href": "slides/lect_09.html#independence-var",
    "title": "Chapter 10: Association between random variables",
    "section": "Independence & Var",
    "text": "Independence & Var\n\\(Var(X) + Var(Y) = Var(X) + Var(Y) + 2Cov(X, Y)\\)\n\n\nIf \\(X\\), \\(Y\\) are independent, \\(Cov(X, Y) = 0\\), so\n\\[Var(X+ Y) = Var(X) + Var(Y)\\]"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-of-a-sum",
    "href": "slides/lect_09.html#sharpe-ratio-of-a-sum",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio of a sum",
    "text": "Sharpe ratio of a sum\n\\[ S(X + Y) = \\frac{(\\mu_X + \\mu_Y) - 2r_f}{\\sqrt{(Var(X+Y))}} \\]"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio-of-sum---r",
    "href": "slides/lect_09.html#sharpe-ratio-of-sum---r",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio of sum - R",
    "text": "Sharpe ratio of sum - R\n\nWhat if we want to invest in two subsequent days instead of investing in two stocks for 1 day?\n\n\n# input x & y\nx <- c(-5, 0, 5)\ny <- c(4, 0, -4)\n\n# input data\ndata <- bind_cols(expand_grid(x, y), \n                  probs = c(0, .03, .06, \n                            .11, .62, .07, \n                            .07, .02, .02), \n                  mu_x = rep(0.1, 9), \n                  mu_y = rep(0.12, 9), \n                  var_x = rep(4.99, 9), \n                  var_y = rep(5.2656, 9))\n\ndata %>% \n  mutate(cov_xy_part = (x - mu_x)*\n           (y - mu_y)*probs, # multiply together\n         cov_xy = sum(cov_xy_part), # sum them\n         var_xy = var_x + var_y + 2*cov_xy) %>% # using the rule\n  summarise(S_r = (mu_x + mu_y - 2*0.015)/\n                      (sqrt(var_xy))) %>% # find the Sharpe value\n  slice(1) # only the first\n\n# A tibble: 1 × 1\n     S_r\n   <dbl>\n1 0.0497\n\n\n\n\nThe Sharpe ratio for \\(X\\) is \\(0.038\\), for \\(Y\\) it’s \\(0.046\\), investing in both gives a better return \\(0.050\\)"
  },
  {
    "objectID": "slides/lect_09.html#double-for-one-day",
    "href": "slides/lect_09.html#double-for-one-day",
    "title": "Chapter 10: Association between random variables",
    "section": "Double for one day",
    "text": "Double for one day\n\\[S(2X) = \\frac{2\\mu_X - 2r_f}{\\sqrt{Var(2X)}}\\]\n\n\n\\(\\mu_X = 0.1\\)\n\\(Var(X) = 4.99\\)\n\\(r_f = .015\\)\n\\[\\begin{aligned}\n  &= \\frac{2 \\cdot 0.1 - 2 \\cdot 0.015}{\\sqrt{4 \\cdot 4.99}}\\\\\n  &= \\frac{.2 - 0.03}{\\sqrt{19.96}}\\\\\n  &= 0.038\n  \\end{aligned}\\]\nThis is the same as before, how do we compute if we invest for two subsequent days?"
  },
  {
    "objectID": "slides/lect_09.html#iid",
    "href": "slides/lect_09.html#iid",
    "title": "Chapter 10: Association between random variables",
    "section": "IID",
    "text": "IID\nIf we invested in a stock on 2 subsequent days instead of investing in 2 stocks on one day the return on those two days are:\nindependent and identically distributed (IID)\n\n\nidentically distributed - the outcomes on each day are likely to be different, but the probability of the outcomes is the same\nindependent - very common assumption for stocks (part of the reason for the 2008 financial crises)"
  },
  {
    "objectID": "slides/lect_09.html#addition-rules-for-iid-variables",
    "href": "slides/lect_09.html#addition-rules-for-iid-variables",
    "title": "Chapter 10: Association between random variables",
    "section": "Addition rules for IID variables",
    "text": "Addition rules for IID variables\n\n\n\n\n\n\nImportant\n\n\nIf \\(n\\) random variables \\((X_1, X_2, ..., X_n)\\) are iid with mean \\(\\mu_X\\) and standard deviation \\(\\sigma_X\\), then\n\\[ E(X_1 + X_2 + ... + X_n) = n \\cdot \\mu_X \\] \\[ Var(X_1 + X_2 + ... + X_n) = n \\cdot \\sigma^2_x \\] \\[ SD(X_1 + X_2 + ... + X_n) = \\sqrt{n} \\sigma_X \\]"
  },
  {
    "objectID": "slides/lect_09.html#sharpe-ratio---two-days",
    "href": "slides/lect_09.html#sharpe-ratio---two-days",
    "title": "Chapter 10: Association between random variables",
    "section": "Sharpe ratio - two days",
    "text": "Sharpe ratio - two days\n\nif you decide to leave money in the bank, you may end up with a constant\n\n\\[ S(X_1 + X_2) = \\frac{2\\mu_X - 2r_f}{\\sqrt{2 \\sigma^2_x}}\\]\n\n\n\\[\\begin{aligned}\n&= \\frac{0.20 - 0.03}{\\sqrt{9.98}}\\\\\n&= 0.054\n\\end{aligned}\\]\nyou expect more variance if you have two stock for one day b/c anything that happens that day is magnified\nif you have one stock for two days you reduce the variance"
  },
  {
    "objectID": "slides/lect_09.html#expectation-of-weighted-sum",
    "href": "slides/lect_09.html#expectation-of-weighted-sum",
    "title": "Chapter 10: Association between random variables",
    "section": "Expectation of weighted sum",
    "text": "Expectation of weighted sum\n\\[ E(2X + 4Y + 0.06)\\]\n\n\n\n\\[\\begin{aligned}\n&= 2E(X) + 4E(Y) + 0.06\\\\\n&= 2(0.10) + 4(0.12) + 0.06\\\\\n&= \\$0.74\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_09.html#variance-of-weighted-sum",
    "href": "slides/lect_09.html#variance-of-weighted-sum",
    "title": "Chapter 10: Association between random variables",
    "section": "Variance of weighted sum",
    "text": "Variance of weighted sum\n\\[ Var(2X + 4Y + 0.06)\\]\n\n\n\\[\\begin{aligned}\n&= 2^2Var(X) + 4^2Var(Y) + 2 \\cdot(2 \\cdot 4) \\cdot Cov(X,Y)\\\\\n&= 4(4.99) + 16(5.27) + 16(2.19)\\\\\n&= 139.32\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_04.html#definition-of-numeric-variable",
    "href": "slides/lect_04.html#definition-of-numeric-variable",
    "title": "Lec 4 - Exploring numeric data",
    "section": "Definition of numeric variable",
    "text": "Definition of numeric variable\nA numeric or quantitative variable is a variable that can be measured."
  },
  {
    "objectID": "slides/lect_04.html#the-purpose-of-exploratory-data-analysis-eda",
    "href": "slides/lect_04.html#the-purpose-of-exploratory-data-analysis-eda",
    "title": "Lec 4 - Exploring numeric data",
    "section": "The purpose of Exploratory Data Analysis (EDA)",
    "text": "The purpose of Exploratory Data Analysis (EDA)\n\nEDA is about learning the structure of a dataset through a series of numerical and graphical techniques.\nWhen you do EDA, you’ll look for both\n\ngeneral trends and\ninteresting outliers in your data.\n\n\ngenerate questions that will help inform subsequent analysis."
  },
  {
    "objectID": "slides/here_lecture.html#why",
    "href": "slides/here_lecture.html#why",
    "title": "Here lecture",
    "section": "Why?",
    "text": "Why?\nToday we will explore the here package. This package is used to organize files within R:\n\ninstall.packages(\"here\")"
  },
  {
    "objectID": "slides/here_lecture.html#including-your-own-data",
    "href": "slides/here_lecture.html#including-your-own-data",
    "title": "Here lecture",
    "section": "Including your own data",
    "text": "Including your own data\nTo add data to your directory, first create a folder that\n\nFigure @ref(fig:3) Adding a folder.and name it “data”. All data related to this chapter should be contained in this folder. In your file management system place your data in this folder. Then in the “Files” menu double-click on the dataset that you would like to import into R."
  },
  {
    "objectID": "slides/here_lecture.html#importing-data",
    "href": "slides/here_lecture.html#importing-data",
    "title": "Here lecture",
    "section": "Importing data",
    "text": "Importing data\n\n\n\nDouble click on the data you would like to install in the data folder in your project and select “Import Dataset.”\n\n\nIf this is the first time you are importing data, you may be prompted to download a package first. Follow the Graphical User Interface (GUI) to import the data. Check that the data is as you expect and update “Import Options” until it seems reasonable. Copy the coding from “Code Preview” and save put it in your document “so that when you restart R, you have coding that will import the data.\n\n\n\nWhen the data is imported, check the “Data Preview” to make sure it is what you expect. If not, change the “Import Options.”\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "slides/lect_11.html#binomial---normal",
    "href": "slides/lect_11.html#binomial---normal",
    "title": "Chapter 12: The normal probability model",
    "section": "Binomial -> Normal",
    "text": "Binomial -> Normal\nAs the number of trials increases, the binomial pdf becomes well approximated by a normal distribution.\n“Observed data often represent the accumulation of many small factors.”"
  },
  {
    "objectID": "slides/lect_11.html#central-limit-theorem",
    "href": "slides/lect_11.html#central-limit-theorem",
    "title": "Chapter 12: The normal probability model",
    "section": "Central limit theorem",
    "text": "Central limit theorem\n\nThere are multiple versions of the CLT\n\nThe probability distribution of a sum of independent random variables of comparable variance approaches a normal distribution as the number of summed random variables increases."
  },
  {
    "objectID": "slides/lect_11.html#shifts-scales",
    "href": "slides/lect_11.html#shifts-scales",
    "title": "Chapter 12: The normal probability model",
    "section": "Shifts & scales",
    "text": "Shifts & scales"
  },
  {
    "objectID": "slides/lect_11.html#standardizing",
    "href": "slides/lect_11.html#standardizing",
    "title": "Chapter 12: The normal probability model",
    "section": "Standardizing",
    "text": "Standardizing\n\nBooks and tables of just normal probabilities to multiple decimal places.\n\nHistorically, it could be quite hard to find probabilities, so standardizing was important.\n\n\nuse shift and scale information from above\n\\(Z = \\frac{X-\\mu_X}{\\sigma_X}\\)\nFind \\(E(Z)\\)\n\\(E(Z) = E(\\frac{X-\\mu_X}{\\sigma_X})\\)\n\\[\\begin{aligned}\nE(Z) & = E(\\frac{X-\\mu_X}{\\sigma_X})\\\\\n& = \\frac{1}{\\sigma}E(X-\\mu_X) \\\\\n&= 0\n\\end{aligned}\\]\n\\[\\begin{aligned}\nVar(Z) & = Var(\\frac{X-\\mu_X}{\\sigma_X})\\\\\n& = \\frac{1}{\\sigma^2}Var(X-\\mu_X) \\\\\n&= \\frac{\\sigma^2}{\\sigma^2} = 1\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_11.html#standardizing-1",
    "href": "slides/lect_11.html#standardizing-1",
    "title": "Chapter 12: The normal probability model",
    "section": "Standardizing",
    "text": "Standardizing\n\n\nuse shift and scale information from above\n\\(Z = \\frac{X-\\mu_X}{\\sigma_X}\\)\nFind \\(Var(Z)\\)\n\\[\\begin{aligned}\nVar(Z) & = Var(\\frac{X-\\mu_X}{\\sigma_X})\\\\\n& = \\frac{1}{\\sigma^2}Var(X-\\mu_X) \\\\\n&= \\frac{\\sigma^2}{\\sigma^2} = 1\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/lect_11.html#example",
    "href": "slides/lect_11.html#example",
    "title": "Chapter 12: The normal probability model",
    "section": "Example",
    "text": "Example\nLet \\(Y \\sim N(\\mu_Y = 5, \\sigma_Y^2 = 4)\\), standardize the following and find the probability:\n\n\n\\(P(Y < 3)\\)\n\\[\\begin{aligned}\nP(Y < 3) &= P(\\frac{Y - \\mu_Y}{\\sigma_Y} < \\frac{3-\\mu_Y}{\\sigma_Y}) \\\\\n& = P(Z < \\frac{3-5}{2} = -1)\n\\end{aligned}\\]\npnorm(-1) \\(0.1586553\\)\npnorm(-1, mean = 5, sd = 2)"
  },
  {
    "objectID": "slides/lect_11.html#graph",
    "href": "slides/lect_11.html#graph",
    "title": "Chapter 12: The normal probability model",
    "section": "Graph",
    "text": "Graph"
  },
  {
    "objectID": "slides/lect_11.html#queen-bee",
    "href": "slides/lect_11.html#queen-bee",
    "title": "Chapter 12: The normal probability model",
    "section": "Queen Bee",
    "text": "Queen Bee\n\nTo the left, to the left, pnorm is to the left\n\nPercentiles are always to the left."
  },
  {
    "objectID": "slides/lect_11.html#example-1",
    "href": "slides/lect_11.html#example-1",
    "title": "Chapter 12: The normal probability model",
    "section": "Example",
    "text": "Example\n\nBoth of these probabilities are the same because of symmetry of the normal distribution. How does this generalize to all normal distributions?\n\nLet \\(Y \\sim N(\\mu_Y = 5, \\sigma_Y^2 = 4)\\), standardize the following and find the probability:\n\n\n\\(P(Y > 7)\\)\n\n\n\\[\\begin{aligned}\nP(Y > 7) &= P(\\frac{Y - \\mu_Y}{\\sigma_Y} > \\frac{7-\\mu_Y}{\\sigma_Y}) \\\\\n& = P(Z > \\frac{7-5}{2} = 1)\n\\end{aligned}\\]\n1- pnorm(1) $ 0.1586553$\n1- pnorm(1, mean = 5, sigma = 2)"
  },
  {
    "objectID": "slides/lect_11.html#graph-1",
    "href": "slides/lect_11.html#graph-1",
    "title": "Chapter 12: The normal probability model",
    "section": "Graph",
    "text": "Graph"
  },
  {
    "objectID": "slides/lect_11.html#rule",
    "href": "slides/lect_11.html#rule",
    "title": "Chapter 12: The normal probability model",
    "section": "Rule",
    "text": "Rule"
  },
  {
    "objectID": "slides/lect_11.html#undo",
    "href": "slides/lect_11.html#undo",
    "title": "Chapter 12: The normal probability model",
    "section": "Undo",
    "text": "Undo"
  },
  {
    "objectID": "slides/lect_11.html#plot---normal",
    "href": "slides/lect_11.html#plot---normal",
    "title": "Chapter 12: The normal probability model",
    "section": "Plot - normal",
    "text": "Plot - normal"
  },
  {
    "objectID": "slides/lect_11.html#plot---tale-of-2-tails",
    "href": "slides/lect_11.html#plot---tale-of-2-tails",
    "title": "Chapter 12: The normal probability model",
    "section": "Plot - tale of 2 tails",
    "text": "Plot - tale of 2 tails"
  },
  {
    "objectID": "slides/lect_11.html#tale-of-2-tails",
    "href": "slides/lect_11.html#tale-of-2-tails",
    "title": "Chapter 12: The normal probability model",
    "section": "Tale of 2 tails",
    "text": "Tale of 2 tails"
  },
  {
    "objectID": "slides/lect_11.html#fat-tails",
    "href": "slides/lect_11.html#fat-tails",
    "title": "Chapter 12: The normal probability model",
    "section": "Fat tails",
    "text": "Fat tails"
  },
  {
    "objectID": "slides/lect_11.html#thin-tails",
    "href": "slides/lect_11.html#thin-tails",
    "title": "Chapter 12: The normal probability model",
    "section": "Thin tails",
    "text": "Thin tails"
  },
  {
    "objectID": "slides/lect_11.html#bimodal",
    "href": "slides/lect_11.html#bimodal",
    "title": "Chapter 12: The normal probability model",
    "section": "Bimodal",
    "text": "Bimodal\n\n\n\n\n\n\n\n\n\n\nstat1010-f22.github.io/website"
  },
  {
    "objectID": "ae/ae-4.html",
    "href": "ae/ae-4.html",
    "title": "Introduction to probability (AE-4)",
    "section": "",
    "text": "One ball will be drawn at random from a box containing: 3 cyan balls, 5 magenta balls, and 7 yellow balls. What is the probability that the ball will be cyan?\nWhat is the probability that the ball will not be cyan?\nInstead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling without replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nNow repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling with replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nTwo events A and B are independent if Pr(A and B)=Pr(A)P(B). Under which situation are the draws independent?\n\nYou don’t replace the draw.\nYou replace the draw.\nNeither\nBoth\n\nSay you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?\nIf you roll a 6-sided die six times, what is the probability of not seeing a 6?"
  },
  {
    "objectID": "ae/ae-3.html",
    "href": "ae/ae-3.html",
    "title": "Exploring numeric data (AE-3)",
    "section": "",
    "text": "Important\n\n\n\nThis application exercise is due on 20 Sept at 2:00pm."
  },
  {
    "objectID": "ae/ae-3.html#dotplot",
    "href": "ae/ae-3.html#dotplot",
    "title": "Exploring numeric data (AE-3)",
    "section": "Dotplot",
    "text": "Dotplot\n\nLook at the coding below and one at a time remove each of the dotsize, alpha, and stackdir from the code. What does each of these inputs do? How does each input impact upon the plot?\n\n\nggplot(data = diamonds) + # the data\n  geom_dotplot(mapping = aes(x = price), # plot of price\n               dotsize = 0.005, # make the dots tiny\n               alpha = 0.3, # less opaque\n               stackdir = \"center\") #"
  },
  {
    "objectID": "ae/ae-3.html#dotplot-vs-boxplot",
    "href": "ae/ae-3.html#dotplot-vs-boxplot",
    "title": "Exploring numeric data (AE-3)",
    "section": "Dotplot vs boxplot",
    "text": "Dotplot vs boxplot\nA boxplot provides summary information for the distribution of a variable. Here are some explanations (using different data) showing the purpose of the box portion of the boxplot.\nThe left line of the box is the quartile 1 (\\(Q_1\\)) or Q1 \n\npraise()\n\nThe middle line of the box is the median (\\(Q_2\\)) \nThe right line of the box is the quartile 3 (\\(Q_3\\)) \n\nLooking at the above plots, count the percentage of yellow dots in each of the dotplots. Is there anything interesting about these values?\nCompare and contrast a dotplot and a boxplot? What are the advantages and disadvantages of each? Think carefully about bimodal data and which plot you would use to show that aspect of a variable. Also think about outliers."
  },
  {
    "objectID": "ae/ae-3.html#boxplots",
    "href": "ae/ae-3.html#boxplots",
    "title": "Exploring numeric data (AE-3)",
    "section": "Boxplots",
    "text": "Boxplots\n\nDraw a boxplot of the price data from the diamonds dataset.\n\n\nggplot(data = INSERT) + # the data\n  INSERT(aes(x = INSERT)) # the variable\n\n\nBoxplot descriptions\n\n\nUse the information above to describe the boxplot of price.\n\n\n\nInterquartile range (IQR)\nThe IQR of a variable is the length of the box in a boxplot. \\[ IQR = Q_3 - Q_1\\]\n\npraise()"
  },
  {
    "objectID": "ae/ae-3.html#density-plot",
    "href": "ae/ae-3.html#density-plot",
    "title": "Exploring numeric data (AE-3)",
    "section": "Density plot",
    "text": "Density plot\n\n ggplot(data = diamonds) + # the data\n       geom_density(aes(x = price), # plot of price\n                    bw = 1) # plot of price\n\n\nWhat does the “bw” input in the geom_density function do? What is an appropriate value of “bw” for this data?\n\n\nggplot(data = diamonds) + # the data\n  geom_density(aes(x = price), # plot of price\n               bw = INSERT) + # binwidth\n  facet_wrap(~clarity) # faceting\n\n\nWhat does the above plot suggest about the prices of diamonds for all levels of the variable clarity?\n\n\npraise()\n\n\nDraw a density plot for each value of cut. Describe the distribution of diamond price for each value of cut.\n\n\nggplot(data = diamonds) + # the data\n  geom_density(aes(x = price), # plot of price\n               bw = INSERT) + # binwidth\n  facet_wrap(~INSERT) # faceting"
  },
  {
    "objectID": "ae/ae-3.html#measures-of-center",
    "href": "ae/ae-3.html#measures-of-center",
    "title": "Exploring numeric data (AE-3)",
    "section": "Measures of center",
    "text": "Measures of center\nWe use the summarise() function when we expect the result to be one number.\n\nMean\n\ndiamonds %>% # the dataset\n  summarise(mean = mean(price)) # function that is used to compute mean of price\n\n9, Now compute the means of the variables \\(x\\), \\(y\\), \\(z\\), and \\(carat\\). (hint: You will need to insert a code chunk for each of these variables.)\n\npraise()\n\nLast class we learned about the group_by() and used it to compute conditional probabilities. Today we will use it to compare the means of different subgroups.\n\ndiamonds %>% # the data\n  group_by(cut) %>% # for each value of cut\n  summarise(mean = mean(price), # find the mean\n            median = median(price)) # and the median\n\n\nCompare the average values of price for each level of the cut variable. Considering the distributions of price for each level of cut in question 8, is the grouped mean a good measure of center for each level of cut? Why or why not?\n\n\n\nMedian\n\nHow would you find the overall median of price?"
  },
  {
    "objectID": "ae/ae-3.html#measures-of-spread",
    "href": "ae/ae-3.html#measures-of-spread",
    "title": "Exploring numeric data (AE-3)",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nVariance\nR also computes measures of spread.\n\ndiamonds %>% # the data\n  summarise(var = var(price)) # find the variance\n\nBesides the direct method above, we can also do this computationally, by using the definition and finding the mean, subtracting, and squaring, then dividing.\n\ndiamonds %>% # the data\n  mutate(\n    mean_price = mean(price), # mean of price\n    deviation = price - mean_price, # subtraction from notes\n    deviation_sq = deviation^2) %>% # then square it\n  summarise(\n    mean_sq_deviation = sum(deviation_sq)/ # sum them\n      (nrow(diamonds) - 1)) # divide by n - 1\n\n\nRun each line of code above and ensure that you understand how this computation was developed. This shows us how to find \\(s_{price}^2\\) directly.\nFind \\(s_{x}^2\\), \\(s_{y}^2\\), and \\(s_{z}^2\\) both directly, and computationally: having R do the computation. (hint: you will need to insert 6 code chunks)\n\n\npraise()\n\n\n\nStandard deviation\n\nR also computes the standard deviation \\(s\\) directly:\n\n\n    diamonds %>% # the data\n      summarise(sd = sd(price)) # find the sd\n\nCan you use the computational approach (finding the mean_sq_deviation) from above to find the standard deviation of price \\(s_{price}\\)? (hint: you will need to use the sqrt() operator)\n\n\nIQR\n\nThe \\(IQR\\) can also be computed directly or indirectly:\n\n\ndiamonds %>% # the data\n  summarise(\n    q1 = quantile(price, 0.25), # find Q1\n    q3 = quantile(price, 0.75), # find Q3\n    iqr = q3 - q1 # now the IQR\n  )\n\n\n\nRange\n\ndiamonds %>% # the data\n  summarise(\n    min = min(price), # find min\n    max = max(price), # find max\n    range = max - min # and range\n  )\n\n\nOf all of the measures of spread, which do you think are sensitive to skewed data and outliers? Why?"
  },
  {
    "objectID": "ae/ae-2-exploring-categorical-vars.html",
    "href": "ae/ae-2-exploring-categorical-vars.html",
    "title": "Exploring categorical data AE-2",
    "section": "",
    "text": "Load packages, data\n\n## loading libraries\nlibrary(tidyverse) # for data analysis and visualisation\nlibrary(here) # to organize files\nlibrary(praise) # for ocassional good vibes!\n\nLet’s look at the data on the web prior to importing it and also to ensure that we know what it should look like when it is imported into R.\nNow press “raw”\n\nThen copy the url:\n\nDownload the file by inserting the URL below:\n\nfs::dir_create(here(\"data\")) # create a data folder \ndownload.file(\n  url = URL_HERE, # url of file to download\n  destfile = here(\"data/comics.csv\") # directory/name_of_file\n)\n\nThen click on the data folder in the “Files” panel.\n\nDouble click on “comics.csv” and click on “Import Dataset…”\n\nCheck the data in the “Data Preview” pane and ensure that it looks as it should.\n\nNext, click on the clipboard icon to copy the code from the “Code Preview” pane, then click “Import”.\n\n#PASTE THE CODE FROM \"Code Preview\" HERE\n\n\n\nData\nThe comics dataset includes basic information scraped from the superheroDb for a kaggle competition.\n\n## An overview of the dataset and type of variables\nglimpse(comics)\n\nThe first superhero is named “A-Bomb” he is male, with yellow eyes, human, with no hair. Marvel Comics created him and his skin color is not listed, but his height and weight are.\n\nAre there any differences between the data on the website above and the one in R? What are they? (Hint: which function can you use to see the whole dataset?)\n\npraise()\n\nThe ___ dataset has ___ observations and ___ variables.\nClassify all variables in the dataset as either: quantitative discrete, quantitative continuous, qualitative nominal, qualitative ordinal. Which of these variables is also categorical?\n\n\n\nCounts\n\nHow many publishers are there in this dataset?\n\ncomics %>% \n  distinct(Publisher) # finds the levels of publisher\n\nHow many levels of the variable Alignment are there in this dataset?\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\n\nA common way to represent the number of cases that fall into each combination of levels of two categorical variables, such as these, is with what’s called a “contingency table.” Note that each superhero appears in exactly one cell, statisticians call this mutually exclusive.\n\npraise()\n\n\nWhich is the most common category in this contingency table? How many superheros are in that category? (note: please look at both of the next two blocks of code.)\n\ncomics %>% \n  count(Publisher, Alignment) %>% # counts all combinations\n  View()\n\n\nThe long format above is difficult to see clearly. The format we normally use for contingency tables is the wide format.\nThe third line of coding below takes a long table and makes it wide by moving the Alignment variable to the columns, and filling the values of the table with the count variable (n). The names_from argument tells R where the names of the new columns are coming from (i.e. what variable), and the values_from argument tells R where the values in the table are coming from. Here, the values we want in our table are stored as a variable labeled n in our table.\n\ncomics %>% \n  count(Publisher, Alignment) %>%  # counts all combinations\n  pivot_wider(names_from = Alignment, \n              values_from = n) # pivots from long to wide \n\n\nThere are about ___ good superheros for each bad superhero.\n\nggplot(data = comics) + # the dataset\n  geom_bar(mapping = aes(x = Alignment)) # a bar chart of Alignment\n\nLook at the next two plots and find the difference between them. What would make you use one plot over the other? Which plot shows that females are much more likely to be good superheros than bad? Which one shows that good superheros are more likely to be missing gender? And which that females are more likely to be good superheros than males? All of these mean that the variables gender and alignment are associated, the value of one impacts upon the value of the other.\n\nggplot(data = comics) + # add the data\n  geom_bar(mapping = aes(x = Gender, # bar chart of gender\n                         fill = Alignment)) +  # colored by alignment\n  labs(title = \"Gender colored with alignment\") # add title\n\n\nggplot(data = comics) + # add the data\n  geom_bar(mapping = aes(x = Alignment, # bar chart of alignment\n                         fill = Gender)) + # colored by gender\n  labs(title = \"Alignment colored with gender\")  # add title\n\n\nWe note that the commonly held belief that gender is binary is no longer the scientific consensus and that gender is a complex spectrum.\n\nStatisticians want to discuss the strength of association of variables. They want to ensure that this association is not the result of random noise, but instead is a function of the underlying population of interest (all superheros).\n\npraise()\n\n\n\nChi-Squared test\nTo test for independence in 2 categorical variables, statisticians use a Chi-squared test. This is a hypothesis test so it has both a null hypothesis (\\(H_0\\)) and an alternative hypothesis (\\(H_A\\)).\n\\(H_0\\) = the variables are independent, there is no relationship between the two categorical variables.\n\\(H_A\\) = Knowing the value of one variable helps to predict the value of the other variable\nJust like a fair court case, where a defendant is assumed to be innocent until proven guilty, here we assume \\(H_0\\) until proven otherwise. The proof that we present at the case is a formula relating the actual values in our sample to what we would expect to get under the independence assumption.\nTo perform a Chi-squared test of independence on gender and alignment we must find the marginal distributions of both gender and alignment.\n\n\nMarginal distribution\n\nThe marginal distribution is the count of each variable.\n\ncomics %>% \n  count(Alignment, Gender) %>% \n  pivot_wider(names_from = Alignment, \n              values_from = n)\n\n\nWe take the original two-way table (with two categorical variables) and added up the cells across each level of align (ie \\(1+7+19+2 = 29\\)) to get the marginal distribution for each variable.\n\ncomics %>% # the dataset\n  count(Gender) # and marginal distribution of gender\n\n\npraise()\n\n\ncomics %>% # the dataset\n  count(Alignment) # and marginal distribution of the Alignment\n\nIf these are independent, we would expect \\(\\frac{200}{29+200+505}\\) of the \\(207\\) (about \\(56.4\\)) bad superheros to be female, and the same proportion of \\(496\\) (about \\(135.1\\)) good superheros to be female, and so on.\n\nAssuming independence of Alignment and Gender, how many good superheros would we expect to be male? (hint: use the “$$” to make\\(\\frac{1}{2}\\))\n\nMore information, including mathematical notation can be found here.\nFortunately, `R` does all of this for us.\n\n# the \"$\" sign pulls out the Gender values and Alignment value from the comics dataset\nchisq.test(comics$Gender, comics$Alignment)\n\nWe get a warning because the missing values (“-”) expected counts are probably quite small. You can safely use the chi-square test with critical values from the chi-square distribution when no more than 20% of the expected counts are less than \\(5\\) and all individual expected counts are 1 or greater. In particular, all four expected counts in a \\(2 \\times 2\\) table should be 5 or greater.\n\npraise()\n\nThe \\(p-value\\) for this test \\(0.0003298\\) is very small which means that we have very strong evidence against \\(H_0\\) — that there is independence between Alignment and Gender — and we can reject the null hypothesis. This suggests that the association between Gender and Alignment is not likely due to chance.\n\nThere are a few characters with missing data “-” in the Alignment and Gender variables? How many are in each?\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\n\ncomics %>% \n  INSERT_FUNCTION(INSERT_VARIABLE)\n\nSince there are only a few missing values (<10%) in each category, there is no reason to keep them especially since our analysis is largely about these two variables.\nWhat does the “!=” operator do?\n\ncomics_filtered <- # assign a name to a new dataset\n  comics %>% # tell R which dataset to start with\n  INSERT_FUNCTION(Alignment != \"-\", # remove \"-\" values in Alignment\n                  Gender != \"-\") # remove \"-\" values in Gender\n\nRemake the “Alignment colored with gender” plot and the “Gender colored with alignment” plots with this new dataset.\nRedo the Chi-Squared test for independence between Alignement and Gender. Include all hypotheses, and computations for at least \\(2\\) expected values. Does this change our conclusion?\n\npraise()\n\nSide-by-side barcharts allow us to represent the counts from a contingency table graphically. Telling R to make a side-by-side barchart involves adding the words position = \"dodge” to the coding from above. Now created the other bar chart side-by-side, the “Gender colored with alignment.” use the comics_filter dataset.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of alignment\n                         fill = INSERT), # colored by gender\n           position = INSERT) + # side_by_side\n  labs(title = \"Alignment colored with gender\")  # add title\n\n\n\n\nProportions\nWe have been focusing mostly on counts. Proportional data is also interesting to explore and it is easy to get R to produce those for us.\n\nWhat combination of Gender and Alignment has the highest proportion? What is the value? What is the sum of all of the proportions in the table below? (Note: Use the View() function to go through each line of code and ensure you know what each step does.)\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>% # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\n\n\n\nConditional proportions\n\nIf we’re curious about systematic associations between variables, we should look to conditional proportions. An example of a conditional proportion is the proportion of female superheroes that are good. To build a table of these conditional proportions, we need to specify a grouping variable before we calculate the proportions. What proportion of female characters are good? What do the rows sum to? (Note: Use the View() function to go through each line of code and ensure you know what each step does.)\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  group_by(Gender) %>% # conditions on gender\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>%  # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\nWhat proportion of good characters are male? What do the columns sum to?\n\ncomics %>% # which dataset to use \n  count(Gender, Alignment) %>% # counts all combinations\n  group_by(Alignment) %>% # conditions on gender\n  mutate(prop = n / sum(n)) %>% # finds proportions\n  select(Gender, Alignment, prop) %>%  # selecting which cols to pivot\n  pivot_wider(names_from = Alignment, # the variable to pivot\n              values_from = prop) # which values to pivot\n\n\npraise()\n\nPlotting proportions is similar to the side-by-side bar chart completed earlier. Instead of position = \"dodge\" we use position = \"fill\" . Draw one such plot below using Gender for the x axis and color it using Alignment.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of ?\n                         fill = INSERT), # colored by ?\n           position = INSERT) # fill\n\nNow, change the label of the y axis from count by including the coding\nlabs(y = \"Proportion of superheroes\")\n\npraise()\n\nDoes the above plot condition on gender or alignment? How do you know? (hint: what sums to 1?)\nCondition on the other variable.\n\nggplot(data = INSERT) + # add the data\n  geom_bar(mapping = aes(x = INSERT, # bar chart of ?\n                         fill = INSERT), # colored by ?\n           position = INSERT)  + # fill\n  lab(y = \"INSERT Y AXIS TITLE HERE\")\n\nAnother way to view the differences in variables is to facet. What is the advantage of a facet plot over a stacked barchart?\n\nggplot(comics) + # which dataset\n  geom_bar(mapping = aes(x = Gender)) + # bar chart of Gender\n  facet_wrap(~Alignment) # broken down by Alignment"
  },
  {
    "objectID": "ae/ae-6.html",
    "href": "ae/ae-6.html",
    "title": "Revision 1 for exam 1",
    "section": "",
    "text": "What tidyverse function would you use to extract rows?\na. filter()\n\n\n\ncount()\nselect()\ndistinct()\n\n\n\nWhat tidyverse function would you use to extract colums?\n\n\n\nfilter()\ncount()\nc. select()\ndistinct()\n\n\n\nTo find the maximum number of times that a categorical variable appears which function should I use?\n\n\n\nfilter()\nb. count()\nselect()\ndistinct()\n\n\n\nWhat does the “%>%” operator do?\n\na. used in tidyverse between layers of dplyr coding\nb. used in ggplot to add more layers of coding\n\n\nWill this code run without an error? diamonds %>% mutate(price_hundred = price %/% 100)\n\n\n\nIt will produce an error\nb. It will not produce an error\n\n\n\nWhat does the binwidth input in ggplot do?\n\n\n\nIt controls the opacity of the plot\nIt can be used to update the labels\nc. It controls the smoothness of a density plot\nIt controls the size of dots\n\n\n\nWhat punctuation must be placed before a function or dataset to access more information?\n\n\n\n“.”\n“+”\nc. “?”\n“!”\n\n\n\nWhere should the variable names go in the following line of code: ggplot(data = A) + B(mapping = aes(C))\n\n\n\nA\nB\nc. C\n\n\n\nWhat does the here package do?\n\n\n\nfor data manipulation and display\nb. to organize files\nnone of the above\n\n\n\nWhich of the following variables are discrete?\na. number of employees in a company.\n\n\n\ndistance traveled to and from work\ntaxes paid in 2019\npurchases from 2018\n\n\n\nWhat is the difference between distinct() and count()?\n\n\n\nthey are the same\nb. distinct() gives the levels in a variable, count() gives the marginal distribution\ndistinct() gives the marginal distribution, count() gives the levels in a variable\n\n\n\nWhat operator is used in ggplot?\n\n\n\n“.”\nb. “+”\n“?”\n“!”\n\nCategorical variables\n\nFind the expected count for clarity VS1 and color I for a \\(\\chi^2\\) distribution assuming independence.\n\n\\(8171\\times 5422/53940\\)\n\n\n# A tibble: 8 × 10\n  clarity     D     E     F     G     H     I     J marginal_clarity marginal_…¹\n  <ord>   <int> <int> <int> <int> <int> <int> <int>            <dbl>       <dbl>\n1 I1         42   102   143   150   162    92    50              741        6775\n2 SI2      1370  1713  1609  1548  1563   912   479             9194        9797\n3 SI1      2083  2426  2131  1976  2275  1424   750            13065        9542\n4 VS2      1697  2470  2201  2347  1643  1169   731            12258       11292\n5 VS1       705  1281  1364  2148  1169   962   542             8171        8304\n6 VVS2      553   991   975  1443   608   365   131             5066        5422\n7 VVS1      252   656   734   999   585   355    74             3655        2808\n8 IF         73   158   385   681   299   143    51             1790       53940\n# … with abbreviated variable name ¹​marginal_color\n\n\n[1] 821.3415\n\n\n\nWhat proportion of the very good cut diamonds are colored I?\n0.0997\n\n\n\n# A tibble: 5 × 8\n  cut            D      E      F      G      H      I      J\n  <ord>      <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Fair      0.0241 0.0229 0.0327 0.0278 0.0365 0.0323 0.0424\n2 Good      0.0977 0.0952 0.0953 0.0771 0.0845 0.0963 0.109 \n3 Very Good 0.223  0.245  0.227  0.204  0.220  0.222  0.241 \n4 Premium   0.237  0.239  0.244  0.259  0.284  0.263  0.288 \n5 Ideal     0.418  0.398  0.401  0.433  0.375  0.386  0.319 \n\n\n\n\n# A tibble: 5 × 8\n# Groups:   cut [5]\n  cut           D     E     F     G     H      I      J\n  <ord>     <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>\n1 Fair      0.101 0.139 0.194 0.195 0.188 0.109  0.0739\n2 Good      0.135 0.190 0.185 0.178 0.143 0.106  0.0626\n3 Very Good 0.125 0.199 0.179 0.190 0.151 0.0997 0.0561\n4 Premium   0.116 0.169 0.169 0.212 0.171 0.104  0.0586\n5 Ideal     0.132 0.181 0.178 0.227 0.145 0.0971 0.0416\n\n\n\nWhich of the lines below is the mean, median, or mode?\n\n\n\n\n\n\n\nred is median, green is mean\nred is mean, green is mode\nred is mode, green is mean\nd. red is mean, green is median\n\n\n\nIs the mean or median a better measure of center in this distribution.\n\nThe mean is a better estimate in a a symmetric distribution, median in a skewed distribution\n\n\n\n\n\n\nWhich plot is best at displaying outliers:\n\n\n\nhistogram\ndotplot\nplot of proportions\nd. boxplot"
  },
  {
    "objectID": "ae/ae-0-first_line_of_code.html",
    "href": "ae/ae-0-first_line_of_code.html",
    "title": "Introduction to the diamonds dataset",
    "section": "",
    "text": "Scenario\nYou own a jewelry business and are working to price your diamonds. To facilitate, you explore the diamond dataset in R and pay special attention to the cost of the diamond. Let’s explore together.\nTo accomplish this, please paste each line of code into your RStudio instance, and answer the accompanying questions.\n\n\nCoding basics\nGood coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread.\n\nWhen writing code, load all libraries first.\n“##” is used to write comments in R and should be used to justify next steps and anything unusual or unexpected steps\nComments are really important and are notes to your future self to remind you about steps that you took and decisions that you made.\n\n\n## loading library\nlibrary(tidyverse) # for data analysis and visualisation\n\n\n\nData\nThe diamonds dataset includes basic information about 53940 diamonds including price and other characteristics.\n\n## View the dataset in a separate tab\nglimpse(diamonds)\n\nThe ___ dataset has ___ observations and ___ variables.\n\n## What are the variables in this dataset?\n?diamonds\n\n\nWhat do the “4 c’s” of every diamond mean? What kind of variables are they? (hint: This video may help, copy this into your notes under the title data types)\n\nggplot is an R package that is used to create data visualizations. We will be using it throughout this course. The basic format for every ggplot command is:\n\n## DO NOT COPY INTO YOUR QUARTO DOCUMENT\n## THIS IS TO SHOW YOU THE BASIC FORMAT OF ALL ggplots\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\n\n\n## What is the distribution of price?\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price), binwidth = 1) \n\n\nWhat kind of variable is price? What happens if you draw a histogram with another kind of variable?\n\n\n## What happens if you draw a histogram with a different type of variable?\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = OTHER_VAR), binwidth = 1) \n\n\nWhat does the binwidth in the geom_histogram() function do? (hint: draw multiple plots changing this value) What binwidth value is most appropriate for this data?\n\n\n## Find an appropriate binwidth\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price), binwidth = OTHER_VALUE) \n\nThe distribution of diamond prices is right skewed (long right tail).\n\nIn your notes, copy these histograms and the words used to describe them.\n\nOne interesting feature of this graph is the dip in diamonds priced at about $1000. Let’s explore this a little further and look at some basic dplyr commands.\nThe pipe operator “%>%” tells R to take the output from one function and sends it to the input in the next function.\n\n## Filtering on price\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% \n  View()\n\n\nWhat does the filter function do?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  View()\n\n\nWhat does this “%/%” operator do? (hint: run 10 %/% 3, 10 %/% 5, 7 %/% 3, 7 %/% 5 in the console)\nWhat does the mutate function do? (hint: pay special attention to the dimensions of the data)\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  View()\n\n\nWhat does the select function do?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  count(price_hundred) %>% ## Count\n  View()\n\n\nCan you identify the values where the dip is using the information above? Why or why not?\n\n\ndiamonds %>% \n  filter(price > 750 & price < 1250) %>% ## Filtering on price\n  mutate(price_hundred = price %/% 100) %>% ## Finding price_hundred\n  select(price, price_hundred) %>% ## Select vars\n  mutate(price_remainder = price %% 100) %>% ## Finding price_remainder\n  count(price_hundred, price_remainder) %>% ## Count\n  View()\n\n10. What does the “%%” operator do?\n\nCan you identify the values where the dip is using the information above? Why or why not?\n\nCut may impact upon price\n\n## Cut and price\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price, color = cut, fill = cut),\n                 binwidth = 100) \n\n\nWhich cut do you suspect is the most common in the dataset? How many diamonds with that cut are in the dataset?\n\n\n## Most common cute\ndiamonds %>% \n  INSERT_FUNCTION_HERE(cut)\n\n\nThe variables color or clarity might impact upon the price. Draw a histogram and color it using one of them.\n\n\n## Impact of color and clarity\nggplot(data = diamonds) +\n  geom_histogram(mapping = aes(x = price, color = VAR_NAME, \n                               fill = VAR_NAME), \n                 binwidth = YOUR_BIN_WIDTH) \n\n\nWhat do the fill and color inputs do in the above coding?\nWhat kind of variables should we use for the fill and color inputs? What happens if another type of variable is used?\n\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_histogram(mapping = aes(x = price, color = VAR_NAME, \n                                   fill = VAR_NAME), \n                     binwidth = YOUR_BIN_WIDTH) \n\nSo far we have been looking at only 1 continuous variable. To look at two continous variables, we draw scatterplots.\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_point(mapping = aes(x = price, y = depth)) \n\n\nWhat kinds of variables do you think you could use to color this plot? Please use an appropriate variable from diamonds dataset and do so.\n\n\n## Color and fill variables\nggplot(data = diamonds) +\n      geom_point(mapping = aes(x = price, y = depth))"
  },
  {
    "objectID": "ae/ae-8.html",
    "href": "ae/ae-8.html",
    "title": "Random variables AE-8",
    "section": "",
    "text": "library(tidyverse)\nlibrary(praise)\n\n\nGiven that the random variable \\(X\\) has mean \\(\\mu = 120\\) and SD \\(\\sigma = 15\\), find the mean and SD of each of these random variables that are defined by \\(X\\).\n\n\\(X/3\\)\n\\(2X - 100\\)\n\\(X+2\\)\n\\(X-X\\)\n\nAn investor buys the stock of two companies, investing \\(\\$10000\\) in each. The stock of each company either goes up by \\(80%\\) after a month (rising to \\(\\$18000\\)) with probability \\(\\frac{1}{2}\\) or drops by \\(60%\\) (falling to \\(\\$4000\\)) with probability \\(\\frac{1}{2}\\). Assume that the changes in each are independent. Let the random variable \\(X\\) denote the value of the amounted invested after one month.\n\nFind the probability distribution of \\(X\\).\nFind the mean value of \\(X\\)\nDoe the mean value represent the experience of the typical investor?\n\n\n\npraise()\n\n\nA law firm takes cases on a contingent fee basis. If the case goes to trial, the firm expects to earn \\(\\$25000\\) as part of the settlement if it wins and nothing if it does not. The firm wins one-third of the cases that go to trial. If the case does not go to trial, the firm earns nothing. Half of the cases do not go to trial.\n\nDefine a random variable to model the earning of taking a case of this type.\nWhat is the expected value of such a case to the firm?\nWhat is the standard deviation of the earnings?\n\nThe maintenance staff of a large office building regularly replaces fluorescent ceiling lights that have gone out. During a visit to a typical floor, the staff may have to replace several lights. The manager of this staff has given the following probabilities to the number of lights (identified by the random variable \\(Y\\)) that need to be replaced on the floor:\n\n\n\n\\(Y\\)\n0\n1\n2\n3\n4\n\n\n\\(P(Y = y)\\)\n0.2\n0.15\n0.2\n0.3\n0.15\n\n\n\n\nHow many lights should the manager expect to replace on a floor?\nWhat is the standard deviation of the number of lights on a floor that are replaced?\nIf a crew takes six lights to a floor, how many should it expect to have left after replacing those that are out?\nIf a crew takes six lights to a floor, find the standard deviation of the number of lights that remain after replacing those that are out on a floor.\nIf it takes 10 minutes to replace each light, how long should the manager expect the crew to take when replacing the lights on a floor.\n\nSuppose that you’ve just bought a \\(\\$4000\\) TV. Should you also buy the \\(\\$50\\) surge protector that guarantees to protect your TV from electric surges caused by lightning?\n\nLet \\(p\\) denote the probability that your home is hit by lightning during the time that you own this TV, say five years. In order for the purchase of the surge protector to have positive long-term values, what must the chance of being hit by lightning be?\nThere are about 100 million households in the United States, and fewer than 10,000 get hit by lightening each year. Do you think the surge protector is a good deal on average? Be sure to note any assumptions that you make.\n\n\n\npraise()\n\n\nThe ATM at a local convenience store allows customers to make withdrawals of \\(\\$10\\), \\(\\$20\\), \\(\\$50\\), or \\(\\$100\\). Let \\(X\\) denote a random variable that indicates the amount withdrawn by a customer. The probability distribution of \\(X\\) is:\n\\(p(10) = 0.2\\)\n\\(p(20) = 0.5\\)\n\\(p(50) = 0.2\\)\n\\(p(100) = 0.1\\)\n\nPlot the probability distribution of \\(X\\) in R.\nWhat is the probability that a customer withdraws more than \\(\\$20\\)?\nWhat is the expected amount of money withdrawn by a customer?\nThe expected value is not a possible value value of the amount withdrawn. Interpret the expected value for a manager.\nFind the variance and standard deviation of \\(X\\)."
  },
  {
    "objectID": "ae/ae-7.html",
    "href": "ae/ae-7.html",
    "title": "Revision 2 for exam 1",
    "section": "",
    "text": "Find the matching item from the second column\n\n\n\n\n\n\n\n1. Independent events\na. \\(P(A \\cap B) \\neq P(A) \\times P(B)\\)\n\n\n\n\n\nDisjoint events\n\nb. \\(0\\leq p \\leq 1\\)\n\n\n\nUnion\n\nc. \\(A, B\\) disjoint \\(P(A\\cup B) = P(A) +P(B)\\)\n\n\n\nIntersection\n\nd. \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\n\nComplement of A\n\ne. \\(P(A \\cup B) \\leq P(A) + P(B)\\)\n\n\n\nSample space\n\nf. \\(A \\cap B\\)\n\n\n\nAddition rule\n\ng. \\(P(A \\cap B) = 0\\)\n\n\n\nComplement rule\n\nh. \\(P(S) = 1\\)\n\n\n\nBoole’s inequality\n\ni. \\(P(A^c) = 1 - P(A)\\)\n\n\n\nDependent events\n\nj. \\(P(A \\cap B) = P(A) \\times P(B)\\)\n\n\n\nKolmogorov’s axiom\n\nk. \\(A \\cup B\\)\n\n\n\nl. \\(A^c\\)\n\n\n\nm. \\(S\\)\n\n\n\n\n\n\nWhen \\(A \\subset B\\), then \\(A \\cup B = A\\)\n\nTrue\nFalse\n\nWhen \\(A \\subset B\\), then \\(A \\cap B = A\\)\n\nTrue\nFalse\n\nOne ball will be drawn at random from a box containing: 4 cyan balls, 3 magenta balls, and 5 yellow balls. What is the probability that the ball will be cyan?\nWhat is the probability that the ball will not be cyan?\nInstead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling without replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nNow repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling with replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?\nTwo events A and B are independent if Pr(A and B)=Pr(A)P(B). Under which situation are the draws independent?\n\nYou don’t replace the draw.\nYou replace the draw.\nNeither\nBoth\n\nSay you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?\nIf you roll a 6-sided die six times, what is the probability of seeing neither a 5 or 6?\nPlease match the following venn diagrams with the corresponding set theory notation.\n\n\n\n22.\na.\\(B \\subset A\\)\n\n\n\n\n23.\nb. \\(A\\) & \\(B\\) disjoint\n\n\n24.\nc. \\(A\\)\n\n\n25.\nd. \\(A \\cup B\\)\n\n\n26.\ne. \\(A \\cap B\\)\n\n\n27.\nf. \\(A^c\\)\n\n\n\n\n\nSolutions\n\n\n\n\n\n\n\n1\nj\n\n\n\n\n2\ng\n\n\n3\nk\n\n\n4\nf\n\n\n5\nl\n\n\n6\nm\n\n\n7\nd\n\n\n8\ni\n\n\n9\ne\n\n\n10\na\n\n\n11\nh, c, b\n\n\n12\nFalse\n\n\n13\nTrue\n\n\n14\n\\(\\frac{4}{4+3+5} = \\frac{4}{12}\\)\n\\(= \\frac{1}{3}\\)\n\n\n15\n\\(1 - \\frac{1}{3} = \\frac{2}{3}\\)\n\n\n16\nLet \\(C_1 = \\{1st\\:draw \\: is \\:cyan\\}\\) and\n\\(C_2 = \\{2nd\\: draw\\: is\\: cyan\\}\\)\nWe want :\\(P(C_1 \\cap C_2^c) = P(C_1) \\times P(C_2^c \\vert C_1)\\)\nThis is \\(\\frac{1}{3} \\times (1 -\\frac{3}{11}) = \\frac{8}{33}\\)\n\n\n17\nBecause they are independent:\\(P(C_1 \\cap C_2^c) = P(C_1) \\times P(C_2^c)\\)\n= \\(\\frac{1}{3} \\times \\frac{2}{3} = \\frac{2}{9}\\)\n\n\n18\nb\n\n\n19\n\\(\\frac{5}{12}\\)\n\n\n20\nLet \\(A = \\{5 \\: or \\: 6 \\: pips\\: facing\\: up\\}\\)\nWe want:\\(P(A^c \\cap A^c \\cap A^c \\cap A^c \\cap A^c \\cap A^c) = P(A^c)^6\\) because of independence of rolling a die.\n\\(= (\\frac{2}{3})^6 = \\frac{64}{729}\\)\n\n\n21\nNo question\n\n\n22\nc\n\n\n23\nf\n\n\n24\nb\n\n\n25\ne\n\n\n26\nd\n\n\n27\na"
  },
  {
    "objectID": "ae/ae-9.html",
    "href": "ae/ae-9.html",
    "title": "Associations AE-9",
    "section": "",
    "text": "library(tidyverse) # for data manipulation and plots\nlibrary(praise) # for good vibes\n\nChapter 6: Association between quantitative variables\n\nIf the covariance between \\(x\\) and \\(y\\) is \\(0\\), then the correlation between \\(x\\) and \\(y\\) is \\(0\\) as well\n\nTrue\nFalse\n\nA retailer calculated the correlation line between the price of an item (\\(x\\)) and the amount sold (\\(y\\)). The correlation line is the same if the \\(x\\) and \\(y\\) variables are exchanged.\n\nTrue\nFalse\n\n\n\npraise()\n\n\nIf the correlation between number of customers and sales in dollars in retail stores is \\(r=0.6\\), then what would be the correlation if the sales were measured in thousands of dollars? In euros? (1 euro is worth about \\(\\$US0.97\\))\n\nChapter 10: Association between random variables\n\nMix and match\n\n\n\n\n\n\n\n\nConsequence of positive covariance\n\na. \\(p(x, y)\\)\n\n\n\n\n\nCovariance between X and Y\n\nb. \\(\\rho\\)\n\n\n\nProperty of uncorrelated random variables\n\nc. \\(p(x, y) = p(x)p(y)\\)\n\n\n\nWeighted sum of two random variables\n\nd. \\(\\rho \\sigma_X \\sigma_Y\\)\n\n\n\nSharpe ratio of a random variable\n\ne. \\(Var(X+Y) > Var(X) +Var(Y)\\)\n\n\n\nImplies \\(X\\) and \\(Y\\) are independent random variables\n\nf. \\(p(x) = p(y)\\)\n\n\n\nImplies \\(X\\) and \\(Y\\) are identically distributed\n\ng. \\(X_1, X_2, X_3\\)\n\n\n\nSymbol for correlation between random variables\n\nh. \\(Var(X, Y) = Var(X) +Var(Y)\\)\n\n\n\nSymbol for a joint probability distribution\n\ni. \\(S(Y)\\)\n\n\n\nSequence of iid random variables\n\nj. \\(3X - 2Y\\)\n\n\n\nIndependent random variables \\(X\\) and \\(Y\\) have the means and standard deviations as given in the following table. Use these parameters to find the expected value and SD of the following random variables that are derived from \\(X\\) and \\(Y\\)\n\n\\(2X - 100\\)\n\\(0.5Y\\)\n\\(X+Y\\)\n\\(X-Y\\)\n\n\n\n\nMean\nSD\n\n\n\\(X\\)\n1000\n200\n\n\n\\(Y\\)\n2000\n600\n\n\n\n\n\n\npraise()\n\n\nRepeat the calculations above but now \\(X\\) and \\(Y\\) are not independent and have \\(Cov(X, Y) = 12,500\\).\nWhat’s the covariance between a random variable \\(X\\) and a constant?\nA student budgets $60 weekly for gas and quick meals off-campus. Let \\(X\\) denote the amount spent for gas and \\(Y\\) the amount spent for quick meals in a typical week. Assume the student sticks to the budget.\n\nCan we model \\(X\\) and \\(Y\\) as independent random variables? Why or why not?\nSuppose we assume \\(X\\) and \\(Y\\) are dependent. What is the effect of this dependence on the variance of \\(X+Y\\)?"
  },
  {
    "objectID": "ae/ae-5.html",
    "href": "ae/ae-5.html",
    "title": "The birthday simulation (AE-5)",
    "section": "",
    "text": "Computers let you assemble, manipulate, and visualize data sets, all at speeds that would have wowed yesterday’s scientists. In short, computers give you superpowers! But if you wish to use them, you’ll need to pick up some programming skills. Steve Job said that “computers are bicycles for our minds” because the efficiency rating of humans on bicycles is so incredible, and computers give us similar powers.\nOne reason computers are so incredible is that they allow us to simulate a multitude of events. Today we will simulate the probability that two of you in this section of Stat1010 have the same birthdays.\n\nlibrary(tidyverse) # for data manipulation\nlibrary(vctrs) # to find the length of a tibble\n\nSuppose you are in a classroom with 100 people. If we assume this is a randomly selected group of 100 people, what is the chance that at least two people have the same birthday? Although it is somewhat advanced, we can deduce this mathematically. We will do this later. Here we use a Monte Carlo simulation. For simplicity, we assume nobody was born on February 29. This actually doesn’t change the answer much.\nFirst, note that birthdays can be represented as numbers between 1 and 365, so a sample of 100 birthdays can be obtained like this:\n\nall_bdays <- as_tibble(1:365) # data from where we can sample\n\nbdays_class <- \n  all_bdays %>% # data from where to sample\n  slice_sample(n = 100, replace = TRUE) # sample of size 100 with replacement\n\nTo check if in this particular set of 100 people we have at least two with the same birthday, we can use the functions group_by and filter, which returns a tibble with a vector of duplicated dates. Here is an example:\n\nbdays_class %>% \n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) # those have more than 1\n\nTo estimate the probability of a shared birthday in the group, we repeat this experiment by sampling sets of 100 birthdays over and over. Prior to replicating, we need to write this as a function.\n\nbdays_dups <- \n  all_bdays %>% # data from where to sample\n  slice_sample(n = 100, replace = TRUE) %>% # take a sample of n 100\n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) %>% # those have more than 1\n  vec_n(.) # the number that are duplicated\n\nA function has an input (in this case \\(n\\))\n\nWhat does \\(n\\) represent in this coding?\n\n\nnum_of_same_birthdays <- function(n){\n  all_bdays %>% # data from where to sample\n  slice_sample(n = n, replace = TRUE) %>% # take a sample\n  group_by(value) %>% # for each birthday\n  count() %>% # count them\n  filter(n > 1) %>% # those have more than 1\n  vec_size(.)  # the number that are duplicated\n}\n\nTo run this function, we do this:\n\nnum_of_same_birthdays(10) # run the function\n\n\nHow many students are there in class today?\nRun the coding above but include the number of students in class today.\n\nThe law of large numbers says that if we do this many times we should have an estimate of the number of people that have the same birthdays in class today. The function replicate can be used to run functions multiple times.\n\nB <- 500 # the number of times to run\nresults <- replicate(B, # replicate this number of times\n          ifelse( # if there are some duplicated birthdays\n            num_of_same_birthdays(50) >= 1, # our function\n            1, # give me a 1\n            0)) # if not, give me a 0\n\nmean(results) # take the mean\n\nWere you expecting the probability to be this high?\nPeople tend to underestimate these probabilities. To get an intuition as to why it is so high, think about what happens when the group size is close to 365. At this stage, we run out of days and the probability is one.\nSay we want to use this knowledge to bet with friends about two people having the same birthday in a group of people. When are the chances larger than 50%? Larger than 75%?\nLet’s create a look-up table. We can create a function to compute this for any group size. This function runs our function \\(500\\) times for every value of $n$. Statisticians will usually do this \\(10000\\) times, but this will take a very very very very looooooooooonnnnnggggg time, so we are simplifying.\n\ncompute_prob <- # name the function\n  function(n, B = 500){ # function inputs\n  results <- # store results\n    replicate(B, # run num_of_same_birthdays B times \n              ifelse( # if there are some duplicated birthdays\n            num_of_same_birthdays(n) >= 1, # our function\n            1, # give me a 1\n            0)) # if not, give me a 0\n  \n  mean(results) # find the mean\n}\n\nUsing the function map_dbl, we can perform element-wise operations on any function. Note that this may take awhile to run.\n\nn <- seq(1, 60) # which values of n are important\nprob <- # save the results as prob\n  map_dbl(n,  # for each value of n \n          compute_prob) # run the function\n\nWe can now make a plot of the estimated probabilities of two people having the same birthday in a group of size n:\n\nas_tibble(n, prob) %>% # the format for ggplot\n  ggplot() + # draw a graph\n  geom_point(aes(x = n, y = prob)) # of points\n\nNow let’s compute the exact probabilities rather than use Monte Carlo approximations. Not only do we get the exact answer using math, but the computations are much faster since we don’t have to generate experiments.\nTo make the math simpler, instead of computing the probability of it happening, we will compute the probability of it not happening, or the compliment. For this, we use the multiplication rule.\nLet’s start with the first person. The probability that person 1 has a unique birthday is 1. The probability that person 2 has a unique birthday, given that person 1 already took one, is 364/365. Then, given that the first two people have unique birthdays, person 3 is left with 363 days to choose from. We continue this way and find the chances of all \\(n\\) people having a unique birthday is:\n\\[1×\\frac{364}{365}×\\frac{363}{365}…\\frac{365−n+1}{365}\\] We can write a function that does this for any number:\n\nexact_prob <- function(n){\n  1 - \n    prod(365:(365-n+1))/ # the product from the numerator above\n    365^(n) # the denominator from above\n}\n\n\nRun this coding for the number of people that are in class today.\n\nNow, we run this on multiple values of \\(n\\)\n\neprob <- map_dbl(n, exact_prob) # run on multiple values of n\n\nNext we plot the results.\n\nas_tibble(n, eprob) %>% # the format for ggplot\n  ggplot() + # draw a graph\n  geom_point(aes(x = n, y = eprob)) # of points\n\nOn mercury, the year is only 88 days. Update the coding above to simulate the expected number of people with the same birthdays on Mercury.\nAssuming we have the same number of people, would you expect the number of people with the same birthdays to be higher or lower than those on earth?"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html",
    "href": "ae/ae-4-exam-1-review.html",
    "title": "AE 4: Exam 1 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-4-exam-1-review-YOUR_GITHUB_USERNAME to get started."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#packages",
    "href": "ae/ae-4-exam-1-review.html#packages",
    "title": "AE 4: Exam 1 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggfortify)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#restaurant-tips",
    "href": "ae/ae-4-exam-1-review.html#restaurant-tips",
    "title": "AE 4: Exam 1 Review",
    "section": "Restaurant tips",
    "text": "Restaurant tips\nWhat factors are associated with the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.1\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\n\nView the data set to see the remaining variables.\n\ntips <- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#exploratory-analysis",
    "href": "ae/ae-4-exam-1-review.html#exploratory-analysis",
    "title": "AE 4: Exam 1 Review",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\n\nVisualize, summarize, and describe the relationship between Party and Tip.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#modeling",
    "href": "ae/ae-4-exam-1-review.html#modeling",
    "title": "AE 4: Exam 1 Review",
    "section": "Modeling",
    "text": "Modeling\nLet’s start by fitting a model using Party to predict the Tip at this restaurant.\n\nWrite the statistical model.\nFit the regression line and write the regression equation. Name the model tips_fit and display the results with kable() and a reasonable number of digits.\n\n\n# add your code here\n\n\nInterpret the slope.\nDoes it make sense to interpret the intercept? Explain your reasoning."
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#inference",
    "href": "ae/ae-4-exam-1-review.html#inference",
    "title": "AE 4: Exam 1 Review",
    "section": "Inference",
    "text": "Inference\n\nInference for the slope\n\nThe following code can be used to create a bootstrap distribution for the slope (and the intercept, though we’ll focus primarily on the slope in our inference). Describe what each line of code does, supplemented by any visualizations that might help with your description.\n\n\nset.seed(1234)\n\nboot_dist <- tips %>%\n  specify(Tip ~ Party) %>%\n  generate(reps = 100, type = \"bootstrap\") %>%\n  fit()\n\n\nUse the bootstrap distribution created in Exercise 6, boot_dist, to construct a 90% confidence interval for the slope using bootstrapping and the percentile method and interpret it in context of the data.\n\n\n# add your code here\n\n\nConduct a hypothesis test at the equivalent significance level using permutation. State the hypotheses and the significance level you’re using explicitly. Also include a visualization of the null distribution of the slope with the observed slope marked as a vertical line.\n\n\n# add your code here\n\n\nCheck the relevant conditions for Exercises 7 and 8. Are there any violations in conditions that make you reconsider your inferential findings?\n\n\n# add your code here\n\n\nNow repeat Exercises 7 and 8 using approaches based on mathematical models.\n\n\n# add your code here\n\n\nCheck the relevant conditions for Exercise 9. Are there any violations in conditions that make you reconsider your inferential findings?\n\n\n# add your code here\n\n\n\nInference for a prediction\n\nBased on your model, predict the tip for a party of 4.\n\n\n# add your code here\n\n\nSuppose you’re asked to construct a confidence and a prediction interval for your finding in Exercise 11. Which one would you expect to be wider and why? In your answer clearly state the difference between these intervals.\nNow construct the intervals from Exercise 12 and comment on whether your guess is confirmed.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#model-diagnostics",
    "href": "ae/ae-4-exam-1-review.html#model-diagnostics",
    "title": "AE 4: Exam 1 Review",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nLeverage (Outliers in x direction)\n\nWhat is the threshold used to identify observations with high leverage? Calculate the threshold and save the value as leverage_threshold.\n\n\n# add your code here\n\n\nMake a plot of the standardized residuals vs. leverage (you can do this with ggplot() or with autoplot(which = 5)). Use geom_vline() to add a vertical line to help identify points with high leverage.\n\n\n# add your code here\n\n\nLet’s dig into the data further. Which observations have high leverage? Why do these points have high leverage?\n\n\n# add your code here\n\n\n\nIdentifying outliers (outliers in y direction)\n\nMake a plot of the residuals vs. fitted values and a plot of the square root of the absolute value of standardized residuals vs. fitted (You can use autoplot(which = c(1, 3)) to display the plots side-by-side).\n\n\nHow are the plots similar? How do they differ?\nWhat is an advantage of using the plot of the residuals vs. fitted to check conditions and model diagnostics?\nWhat is an advantage of using the plot of the \\(\\sqrt{|\\text{standardized residuals}|}\\) vs. fitted to check conditions and model diagnostics?\n\n\n# add your code here\n\n\nAre there any observations that are outliers?\n\n\n# add your code here\n\n\n\nCook’s distance\n\nMake a plot to check Cook’s distance (autoplot(which = 4)). Based on this plot, are there any points that have a strong influence on the model coefficients?\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-4-exam-1-review.html#adding-another-variable",
    "href": "ae/ae-4-exam-1-review.html#adding-another-variable",
    "title": "AE 4: Exam 1 Review",
    "section": "Adding another variable",
    "text": "Adding another variable\n\nAdd another variable, Alcohol, to your exploratory visualization. Describe any patterns that emerge.\n\n\n# add your code here\n\n\nFit a multiple linear regression model predicting Tip from Party and Alcohol. Display the results with kable() and a reasonable number of digits.\n\n\n# add your code here\n\n\nInterpret each of the slopes.\nDoes it make sense to interpret the intercept? Explain your reasoning.\nAccording to this model, is the rate of change in tip amount the same for various sizes of parties regardless of alcohol consumption or are they different? Explain your reasoning."
  },
  {
    "objectID": "exams/exam-1.html",
    "href": "exams/exam-1.html",
    "title": "Exam 1",
    "section": "",
    "text": "Grading (50 pts)\n\n\n\nPart\nPoints\n\n\n\n\nPart 1 - Conceptual (on Sakai)\n10\n\n\nPart 2 - Applied (on Gradescope)\n40\n\n\nTotal\n50"
  },
  {
    "objectID": "project-description.html#data",
    "href": "project-description.html#data",
    "title": "Showcase your inner data scientist",
    "section": "Data",
    "text": "Data\nIn order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset’s variables should include categorical variables, discrete numerical variables, and continuous numerical variables.\nIf you are using a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late.\nNote on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class.\nBelow are a list of data repositories that might be of interest to browse. You’re not limited to these resources, and in fact you’re encouraged to venture beyond them. But you might find something interesting there:\n\nTidyTuesday\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland’s official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nIf you know of others, let me know, and we’ll add here…"
  },
  {
    "objectID": "project-description.html#deliverables",
    "href": "project-description.html#deliverables",
    "title": "Showcase your inner data scientist",
    "section": "Deliverables",
    "text": "Deliverables\n\nProposal - due 26 October\nPresentation - due 5 & 7 Dec\nExecutive summary - due 9 Dec\n\n\nProposal\nThis is a draft of the introduction section of your project as well as a data analysis plan and your dataset.\n\nSection 1 - Introduction: The introduction should introduce your general\nresearch question and your data (where it came from, how it was collected, what are the cases, what are the variables, etc.).\nSection 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame.\nSection 3 - Data analysis plan:\n\nAny outcomes (response, Y) and predictor (explanatory, X) variables you will use to answer your question.\nThe comparison groups you will use, if applicable.\nVery preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project.)\nThe method(s) that you believe will be useful in answering your question(s). (You can update these later as you work on your project.)\nWhat results from these specific statistical methods are needed to support your hypothesized answer?\n\n\nEach section should be no more than 1 page (excluding figures). You can check a print preview to confirm length.\nThe grading scheme for the project proposal is as follows. Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it. If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).\n\n\n\nTotal\n10 pts\n\n\n\n\nData\n3 pts\n\n\nProposal\n5 pts\n\n\nWorkflow, organization, code quality\n1 pt\n\n\nTeamwork\n1 pt\n\n\n\n\n\nPresentation\n5 minutes maximum, and each team member should say something substantial. You can either present live during your workshop or pre-record and submit your video to be played during the workshop.\nPrepare a slide deck using the template I will give to you. This template uses quarto, and allows you to make presentation slides using R Markdown syntax. There isn’t a limit to how many slides you can use, just a time limit (5 minutes total). Each team member should get a chance to speak during the presentation. Your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found.\nBefore you finalize your presentation, make sure your chunks are turned off with echo = FALSE.\nPresentations will take place on 5 and 7 December. You can choose to do your presentation live or pre-record it. During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations. The presentation line-up will be generated randomly.\nThe grading scheme for the presentation is as follows:\n\n\n\n\n\n\n\nTotal\n50 pts\n\n\n\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\n4 pts\n\n\nContent: Is the research question well designed and is the data being used relevant to the research question?\n5 pts\n\n\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\n5 pts\n\n\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\n6 pts\n\n\nContent: Did the team use appropriate statistical procedures and interpretations of results accurately?\n10 pts\n\n\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n10 pts\n\n\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n10 pts\n\n\n\n\n\nExecutive summary\nAlong with your presentation slides, we want you to provide a brief summary of your project.\nThis executive summary should provide information on the dataset you’re using, your research question(s), your methodology, and your findings.\nThe executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it’s concise but detailed enough.\n\n\nProject organization\nThe following folders and files in your project:\n\npresentation.qmd + presentation.html: Your presentation slides\nREADME.Rmd + README.md: Your write-up\n/data: Your dataset in CSV or RDS format and your data dictionary\n/proposal: Your project proposal\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted."
  },
  {
    "objectID": "project-description.html#tips",
    "href": "project-description.html#tips",
    "title": "Showcase your inner data scientist",
    "section": "Tips",
    "text": "Tips\n\nYou’re working in the same google doc as your teammates now, so make sure that the coding is in the correct order.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution.\nSet aside time to work together and apart (physically).\nWhen you’re done, review the documents to make sure you’re happy with the final state of your work. Then go get some rest!\nCode: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your quarto file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion.\n\nTeamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-description.html#marking",
    "href": "project-description.html#marking",
    "title": "Showcase your inner data scientist",
    "section": "Marking",
    "text": "Marking\n\n\n\nTotal\n100 pts\n\n\n\n\nProposal\n10 pts\n\n\nPresentation\n50 pts\n\n\nExecutive summary\n15 pts\n\n\nReproducibility and organization\n10 pts\n\n\nTeam peer evaluation\n10 pts\n\n\nClassmates’ evaluation\n5 pts\n\n\n\n\nCriteria\nYour project will be assessed on the following criteria:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60% - Student is not making a sufficient effort.\n\n\n\nTeam peer evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points. You will additionally report a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.\n\n\nLate work policy\n\nThere is no late submission / make up for the presentation. You must be in class on the day of the presentation to get credit for it or pre-record and submit your presentation by 9am in the morning of the presentations.\nThe late work policy for the write-up is 5% of the maximum obtainable mark per calendar day up to seven calendar days after the deadline. If you intend to submit work late for the project, you must notify the course organizer before the original deadline as well as soon as the completed work is submitted."
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures",
    "href": "course-support.html#lectures",
    "title": "Course support",
    "section": "Lectures",
    "text": "Lectures\nIf you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#discussion-forum",
    "href": "course-support.html#discussion-forum",
    "title": "Course support",
    "section": "Discussion forum",
    "text": "Discussion forum\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The online discussion forum is the best venue for these! We will use Ed discussion as the online discussion forum. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go Ed discussion), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email dr. gwynn sturdevant at gwynnc@wharton.upenn.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STAT 1010” and only “STAT 1010” in the subject line. You can also contact me privately on Canvas. Barring extenuating circumstances, I will respond to STAT 1010 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Weingarten learning center. The Weingarten Center offers a variety of resources to support all Penn students in reaching their academic goals. They offer multiple workshops throughout the semester and students can request workshops. All services are free and confidential. To contact the Weingarten Center, call 215-573-9235. The office is located in Stouffer Commons at 3702 Spruce Street, Suite 300.\nLearning Consultations offers individual consultations and group workshops that support students in developing more efficient and effective study skills and learning strategies. Learning specialists work with students to address time and project management, academic reading and writing, note-taking, problem-solving, exam preparation, test-taking, self-regulation, and flexibility.\n\nTutoring offers free access to on-campus tutors for many Penn courses in both drop-in and weekly contract format. Tutoring may be individual or in small groups. Tutors will assist with applying course information, understanding key concepts, and developing course-specific strategies. Tutoring support is available throughout the term but is best accessed early in the semester. First-time users must meet with a staff member; returning users may submit their requests online.\n\nAdditionally, Marks Family Writing Center provides expert help in writing for undergraduate and graduate students. Communication Within the Curriculum helps students express themselves orally with clarity and confidence. Language Direct provides tutoring for foreign languages. Van\nPelt Library supports students in research and instructional technologies through a range of workshops and consultations."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nCounseling and Psychological Services (CAPS) provides professional psychological and psychiatric services to students who need support in fulfilling their academic, social, and personal objectives. CAPS directly supports student mental health through counseling, crisis management, consultation, education and outreach, and training. CAPS has a satellite office in Huntsman Hall, and students with urgent concerns can talk with a CAPS clinician 24/7 at 215.898.7021 (press 1) or visit CAPS' main office at 3624 Market Street during business hours.\n\nStudent Health Service provides students with accessible, cost-effective, culturally-sensitive, and student-focused healthcare, including care for acute and chronic health problems, preventive health services, and health and wellness education.\n\nAlcohol and Other Drug Program Initiatives (AOD) works to reduce harm related to alcohol and other drug use at Penn.\n\nPenn Violence Prevention (PVP) engages the Penn community in the prevention of sexual violence, relationship violence, stalking, and sexual harassment on campus. PVP provides education and outreach and the staff serves as confidential resources for students.\n\nPublic Safety: From riding your bike on campus, to preventing unattended theft, the Division of Public Safety wants to make sure you have the information you need to protect your safety and your belongings.\n\nPenn Recreation: Penn offers many opportunities for students to participate in competitive team sports and stay physically fit at state-of-the-art, world-class training centers.\n\nWharton Wellness is a division-sponsored student organization that works to implement initiatives targeted at specific wellness issues in the Wharton community by creating experiences, fostering a positive culture of well-being, and connecting clubs/students to wellness resources.\n\nIt is important to me that you have the resources you need to be able to focus on learning in this course – this includes both the necessary academic materials as well as taking care of your day-to-day needs. Students experiencing difficulty affording the course materials should reach out to the Penn First Plus office (pennfirstplus@upenn.edu). Students who are struggling to afford sufficient food to eat every day and/or lack a safe and suitable space to live should contact Student Intervention Services (vpul-sisteam@pobox.upenn.edu). Students may also wish to contact their Financial Aid Counselor or Academic Advisor about these concerns. You are welcome to notify me if any of these challenges are affecting your success in this course, as long as you are comfortable doing so – I may have resources to support you."
  },
  {
    "objectID": "course-support.html#technology-accommodations",
    "href": "course-support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nStudents with demonstrated high financial need who have limited access to computers may request assistance in the form of loaner laptops. For technology assistance requests, please go here. Please note that supplies are limited. Additional support is also available through Student Intervention Services."
  },
  {
    "objectID": "course-support.html#course-materials-costs",
    "href": "course-support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-canvas",
    "href": "course-support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas, Gradescope, or Zoom, contact Wharton Student Computing. You can also access the self-service help documentation for Zoom here, Canvas here, and for Gradescope here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Open your Stat1010 project then go to file and open a quarto document. You can add code chunks by clicking on the green button in the IDE and answer some questions directly in the document, and add further code chunks. Hit render and if there are no errors in your code, the pdf should pop up. You can then upload to either Canvas or Gradescope"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 1010: Introduction to Business Statistics",
    "section": "",
    "text": "Week\nDate\nTopic\nPrepare\nSlides\nAE\nHW\nExam\nProject\n\n\n\n\n\n1\nMon, 29 Aug\nNo class - opening exercises\n\n\n\n\n\n\n\n\n\n\nWed, 31 Aug\nStarting with R\n\n🖥️\n📋\n\n\n\n\n\n\n2\nMon, 5 Sept\nNo class - Labor Day\n\n\n\n\n\n\n\n\n\n\nWed, 7 Sept\nContinuation of Intro to R\n📖\n🖥️\n\n\n\n\n\n\n\n3\nMon, 12 Sept\nCategorical variables\n📖\n🖥️\n📋\n\n\n\n\n\n\n\nWed, 14 Sept\nNumeric variables\n\n🖥️\n📋\n✍️\n\n\n\n\n\n4\nMon, 19 Sept\nIntro to probability\n📖\n🖥️\n📋\n✍️\n\n\n\n\n\n\nWed, 21 Sept\nMore probability rules\n\n🖥️\n📋\n\n\n\n\n\n\n5\nMon, 26 Sept\nRevision of AE 1-4\n📖\n\n📋\n\n\n\n\n\n\n\nWed, 28 Sept\nRevision of HW-1\n📖\n\n📋\n\n\n\n\n\n\n6\nMon, 3 Oct\nExam 1\n\n\n\n\n✅\n\n\n\n\n\nWed, 5 Oct\nRandom variables\n📖\n🖥️\n📋\n\n\n\n\n\n\n7\nMon, 10 Oct\nAssociation between quantitative variables\n📖\n🖥️\n\n\n\n\n\n\n\n\nWed, 12 Oct\nAssociation between random variables\n\n🖥️\n📋\n✍️\n\n\n\n\n\n8\nMon, 17 Oct\nProbability models for counts\n📖\n🖥️\n\n\n\n\n\n\n\n\nWed, 19 Oct\nThe normal probability model\n\n🖥️"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Discussion forum\n🔗 on Ed discussion\n\n\n\n\nLecture streaming and recordings (email for permission)\n🔗 on Canvas\n\n\nSubmit AE\n🔗 on Canvas\n\n\nSubmit HWK\n🔗 on Gradescope\n\n\nGradebook\n🔗 on Canvas"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "STA 1010: Introduction to Business Statistics",
    "section": "",
    "text": "The course goals are as follows:\n\nRecognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the scope of inference.\nUse statistical software to summarize data numerically and visually, and to perform data analysis.\nHave a conceptual understanding of the unified nature of statistical inference.\nApply estimation and testing methods to analyze single variables or the relationship between two variables in order to understand natural phenomena and make data-based\ndecisions.\nModel numerical response variables using a single or multiple explanatory variables.\nInterpret results correctly, effectively, and in context without relying on statistical jargon.\nCritique data-based claims and evaluate data-based decisions.\nComplete a research project demonstrating mastery of statistical data analysis from exploratory analysis to inference to modeling."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "STAT 1010 - Fall 2022",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-syllabus.html#course-info",
    "href": "course-syllabus.html#course-info",
    "title": "Syllabus",
    "section": "Course info",
    "text": "Course info\n\n\n\n\nDay\nTime\nLocation\n\n\n\n\nSection 1\nMon & Wed\n8:30 am - 10:00 am\nSHDH 1206\n\n\nSection 2\nMon & Wed\n10:15 am - 11:45 am\nSHDH 1206\n\n\nSection 3\nMon & Wed\n1:45 pm - 3:15 pm\nSHDH 1206"
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the semester, you will be able to…\n\nunderstand data manipulation, and find basic summaries\nreason under uncertainity\nmake predictions\nunderstand probability\ncommunicate results from statistical analyses to a general audience."
  },
  {
    "objectID": "course-syllabus.html#community",
    "href": "course-syllabus.html#community",
    "title": "Syllabus",
    "section": "Community",
    "text": "Community\n\nWharton’s Code of Conduct\nAs a student in this course, you have agreed to uphold the Wharton’s Student Code of Conduct as well as the practices specific to this course.\n\n\nInclusive community\nMy goal as your lecturer is to help you accomplish or discover your passion and find your spark. You all belong here. It is also my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Diversity, Inclusion and Belonging at the Wharton School. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups. Please feel free to leave anonymous comments in my mailbox on the 4th floor of the Academic Research Building.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Weingarten Center is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the the Weingarten Center to request or update accommodations under these circumstances; it can take up to 4 weeks to review documents and get approval.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website at stats1010-f22.github.io/website.\nI will regularly send course announcements via email and canvas, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the Ed discussion forum. There is a chance another student has already asked a similar question, so please check the other posts in Conversations before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\nEmails should be reserved for questions not appropriate for the public forum. If you email me, please include “STAT 1010” in the subject line and ONLY STAT 1010. Barring extenuating circumstances, I will respond to STAT 1010 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\n\nCheck out the Support page for more resources."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nWhile there is no official textbook for the course, we will be assigning readings from the following textbooks.\n\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin\nStatistics for Business by Robert Stine and Dean Foster"
  },
  {
    "objectID": "course-syllabus.html#lectures",
    "href": "course-syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nThe goal of the lectures is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded. In addition to application exercises will be periodic activities to help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. If you are in need of a loaner laptop please seek support here."
  },
  {
    "objectID": "course-syllabus.html#teams",
    "href": "course-syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture. All team members are expected to contribute equally to the completion of the labs and project and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team’s overall mark."
  },
  {
    "objectID": "course-syllabus.html#assessment",
    "href": "course-syllabus.html#assessment",
    "title": "Syllabus",
    "section": "Assessment",
    "text": "Assessment\nAssessment for the course is comprised of five components: application exercises, homework assignments, exams, projects, and teamwork.\n\nApplication exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises give you an opportunity to apply the statistical concepts and code introduced in the readings and lectures. Due dates for AEs will be announced as they are assigned.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and submitted as a PDF in Canvas.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be four exams consisting of multiple choice questions. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on the conceptual understanding of the content. The content of the exam will be related to the content in the prepare, practice, and perform assignments. More detail about the exams will be given during the semester.\nThe lowest exam grade will be dropped at the end of the semester.\n\n\nProject\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting, data-driven research question. The project will be completed with your teams, and each team will present their work. More information about the project will be provided during the semester."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nApplication exercises\n7%\n\n\nHomework\n35% (7 x 5%)\n\n\nProject\n15%\n\n\nExam 01\n10%\n\n\nExam 02\n10%\n\n\nExam 03\n10%\n\n\nTeamwork\n13%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "course-syllabus.html#five-tips-for-success",
    "href": "course-syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TA and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TA, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. If something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, and eventually you won’t know where to begin asking questions. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours, and let me help you identify a good (re)starting point."
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic integrity\nTL;DR: Don’t cheat!\nAll students must adhere to Wharton’s Code of Academic Integrity: Wharton is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nRegardless of course delivery format, it is your responsibility to understand and follow Wharton policies regarding academic integrity, including doing one’s own work, following proper citation of sources, and adhering to guidance around group work projects. Ignoring these requirements is a violation of the Wharton Community Standard. If you have any questions about how to follow these requirements, please contact Julie Nettleton, Director of the Center for Community Standards and Accountability (CSA).\n\n\nCollaboration policy\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\n\n\n\nPolicy on sharing and reusing code\nI am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g. RStudio Community, StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. On individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email dr. sturdevant before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let dr. sturdevant know if you need help contacting your academic dean.\n\n\nRegrade request policy\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Wharton attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you’re going to miss a class and you’re feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others’ time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have symptoms related to COVID-19, have had a known exposure to COVID-19, or have tested positive for COVID-19. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health at 215-898-0300. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class. For the safety of all students, I require that students wear masks in class and prefer N95 or KN95 masks.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously or watching a recording of the class.\n\n\nPolicy on video recording course content\nLectures will be recorded and available on Canvas, so students should not need to create their own recordings of lectures. If you feel that you need record the lectures yourself, you must get written permission from me ahead of time and these recordings should be used for personal study only, not for distribution. The full policy on recording of lectures falls under the University of Pennsylvania’s V.L. Policy on Unauthorized Copying of Copyrighted Media, available at https://catalog.upenn.edu/faculty-handbook/v/v-l/. Unauthorized distribution may result in a civil suite, criminal charges, and/or penalties and fines."
  },
  {
    "objectID": "course-syllabus.html#learning-during-a-pandemic",
    "href": "course-syllabus.html#learning-during-a-pandemic",
    "title": "Syllabus",
    "section": "Learning during a pandemic",
    "text": "Learning during a pandemic\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis.\n\nNote: If you’ve read this far in the syllabus, send me an email with a picture of your pet if you have one or your favorite memes with STAT1010 in the subject line!"
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAugust 30: First day of classes\nSeptember 5: Labor Day holiday, no classes are held\nSeptember 13: Course Selection Period ends\nOctober 6 - 9: Fall term break, no classes are held\nOctober 10: Drop period ends\nOctober 10: Indigenous People’s Day (classes in session)\nOctober 28: Grade Type Change Deadline\nNovember 7: Last day to withdraw from a course\nNovember 22-23: Thur-Fri class schedule on Tue-Wed\nNovember 24-27: Thanksgiving Break\nDecember 12: Last day of classes\nDecember 13-14: Reading Days\nDecember 15 - 22: Final exams\nDecember 22: Fall term ends\n\nClick here for the full University of Pennsylvania academic calendar."
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "R Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\n\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies"
  },
  {
    "objectID": "project-tips-resources.html#tips",
    "href": "project-tips-resources.html#tips",
    "title": "Project tips + resources",
    "section": "Tips",
    "text": "Tips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "project-tips-resources.html#formatting-communication-tips",
    "href": "project-tips-resources.html#formatting-communication-tips",
    "title": "Project tips + resources",
    "section": "Formatting + communication tips",
    "text": "Formatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\n\nHeaders\n\nUse headers to clearly label each section.\nInspect the document outline to review your headers and sub-headers.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\nResize plots and figures, so you have more space for the narrative.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(y = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg %>%\n  count(manufacturer) %>%\n  mutate(manufacturer = str_to_title(manufacturer)) %>%\n  ggplot(aes(y = fct_reorder(manufacturer,n), x = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_minimal() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel <- lm(mpg ~ hp, data = mtcars)\ntidy(model) %>%\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STAT 1010.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document."
  },
  {
    "objectID": "project-tips-resources.html#additional-resources",
    "href": "project-tips-resources.html#additional-resources",
    "title": "Project tips + resources",
    "section": "Additional resources",
    "text": "Additional resources\n\nR for Data Science\nQuarto Documentation\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "documents/about_R.html",
    "href": "documents/about_R.html",
    "title": "About R",
    "section": "",
    "text": "The R programming language was first released on [29 February 2000](https://www.hermetic.ch/y2k/feb29.htm). [Ross Ihaka](https://en.wikipedia.org/wiki/Ross_Ihaka) and [Robert Gentleman](https://en.wikipedia.org/wiki/Robert_Gentleman_(statistician)) wanted a free, open-source language that their statistics students at the University of Auckland could use to fit statistical models. [R is now an internationally recognized language used all over the world](https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html). It is possible to do a multitude of advanced computations in R but to keep R nimble, we don’t download all of the things at once. Instead, coding is bundled together into something called “packages” that are stored on [CRAN](https://cran.r-project.org/)."
  },
  {
    "objectID": "hw/hw-1.html",
    "href": "hw/hw-1.html",
    "title": "HW 1 - Titanic dataset",
    "section": "",
    "text": "For this homework assignment we will be exploring the Titanic dataset.\n\n\nIn this assignment, you will…\n\nDownload and import data into R\nExplore categorical variables\nCompute the expected counts of a \\(\\chi^2\\) distribution and\nPerform a \\(\\chi^2\\) test on some variables"
  },
  {
    "objectID": "hw/hw-1.html#getting-started",
    "href": "hw/hw-1.html#getting-started",
    "title": "HW 1 - Titanic dataset",
    "section": "Getting started",
    "text": "Getting started\n\nLog in to RStudio\nClick on your Stat1010.Rproj.\nGo to File ➛ New File ➛ Quarto Document and name the document hw-1 click create"
  },
  {
    "objectID": "hw/hw-1.html#packages",
    "href": "hw/hw-1.html#packages",
    "title": "HW 1 - Titanic dataset",
    "section": "Packages",
    "text": "Packages\nThe following packages will be used in this assignment:\n\nlibrary(tidyverse) # for data manipulation and data visualization\nlibrary(here) # to organize files"
  },
  {
    "objectID": "hw/hw-1.html#data-titanic",
    "href": "hw/hw-1.html#data-titanic",
    "title": "HW 1 - Titanic dataset",
    "section": "Data: Titanic",
    "text": "Data: Titanic\nOn April 15, 1912, the largest passenger liner ever made collided with an iceberg during her maiden voyage. When the Titanic sank it killed 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck resulted in such loss of life wasthat there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others.\nThe titanic.csv file contains data for 887 of the real Titanic passengers. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their passenger-class, their sex, and the fare they paid\n\nPclass: The class of passengers on the titanic, with \\(1st\\) being the highest class, and \\(3rd\\) the lowest.\nSurvived: A variable that records whether or not a passenger survived the sinking of the titanic.\n\nPart 1: Download and import the data\n\nDownload the file into your Stat1010 R project in the data folder.\nImport your data into R.\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document to ensure that the data loads without errors.\n\n\nPart 2: Exploring categorical variables\n\nHow many observations and how many variables in this dataset?\nClassify all the variables into two categories: qualitative or quantitative\nHow many levels of passenger class are there in the variable?\nHow many passengers survived the sinking of the titanic?\nMake a contingency table of class and survival. Which combination of class and survival is the most common?\n\nWhat proportion of \\(3rd\\) class passengers survived?\nWhat proportion of \\(1st\\) class passengers survived?\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document.\n\n\n\nDraw a plot that conditions on class and displays the proportions of each that survived and update labels. What does the plot suggest regarding the chance of survival and your class? Does it suggest that they are associated?\nAssuming Survived and Pclass are independent, write R coding to find the expected counts for all cells of the contingency table. (Hint: you will need to use the rowSums(.[2:3]) and colSums(.[2:4]) functions, depending on the order that you compute the two.)\nPerform a \\(\\chi^2\\) test on the two variables Survived and Pclass. Include both \\(H_0\\) and \\(H_A\\) and interpret the \\(p-value\\). What conclusions can you draw about the independence of Survived and Pclass?\n\n\n\n\n\n\n\nWarning\n\n\n\nBefore submitting, make sure you render your document,"
  },
  {
    "objectID": "hw/hw-1.html#submission",
    "href": "hw/hw-1.html#submission",
    "title": "HW 1 - Titanic dataset",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nThen submit the pdf following the link on the course website."
  },
  {
    "objectID": "hw/hw-1.html#grading",
    "href": "hw/hw-1.html#grading",
    "title": "HW 1 - Titanic dataset",
    "section": "Grading",
    "text": "Grading\nTotal points available: 25 points.\n\n\n\nComponent\nPoints\n\n\n\n\nPart 1 Qu 1\n2\n\n\nPart 1 Qu 2\n3\n\n\nPart 2 Qu 1\n2\n\n\nPart 2 Qu 2\n2\n\n\nPart 2 Qu 3\n1\n\n\nPart 2 Qu 4\n2\n\n\nPart 2 Qu 5 Pt 1\n1\n\n\nPart 2 Qu 5 Pt 2\n1\n\n\nPart 2 Qu 6\n3\n\n\nPart 2 Qu 7\n4\n\n\nPart 2 Qu 8\n4"
  },
  {
    "objectID": "hw/hw-2.html",
    "href": "hw/hw-2.html",
    "title": "HW 2 - Titanic dataset",
    "section": "",
    "text": "For this homework assignment we will be exploring the Titanic dataset.\n\n\nIn this assignment, you will…\n\nImport data into R\nExplore numeric variables\nCompute means for subgroups and compare them\nComment on and produce a pairs plot of numeric variables\nAddress overplotting"
  },
  {
    "objectID": "hw/hw-2.html#getting-started",
    "href": "hw/hw-2.html#getting-started",
    "title": "HW 2 - Titanic dataset",
    "section": "Getting started",
    "text": "Getting started\n\nLog in to RStudio\nClick on your Stat1010.Rproj that we made the first day of class.\nGo to File ➛ New File ➛ Quarto Document and name the document hw-2 click create."
  },
  {
    "objectID": "hw/hw-2.html#packages",
    "href": "hw/hw-2.html#packages",
    "title": "HW 2 - Titanic dataset",
    "section": "Packages",
    "text": "Packages\nThe following packages will be used in this assignment:\n\nlibrary(tidyverse) # for data manipulation and data visualization\nlibrary(here) # to organize files"
  },
  {
    "objectID": "hw/hw-2.html#data-titanic",
    "href": "hw/hw-2.html#data-titanic",
    "title": "HW 2 - Titanic dataset",
    "section": "Data: Titanic",
    "text": "Data: Titanic\nOn April 15, 1912, the largest passenger liner ever made collided with an iceberg during her maiden voyage. When the Titanic sank it killed 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck resulted in such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others.\nThe titanic.csv file contains data for 887 of the real Titanic passengers. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their passenger-class, their sex, and the fare they paid\n\nPclass: The class of passengers on the titanic, with \\(1st\\) being the highest class, and \\(3rd\\) the lowest.\nSurvived: A variable that records whether or not a passenger survived the sinking of the titanic.\nFare: A variable that records the passenger fare.\n\n\nImport the data into R\nFor each value of Pclass, compute the mean fare and standard deviation paid by the passengers in that class. Comment on them in context.\nFor each value of Survived, compute the mean fare and standard deviation paid by the passengers with that survival status. Comment on them in context.\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document.\n\n\n\nDraw a pairs plot of all numeric variables in the dataset and comment on all scatterplots and histograms. Be sure to use variable names.\nExplore any outliers by filtering and looking at the data. Answer questions like this, but include others that spark your curiosity.\n\nWhich was the biggest family aboard?\nWhich and how many people paid the highest fair?\n\nDraw one plot containing 3 boxplots of the Fare paid for each category of Pclass. What conclusions can you draw from this plot? Consider our last assignment and how the passenger class predicted survival.\n\n\n\n\n\n\n\nWarning\n\n\n\nThis may be a good time to render your document.\n\n\n\nDraw a scatterplot of Pclass_num and Fare, and color it by the survival variable. (Hint: use the function geom_jitter() to avoid overplotting.) Comment on the plot.\n\n\n\n\n\n\n\nWarning\n\n\n\nBefore submitting, make sure you render your document,"
  },
  {
    "objectID": "hw/hw-2.html#submission",
    "href": "hw/hw-2.html#submission",
    "title": "HW 2 - Titanic dataset",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nThen submit the pdf following the link on the course website."
  },
  {
    "objectID": "hw/hw-2.html#grading",
    "href": "hw/hw-2.html#grading",
    "title": "HW 2 - Titanic dataset",
    "section": "Grading",
    "text": "Grading\nTotal points available: 38 points\n\n\n\nComponent\nPoints\n\n\n\n\nQu 1\n2\n\n\nQu 2\n4\n\n\nQu 3\n4\n\n\nQu 4\n15\n\n\nQu 5\n4\n\n\nQu 6\n5\n\n\nQu 7\n4"
  },
  {
    "objectID": "hw/hw-6.html",
    "href": "hw/hw-6.html",
    "title": "HW 6 - Statistics Experience",
    "section": "",
    "text": "The world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience\n2️⃣ Make a slide summarizing on your experience\nYou must complete both parts to receive credit."
  },
  {
    "objectID": "hw/hw-6.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/hw-6.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "HW 6 - Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professional in industry, a speaker from the RLadies directory, or other local data science groups.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\nrstudio::conf 2022\nrstudio::global 2021 talks\nrstudio::conf 2020 talks\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask your professor if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team. Kaggle and Drivendata both lead online competitions. More information to follow here or here.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask your professor to make sure it counts toward the experience. Many of these books are available through the Van Pelt Library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some don’t by Nate Silver\nHow Charts Lie by Alberto Cairo\nList of books about data science ethics\n\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a project for your TidyTuesday submission - The Quarto file with all the code needed to reproduce your visualization. - A pdf that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n✅ The visualization should include features or customization that are beyond what we’ve done in class ."
  },
  {
    "objectID": "hw/hw-6.html#part-2-summarize-your-experience",
    "href": "hw/hw-6.html#part-2-summarize-your-experience",
    "title": "HW 6 - Statistics Experience",
    "section": "Part 2: Summarize your experience",
    "text": "Part 2: Summarize your experience\nMake one slide summarizing your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nName and brief description of the event/podcast/competition/etc.\nSomething you found new, interesting, or unexpected\nHow the event/podcast/competition/etc. connects to something we’ve done in class.\nCitation or link to web page for event/competition/etc.\n\nClick here to see a template to help you get started on your slide. Your slide does not have to follow this exact format; it just needs to include the information mentioned above and be easily readable (i.e. use a reasonable font size!). Creativity is encouraged!"
  },
  {
    "objectID": "hw/hw-6.html#submission",
    "href": "hw/hw-6.html#submission",
    "title": "HW 6 - Statistics Experience",
    "section": "Submission",
    "text": "Submission\nSubmit the reflection as a PDF under the HW 6 - Statistics Experience assignment on Gradescope by Tuesday, Nov 22 at 5 pm ET. It must be submitted by the deadline on Gradescope to be considered for grading."
  }
]